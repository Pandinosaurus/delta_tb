define model
load data
indexing miniworld (mode train ): 23 towns found ( ['potsdam/train', 'austin/train', 'chicago/train', 'kitsap/train', 'tyrol-w/train', 'vienna/train', 'christchurch/train', 'vegas/train', 'paris/train', 'shanghai/train', 'khartoum/train', 'toulouse/train', 'bruges/train', 'rio/train', 'Arlington/train', 'Austin/train', 'DC/train', 'NewYork/train', 'SanFrancisco/train', 'Atlanta/train', 'NewHaven/train', 'Norfolk/train', 'Seekonk/train'] ) with a total of 12434 images
train
epoch= 0 / 200
loss= 0.6325373905045646
loss= 0.5889332525010379
loss= 0.5698888238336219
loss= 0.5601472249397865
loss= 0.5566651509768927
loss= 0.5519846591396608
loss= 0.5465730163786147
loss= 0.47109019355613646
loss= 0.46318777544157846
loss= 0.4349003674892279
loss= 0.40780046877219595
loss= 0.36859967216849326
loss= 0.3496498945355415
backup model
accuracy 84.74412626378677
epoch= 1 / 200
loss= 0.31977959714829923
loss= 0.3017412319034338
loss= 0.28818583242595197
loss= 0.2692033620923758
loss= 0.26512400440871714
loss= 0.24499400667846202
backup model
accuracy 82.70242130055146
epoch= 2 / 200
loss= 0.2420403666049242
loss= 0.24207962326705457
loss= 0.2312116353213787
loss= 0.22806007392704486
loss= 0.22297374188899993
loss= 0.22163332179188727
loss= 0.22086819916963576
backup model
accuracy 90.10838088490604
epoch= 3 / 200
loss= 0.2117912094295025
loss= 0.2107714881747961
loss= 0.21069078907370567
loss= 0.21211134262382983
loss= 0.20908837229013444
loss= 0.20697468250989914
loss= 0.2034174544364214
loss= 0.2028893718868494
backup model
accuracy 90.00954701542075
epoch= 4 / 200
loss= 0.20103094466030597
loss= 0.19458552718162536
loss= 0.19289031855762004
loss= 0.19140041880309583
loss= 0.19100236378610133
backup model
accuracy 89.82507084865196
epoch= 5 / 200
loss= 0.19001977253705263
loss= 0.18820981327444314
loss= 0.18660505313426257
loss= 0.1861235935613513
loss= 0.18652289893478155
loss= 0.1863939320668578
loss= 0.18515624698251487
loss= 0.18514314521104097
loss= 0.18466715928167104
loss= 0.18493476014584304
backup model
accuracy 90.04982862285539
epoch= 6 / 200
loss= 0.18677541088312866
loss= 0.1870257693901658
loss= 0.18692030105739832
loss= 0.18669456999748946
loss= 0.186028267852962
loss= 0.18255407478660346
loss= 0.182246986143291
loss= 0.1845005875080824
loss= 0.1843888407945633
backup model
accuracy 89.57590699040033
epoch= 7 / 200
loss= 0.18946404710412026
loss= 0.1904488141834736
loss= 0.18973895728588105
loss= 0.18379237927496433
loss= 0.18165873758494855
backup model
accuracy 92.57455065359477
epoch= 8 / 200
loss= 0.17916614312678575
loss= 0.17800474416464568
loss= 0.17842757787555455
loss= 0.17805782917886973
loss= 0.17830341372638941
loss= 0.1772651780024171
loss= 0.17945688724517822
loss= 0.1796338377147913
backup model
accuracy 91.70751314848856
epoch= 9 / 200
loss= 0.1783407149463892
loss= 0.1773011638969183
loss= 0.17587880678474904
loss= 0.1761188519001007
loss= 0.173546182513237
loss= 0.18101649940013886
backup model
accuracy 90.68987119587419
epoch= 10 / 200
loss= 0.1875052873045206
loss= 0.1888036758452654
loss= 0.1888057851046324
loss= 0.1882673902064562
loss= 0.1808994208276272
loss= 0.1761484805494547
loss= 0.17074250038713218
backup model
accuracy 91.15261501736111
epoch= 11 / 200
loss= 0.16920535180717708
loss= 0.16859637521207332
loss= 0.16820022087544204
loss= 0.16784470867365597
loss= 0.1676957881450653
loss= 0.16580898478627204
loss= 0.16690827682614326
loss= 0.1665978731215
backup model
accuracy 92.03795668658088
epoch= 12 / 200
loss= 0.16258438162505626
loss= 0.16284804284572602
loss= 0.1622996776551008
loss= 0.16138122215867043
backup model
accuracy 92.50143292994281
epoch= 13 / 200
loss= 0.1643449468910694
loss= 0.16362754981964828
loss= 0.16353072378784417
loss= 0.16375928096473216
loss= 0.16475883983075618
loss= 0.16452316865324973
loss= 0.16458321668207646
loss= 0.1641084948927164
loss= 0.16366022296249866
loss= 0.16333329048007728
loss= 0.16288593344390392
backup model
accuracy 91.60087475745506
epoch= 14 / 200
loss= 0.16115218941122295
loss= 0.16172543548047544
loss= 0.1613614523410797
loss= 0.1613881044089794
loss= 0.15904779374599456
loss= 0.16014738351106644
loss= 0.1617489954084158
loss= 0.16063642665743827
loss= 0.16028448075056076
backup model
accuracy 92.03630514705883
epoch= 15 / 200
loss= 0.16159049216657878
loss= 0.16185604277998208
loss= 0.16464882906526326
loss= 0.16457347001880407
loss= 0.16447623092681168
loss= 0.16450564216822386
loss= 0.16513511199504138
loss= 0.1651184792816639
loss= 0.16356402713805437
loss= 0.16432529352605343
loss= 0.16464687898755073
loss= 0.16489133637398481
backup model
accuracy 92.30429336448121
epoch= 16 / 200
loss= 0.1606260097399354
loss= 0.15911094184964894
loss= 0.15921503432095052
loss= 0.1596635579317808
loss= 0.15997040376067162
loss= 0.1568013409525156
loss= 0.15627406161278487
loss= 0.15488582260906697
backup model
accuracy 91.94921396292892
epoch= 17 / 200
loss= 0.1547661681100726
loss= 0.15544175758957862
loss= 0.15545185178518295
loss= 0.1559014292806387
loss= 0.15557183094322682
loss= 0.15565178368240595
loss= 0.1548728608340025
loss= 0.15536549039185046
loss= 0.1572580574080348
loss= 0.15794458124786614
loss= 0.1572731253132224
loss= 0.15853833518922328
loss= 0.1569289617240429
backup model
accuracy 91.65811217064952
epoch= 18 / 200
loss= 0.1563739825040102
loss= 0.16084050107747316
loss= 0.160640051625669
loss= 0.1610482532158494
loss= 0.16106002114713192
loss= 0.16127189725637436
loss= 0.16181072622537612
loss= 0.1607761638239026
loss= 0.16082042422145604
loss= 0.15978293385356665
loss= 0.15897731695324183
backup model
accuracy 92.41145514195262
epoch= 19 / 200
loss= 0.15525508914142847
loss= 0.15578655496239663
loss= 0.16007730644196272
loss= 0.16041145738214255
loss= 0.16328772000968456
loss= 0.1636278473958373
backup model
accuracy 91.5376327614379
epoch= 20 / 200
loss= 0.16193615534808486
loss= 0.16112994854804127
loss= 0.16164729443844408
loss= 0.1601994847273454
loss= 0.1583865933632478
loss= 0.15881985125597567
loss= 0.15167200313415377
backup model
accuracy 92.35460707720588
epoch= 21 / 200
loss= 0.15168880969285964
loss= 0.14961003866046668
loss= 0.15059276919811965
loss= 0.14913441613316536
loss= 0.14795293882489205
loss= 0.15147871129214763
loss= 0.15052648521959783
backup model
accuracy 92.96144971660539
epoch= 22 / 200
loss= 0.15335444677621127
loss= 0.15116646133363246
loss= 0.15246851898729802
backup model
accuracy 90.9882062525531
epoch= 23 / 200
loss= 0.15203789826482533
loss= 0.15198674522340297
loss= 0.1532110112160444
loss= 0.15374334689229727
loss= 0.151229392811656
loss= 0.15039704486727715
loss= 0.14931539986282588
loss= 0.14729119297116994
loss= 0.1470357095822692
backup model
accuracy 92.22120098039215
epoch= 24 / 200
loss= 0.14778683740645648
loss= 0.14790931548923253
loss= 0.1487422790750861
loss= 0.152608054690063
backup model
accuracy 92.37864136540033
epoch= 25 / 200
loss= 0.15140058491379021
loss= 0.15007035695016385
loss= 0.15056263130158187
loss= 0.1503607192263007
loss= 0.1491262713447213
loss= 0.1439125894382596
loss= 0.14516232967376708
backup model
accuracy 92.75597426470588
epoch= 26 / 200
loss= 0.1450132418051362
loss= 0.14430407121777533
loss= 0.1436777590215206
loss= 0.14295434415340424
loss= 0.14267382018268107
loss= 0.14535528603941203
loss= 0.1453450257703662
loss= 0.145493740811944
loss= 0.14511102240532636
loss= 0.14576620139181615
backup model
accuracy 92.33385352839052
epoch= 27 / 200
loss= 0.14541103947907685
loss= 0.145502100661397
loss= 0.144114481061697
loss= 0.14432079564779998
loss= 0.14545893486589193
loss= 0.14602655488997698
loss= 0.1476393288001418
loss= 0.14729605611413718
backup model
accuracy 91.0212242774714
epoch= 28 / 200
loss= 0.14786255948245525
loss= 0.14843084368854761
loss= 0.14705088764429092
loss= 0.14700628150254488
loss= 0.14392182983458043
loss= 0.1440596891567111
loss= 0.14490242663770914
loss= 0.14431843519210816
backup model
accuracy 91.63833518433415
epoch= 29 / 200
loss= 0.14713726371526717
loss= 0.14679938282817603
loss= 0.14879561211913825
loss= 0.1503579654917121
loss= 0.15042275242507458
loss= 0.15082908757030963
loss= 0.14979292500764133
loss= 0.1495545817166567
loss= 0.1494712904840708
loss= 0.14691592268645765
loss= 0.14595779843628406
loss= 0.14621536176651717
backup model
accuracy 92.29996744791667
epoch= 30 / 200
loss= 0.14287955719977619
loss= 0.14345141604542733
loss= 0.14401949185878038
loss= 0.14385929774492978
loss= 0.14296460460871457
loss= 0.1429845792427659
loss= 0.14225803300738335
backup model
accuracy 89.74455231311275
epoch= 31 / 200
loss= 0.14280785761773587
loss= 0.14317674860358237
loss= 0.14475147951394318
loss= 0.14445542708039283
loss= 0.14432297095656396
loss= 0.1436382484808564
loss= 0.14390634413808584
loss= 0.1442331288382411
loss= 0.14437379695475103
loss= 0.14258829157799482
backup model
accuracy 92.5799600439134
epoch= 32 / 200
loss= 0.14031154792755843
loss= 0.13976510636508466
loss= 0.13988634925335647
loss= 0.13895408790558578
loss= 0.13880320239812136
backup model
accuracy 92.16202480341094
epoch= 33 / 200
loss= 0.1389305017516017
loss= 0.13741039384156464
loss= 0.13770914647728205
loss= 0.1386504314094782
loss= 0.13990131352096796
backup model
accuracy 92.43029864940767
epoch= 34 / 200
loss= 0.1419542370736599
loss= 0.14153020482510328
loss= 0.14232339810580016
loss= 0.1419652435928583
loss= 0.1414052463695407
backup model
accuracy 92.1539777369281
epoch= 35 / 200
loss= 0.14130529038608075
loss= 0.14066335663199425
loss= 0.14039353352040052
loss= 0.139576895236969
loss= 0.14011203918606044
loss= 0.145663698092103
loss= 0.14541225925087928
loss= 0.14708435356616975
backup model
accuracy 92.3618674683415
epoch= 36 / 200
loss= 0.14834663849323987
loss= 0.14881400287151336
loss= 0.1491831286996603
loss= 0.14923793379217387
loss= 0.1492861321941018
loss= 0.14857714362442492
loss= 0.14049833208322526
loss= 0.13748642820864915
backup model
accuracy 92.63473690257354
epoch= 37 / 200
loss= 0.13793430663645267
loss= 0.13547778762876989
loss= 0.136940526291728
loss= 0.13710987303406
loss= 0.1372074306756258
loss= 0.13735478308051824
loss= 0.13868580326437951
backup model
accuracy 93.26705952563317
epoch= 38 / 200
loss= 0.13800149410963058
loss= 0.13800375044345856
loss= 0.13834272887557744
loss= 0.13821744550019502
loss= 0.13841072481125594
loss= 0.14184430975466966
backup model
accuracy 93.650288500817
epoch= 39 / 200
loss= 0.15656036995351313
loss= 0.16233070623129606
loss= 0.1625215959921479
loss= 0.16766741026192902
loss= 0.16928944688290357
loss= 0.16975445043295623
loss= 0.1688841721788049
backup model
accuracy 93.39117072610294
epoch= 40 / 200
loss= 0.14729841731488705
loss= 0.1469385251775384
loss= 0.14615818519145252
loss= 0.14660873271524907
backup model
accuracy 91.93512242136438
epoch= 41 / 200
loss= 0.14717239763587714
loss= 0.14715210247784852
loss= 0.14715487089008092
loss= 0.14671886343508958
loss= 0.14720477513968944
loss= 0.14694654397666454
loss= 0.14676539100706576
loss= 0.14676707349717616
loss= 0.14586036507040262
loss= 0.14572259061038495
loss= 0.1464490307494998
loss= 0.1440585743263364
loss= 0.1441973774507642
loss= 0.14424195274710655
backup model
accuracy 92.4731796364379
epoch= 42 / 200
loss= 0.14341988399624825
loss= 0.14372084077447653
loss= 0.14424941461533308
loss= 0.14304966311901807
loss= 0.14368425656110048
loss= 0.1437138504907489
loss= 0.14386549044400454
loss= 0.14392345901578665
loss= 0.14359821155667304
backup model
accuracy 91.73194316789215
epoch= 43 / 200
loss= 0.14203066132962705
loss= 0.1417013207823038
loss= 0.13890186805278062
loss= 0.13895220119506121
loss= 0.1379483038932085
backup model
accuracy 92.90060923457925
epoch= 44 / 200
loss= 0.14008858673274516
loss= 0.14010931693017484
loss= 0.140114364400506
loss= 0.14018448386341334
loss= 0.14055229760706425
loss= 0.14018723290413618
loss= 0.14012718360871076
loss= 0.14037500753998755
loss= 0.14022939145565033
loss= 0.14089191682636737
backup model
accuracy 92.47446097579657
epoch= 45 / 200
loss= 0.14148395240306855
loss= 0.14138101883232593
loss= 0.139983933493495
loss= 0.1395919630303979
loss= 0.14138061463832854
loss= 0.1415906162932515
loss= 0.14138363510370255
loss= 0.1407528917118907
loss= 0.13761448577046395
loss= 0.13776814594864845
loss= 0.13797716803848745
loss= 0.13789414290338756
backup model
accuracy 92.977152905433
epoch= 46 / 200
loss= 0.13640110950917006
loss= 0.13548405963927507
loss= 0.1384997106716037
loss= 0.13944926358759402
loss= 0.14262007523328066
loss= 0.1429839951545
loss= 0.14326202400028706
backup model
accuracy 92.50008457158906
epoch= 47 / 200
loss= 0.13935162607580423
loss= 0.13932709954679012
loss= 0.1381878799945116
loss= 0.13831803109496832
loss= 0.1392651117965579
loss= 0.1381831444427371
loss= 0.13778769575059413
loss= 0.1373984372615814
loss= 0.13803305972367524
backup model
accuracy 92.15824940002042
epoch= 48 / 200
loss= 0.13877985831350087
loss= 0.13933394063264132
loss= 0.1382745374366641
loss= 0.13803671766072512
backup model
accuracy 93.45063891441994
epoch= 49 / 200
loss= 0.13394465133547784
loss= 0.1336389594897628
backup model
accuracy 93.37278039470996
epoch= 50 / 200
loss= 0.13466881539672612
loss= 0.13593407616019249
loss= 0.13658859852701424
loss= 0.13826971780508757
loss= 0.13683908686041832
loss= 0.13747721809893845
loss= 0.1375326481834054
backup model
accuracy 93.3543581495098
epoch= 51 / 200
loss= 0.13613314021378756
loss= 0.13627462904900312
loss= 0.13605698578059675
loss= 0.13483077369630336
backup model
accuracy 92.97137171926062
epoch= 52 / 200
loss= 0.13538344226777554
backup model
accuracy 92.21535756229575
epoch= 53 / 200
loss= 0.13387790948152542
loss= 0.13446276232600213
loss= 0.13321026515215637
loss= 0.13282614141702653
loss= 0.13218277953565122
loss= 0.13226992651820182
backup model
accuracy 92.73265325010212
epoch= 54 / 200
loss= 0.13132487703114748
loss= 0.13071003574877976
loss= 0.13179789427667857
loss= 0.13364690460264683
loss= 0.13436876881867646
loss= 0.1345072691142559
loss= 0.13453959591686726
loss= 0.13452369920909404
loss= 0.1329483478143811
loss= 0.13272107400000097
backup model
accuracy 91.96346188214869
epoch= 55 / 200
loss= 0.1352355434000492
loss= 0.13498124461621047
loss= 0.13448868736624717
loss= 0.13812925182282926
loss= 0.13623677987605334
loss= 0.1350539679452777
loss= 0.13580348566174508
backup model
accuracy 93.66579701542075
epoch= 56 / 200
loss= 0.13532506119459867
loss= 0.13503578245639802
loss= 0.13508236732333898
loss= 0.132731753885746
loss= 0.13276983313262464
loss= 0.1343795720115304
loss= 0.13373239800333978
loss= 0.13418317932635546
loss= 0.13383618380874396
loss= 0.13385594438761472
backup model
accuracy 93.04916800704657
epoch= 57 / 200
loss= 0.13108857616782188
loss= 0.13090177848935128
loss= 0.1313411335647106
loss= 0.1313187949731946
loss= 0.1313227428495884
loss= 0.13181516114622355
backup model
accuracy 92.57858296313317
epoch= 58 / 200
loss= 0.13089371234178543
loss= 0.14006360355764627
loss= 0.14143526297062636
loss= 0.14360961329191924
loss= 0.14927118804305792
loss= 0.14984002724289894
backup model
accuracy 93.85734049479167
epoch= 59 / 200
loss= 0.15004170142114162
loss= 0.13828469149768352
loss= 0.13579526096582412
loss= 0.13359862685203552
loss= 0.1343538324534893
loss= 0.13441052611917256
backup model
accuracy 93.20394518484477
epoch= 60 / 200
loss= 0.13387635312974452
loss= 0.13403817713260652
loss= 0.13387839846313
loss= 0.13246220160275698
loss= 0.13109963484108447
loss= 0.13120735980570317
loss= 0.1304839637875557
loss= 0.13062237616628408
loss= 0.1321202765032649
backup model
accuracy 92.93069118923611
epoch= 61 / 200
loss= 0.13161674454808237
loss= 0.13219580613076687
loss= 0.13297961216419935
loss= 0.13193734660744666
loss= 0.1291246183589101
loss= 0.1288668806478381
backup model
accuracy 93.45744612949346
epoch= 62 / 200
loss= 0.12815849363803863
loss= 0.12829341925680637
loss= 0.1264029235392809
loss= 0.12642568867653609
loss= 0.12670056689530612
loss= 0.12666947070509196
loss= 0.12637913972139359
backup model
accuracy 93.14701733558006
epoch= 63 / 200
loss= 0.12546875789761544
loss= 0.12947204407304524
loss= 0.13111005637794734
backup model
accuracy 92.56714505463644
epoch= 64 / 200
loss= 0.13041510213166474
loss= 0.13125511549413205
loss= 0.13006839230656625
loss= 0.13109093748033046
loss= 0.13014596961438657
backup model
accuracy 93.58135308159723
epoch= 65 / 200
loss= 0.12961381789296866
loss= 0.1301556220278144
loss= 0.13043113391846417
loss= 0.129382831081748
loss= 0.1285017789527774
loss= 0.1271605458855629
loss= 0.12506154630333186
loss= 0.12503659769892692
loss= 0.12533883944153787
loss= 0.12527422696352006
backup model
accuracy 92.85578948376225
epoch= 66 / 200
loss= 0.1244139028340578
loss= 0.1250866460800171
loss= 0.12471843250095845
loss= 0.12622001867741348
loss= 0.12697119455784558
loss= 0.12726758159697055
loss= 0.12774699300527573
backup model
accuracy 93.16717090482027
epoch= 67 / 200
loss= 0.13078809261322022
loss= 0.1295901348441839
loss= 0.13218440979719162
loss= 0.13239606224000455
loss= 0.13080192897468806
loss= 0.12998676158487796
backup model
accuracy 92.45044424019608
epoch= 68 / 200
loss= 0.12918648593127727
loss= 0.12906889498233795
loss= 0.12656286258250474
loss= 0.12658547326922417
loss= 0.12739364754408597
loss= 0.1253112593665719
backup model
accuracy 93.51238893995098
epoch= 69 / 200
loss= 0.1263789802417159
loss= 0.12626149632036687
loss= 0.12426516678184271
backup model
accuracy 93.4006698708129
epoch= 70 / 200
loss= 0.124874032959342
loss= 0.12547242499887942
loss= 0.12600602507591246
loss= 0.12707244273275137
loss= 0.12644532214850188
loss= 0.12822949923574925
backup model
accuracy 93.57582082312092
epoch= 71 / 200
loss= 0.12736834228038788
loss= 0.12764930173754693
loss= 0.12803476750850679
loss= 0.12800098866224288
loss= 0.1261996577680111
loss= 0.12749241195619107
loss= 0.12748680293560027
backup model
accuracy 92.85214013991013
epoch= 72 / 200
loss= 0.12625387348234654
loss= 0.12638008933514355
loss= 0.12529276128858327
loss= 0.12713362365961076
loss= 0.12882410682737827
loss= 0.12750690639019013
backup model
accuracy 93.6743754467933
epoch= 73 / 200
loss= 0.12777563635259867
loss= 0.12801509976387024
loss= 0.1287096646055579
loss= 0.1287668740004301
loss= 0.1264781406894326
loss= 0.12675136383622884
loss= 0.12670835662633181
loss= 0.12656029529869556
backup model
accuracy 93.47533381842321
epoch= 74 / 200
loss= 0.12743372455239296
loss= 0.1273735409975052
loss= 0.12625348307192324
loss= 0.1236919255182147
loss= 0.12331768192350864
loss= 0.12318783439695835
backup model
accuracy 93.22458863102533
epoch= 75 / 200
loss= 0.12399312142282724
loss= 0.12553809262812138
loss= 0.12627890661358834
loss= 0.12708794713020324
loss= 0.12727159973233937
loss= 0.1255803547799587
loss= 0.12571294143795966
loss= 0.12596338283270597
backup model
accuracy 93.31780088337419
epoch= 76 / 200
loss= 0.12323143150657416
loss= 0.12578614689409734
loss= 0.12528563916683197
loss= 0.1261558920890093
loss= 0.12664715204387902
loss= 0.1322415952384472
backup model
accuracy 92.40623563878677
epoch= 77 / 200
loss= 0.1319188442081213
loss= 0.13163732759654523
loss= 0.13087342634797097
loss= 0.1271658305823803
backup model
accuracy 93.0189169092116
epoch= 78 / 200
loss= 0.12639314010739328
loss= 0.12587198100984096
loss= 0.1254916623234749
loss= 0.125348053984344
loss= 0.12369514759629965
loss= 0.12351976305246354
loss= 0.12368555150926114
backup model
accuracy 93.4674702563317
epoch= 79 / 200
loss= 0.12419879648834467
loss= 0.12300008971244097
loss= 0.12382001128047705
loss= 0.1255148573964834
loss= 0.12598426219075917
loss= 0.12753272622823716
backup model
accuracy 93.6012321920956
epoch= 80 / 200
loss= 0.12654893543571233
loss= 0.12530456390231848
loss= 0.12536308016628028
loss= 0.12524654731154442
loss= 0.1257535572350025
loss= 0.12609886784106494
loss= 0.12556343622505664
loss= 0.1257037029415369
backup model
accuracy 93.42456852532679
epoch= 81 / 200
loss= 0.1248302898183465
loss= 0.12399481065571308
loss= 0.12398534331470729
loss= 0.12358404457569122
loss= 0.1238371454551816
loss= 0.1217493799328804
loss= 0.12193697705864906
loss= 0.12219416752457618
loss= 0.12211811065673828
loss= 0.12212812952697277
loss= 0.12269788812845946
loss= 0.12241900287568569
loss= 0.12123798921704293
loss= 0.12080867379903794
loss= 0.12107673060148955
backup model
accuracy 92.27138703788808
epoch= 82 / 200
loss= 0.12287310481071473
loss= 0.12353976778686046
loss= 0.12459018368273973
loss= 0.1250912503898144
loss= 0.12629978280514478
backup model
accuracy 93.14122178819444
epoch= 83 / 200
loss= 0.12535817038267852
loss= 0.12568129222840072
loss= 0.12528115637600423
loss= 0.12513011980801822
loss= 0.12462569743394852
loss= 0.12430235963314772
loss= 0.1237133890017867
loss= 0.12250042624771595
backup model
accuracy 93.17763703788808
epoch= 84 / 200
loss= 0.12196190059185028
loss= 0.1217972519621253
loss= 0.12294716276228428
loss= 0.12220664095133543
loss= 0.1221273760125041
loss= 0.12238778233528137
backup model
accuracy 93.69328278186275
epoch= 85 / 200
loss= 0.12350576266646385
loss= 0.1231344024464488
loss= 0.122820392139256
loss= 0.12204178128391505
loss= 0.12245365615934134
loss= 0.12228018496185541
loss= 0.12409672893583774
loss= 0.12403261762112379
loss= 0.12363272853195667
backup model
accuracy 93.54006299785539
epoch= 86 / 200
loss= 0.1250363051518798
loss= 0.12461128372699022
loss= 0.12375078462064266
loss= 0.12274222265928984
loss= 0.12251898173242808
loss= 0.12225143790245056
loss= 0.12362144377082586
loss= 0.12430988553911447
loss= 0.1224175675958395
loss= 0.12219486415386199
loss= 0.12204482402652501
loss= 0.12234366960823535
loss= 0.12229668889194727
backup model
accuracy 93.29761061325571
epoch= 87 / 200
loss= 0.12284333080053329
loss= 0.1291406049206853
loss= 0.12944948989897967
loss= 0.1316295763477683
loss= 0.1323384790495038
backup model
accuracy 93.89790294372958
epoch= 88 / 200
loss= 0.13047363083809616
loss= 0.12955892469733954
loss= 0.1281727148592472
loss= 0.12723683688789605
loss= 0.12654202792793512
loss= 0.12487004347145557
backup model
accuracy 94.03880878523285
epoch= 89 / 200
loss= 0.12432383444160224
loss= 0.1246356874704361
loss= 0.12483399499207735
loss= 0.1244521102681756
loss= 0.12095856983214617
loss= 0.12054379109293223
loss= 0.1189313093945384
backup model
accuracy 93.15940946691177
epoch= 90 / 200
loss= 0.11939891669899225
loss= 0.11937351096421481
loss= 0.12430622410029173
loss= 0.12444141805171967
loss= 0.12475716128945351
loss= 0.12466855641454458
loss= 0.12504755053669214
loss= 0.12502417873591185
loss= 0.12442881885915995
loss= 0.1243099244683981
loss= 0.12424329858273268
loss= 0.12412355359643698
backup model
accuracy 93.28521369485294
epoch= 91 / 200
loss= 0.12596482917666435
loss= 0.1261427104473114
loss= 0.12626889877021313
loss= 0.1250328414514661
loss= 0.12315091855823994
loss= 0.12420413497835397
loss= 0.12421614971011877
loss= 0.124531922750175
loss= 0.12492632918059826
loss= 0.12443228874355555
loss= 0.12406109791249037
loss= 0.12437342561781406
loss= 0.12429192267358304
backup model
accuracy 92.92114896088644
epoch= 92 / 200
loss= 0.12396982185542584
loss= 0.12192118521779775
loss= 0.12159666180610657
loss= 0.12162561919540167
loss= 0.12173113595694303
loss= 0.12138743255287408
loss= 0.12150756038725376
backup model
accuracy 93.98494785283906
epoch= 93 / 200
loss= 0.12135695893317461
loss= 0.12112317979335785
loss= 0.12197854250669479
loss= 0.12134989563375712
loss= 0.1216177138313651
loss= 0.1219361250847578
loss= 0.12254437133669853
loss= 0.12263072855770588
backup model
accuracy 94.04784358404821
epoch= 94 / 200
loss= 0.12204755052924156
loss= 0.12233040615916252
loss= 0.1204668953642249
loss= 0.12015182383358479
loss= 0.11981809239834547
loss= 0.11998890526592731
loss= 0.1196078784763813
loss= 0.11994618814438582
loss= 0.11980435710400343
loss= 0.11988454733043909
backup model
accuracy 93.85663679534314
epoch= 95 / 200
loss= 0.12080324709415435
loss= 0.11995561592280865
loss= 0.11937561545521021
loss= 0.11928360644727945
loss= 0.12009939815849066
loss= 0.1198750787228346
loss= 0.12037276212126016
loss= 0.12235917236655951
backup model
accuracy 92.83922462214052
epoch= 96 / 200
loss= 0.12545985739678145
loss= 0.12190173212438822
loss= 0.12056581776589155
loss= 0.12036434516310691
backup model
accuracy 93.27013920802696
epoch= 97 / 200
loss= 0.11931240454316139
loss= 0.11945019260048867
loss= 0.11960123587399721
loss= 0.11934038870036602
loss= 0.11897501338273286
loss= 0.12090792432427407
backup model
accuracy 92.66566457312092
epoch= 98 / 200
loss= 0.12063465740531683
loss= 0.14338151119649412
loss= 0.14792332760989665
loss= 0.14817039247602223
loss= 0.1482137906551361
backup model
accuracy 93.2622740502451
epoch= 99 / 200
loss= 0.12984190456569195
loss= 0.1267116104066372
loss= 0.12565334662795066
loss= 0.12563624408096075
loss= 0.12527581118047237
loss= 0.12481374725699425
loss= 0.1247587776184082
loss= 0.12458986602723598
backup model
accuracy 93.62076663347631
epoch= 100 / 200
loss= 0.12500792659819127
loss= 0.12496587961912155
loss= 0.12424108881503343
backup model
accuracy 93.25852577359069
epoch= 101 / 200
loss= 0.12184538699686527
loss= 0.12062502469867468
loss= 0.11923715494573116
loss= 0.11998266987502575
loss= 0.11989056263118983
loss= 0.11940755032002925
backup model
accuracy 93.66905860651552
epoch= 102 / 200
loss= 0.11711243361234665
loss= 0.11736567959189415
loss= 0.11787488304078579
loss= 0.11850147746503353
loss= 0.11789885446429253
loss= 0.11850940231233835
loss= 0.1171592116355896
loss= 0.11740296538919211
loss= 0.11795167047530412
loss= 0.11779751062393189
backup model
accuracy 94.00846354166667
epoch= 103 / 200
loss= 0.11752965539693833
loss= 0.1176366363838315
loss= 0.11768471632152795
loss= 0.11709163159132004
loss= 0.11664562929421664
loss= 0.11657799195498228
loss= 0.11608272910118103
loss= 0.11623509496450424
loss= 0.11671227253973485
loss= 0.11712961744517088
loss= 0.11719460990279913
backup model
accuracy 93.88386565563725
epoch= 104 / 200
loss= 0.11605536434799432
loss= 0.11678624164313078
loss= 0.11699146211147309
loss= 0.11627324439585209
loss= 0.11658491797745228
loss= 0.1175533191487193
backup model
accuracy 93.72320835886438
epoch= 105 / 200
loss= 0.11865891005843877
loss= 0.11917209438979626
loss= 0.11915286544710398
loss= 0.11910373829305172
loss= 0.11911116033792496
loss= 0.11818692356348037
backup model
accuracy 92.37022569444444
epoch= 106 / 200
loss= 0.11928300235420465
loss= 0.11967597134411335
loss= 0.12038392841815948
loss= 0.11986305329948664
loss= 0.11965578809380531
loss= 0.11796597573906183
backup model
accuracy 93.68182253370098
epoch= 107 / 200
loss= 0.11702208332717419
loss= 0.1165384927392006
loss= 0.11650624617934227
loss= 0.1155482354015112
loss= 0.11430585507303476
loss= 0.113817691616714
backup model
accuracy 93.56694878472223
epoch= 108 / 200
loss= 0.11476455140858889
loss= 0.11530310742557048
loss= 0.11704170294106006
loss= 0.11751802396029234
loss= 0.11762472700327635
loss= 0.11758445404469967
backup model
accuracy 93.70173196231617
epoch= 109 / 200
loss= 0.11536142725497484
loss= 0.115274299941957
loss= 0.11202953975647688
backup model
accuracy 93.34699722988154
epoch= 110 / 200
loss= 0.11207707520574331
loss= 0.11283739671111107
loss= 0.11220156315714121
loss= 0.11280909862369298
loss= 0.11304995145648718
loss= 0.11530162684619427
backup model
accuracy 93.40332350388071
epoch= 111 / 200
loss= 0.11791242081671953
loss= 0.11919192235916853
loss= 0.11946883633732795
loss= 0.12161978892982006
loss= 0.12341862462460995
loss= 0.12335343338549137
loss= 0.12287565067410469
loss= 0.12249406952410936
backup model
accuracy 93.91809800091912
epoch= 112 / 200
loss= 0.11994937293231488
loss= 0.11968832574784756
loss= 0.11862763836979866
loss= 0.1193927738070488
loss= 0.11890937760472298
loss= 0.11824148833751678
loss= 0.11812751911580563
backup model
accuracy 92.93785264756944
epoch= 113 / 200
loss= 0.11499876320362092
loss= 0.11504676099866629
loss= 0.1161615751311183
loss= 0.1158742979541421
backup model
accuracy 93.53359566482843
epoch= 114 / 200
loss= 0.11447602059692144
loss= 0.11369356770068408
loss= 0.11366880159825087
loss= 0.1142726792395115
loss= 0.11336530454456806
loss= 0.11279207441955805
loss= 0.11295697193592787
backup model
accuracy 93.91554808772467
epoch= 115 / 200
loss= 0.11357232011854648
loss= 0.11313977241516113
loss= 0.11390455227345228
loss= 0.11381163973361254
loss= 0.11335098829120398
loss= 0.11351787760853767
backup model
accuracy 93.76128791360294
epoch= 116 / 200
loss= 0.11332984820008278
loss= 0.11313698418438435
loss= 0.11302186362445354
loss= 0.11362566012889147
loss= 0.11483858320862055
loss= 0.11444002024829387
loss= 0.11355207324028015
loss= 0.11393075451254844
loss= 0.11399572163820267
backup model
accuracy 93.67257710375817
epoch= 117 / 200
loss= 0.11434954177588225
loss= 0.1155452000722289
loss= 0.114291189648211
loss= 0.11386365331709385
loss= 0.11448929168283939
loss= 0.11466361783444881
backup model
accuracy 93.84367340686275
epoch= 118 / 200
loss= 0.11284277398139238
loss= 0.11281491726636887
loss= 0.11246319640427828
backup model
accuracy 94.13461243872548
epoch= 119 / 200
loss= 0.1124423573538661
loss= 0.11264847308397292
loss= 0.11216016747057438
loss= 0.11250190947204829
backup model
accuracy 93.88234496272467
epoch= 120 / 200
loss= 0.11147654589265585
loss= 0.11165644962340593
loss= 0.11258654106408357
loss= 0.11249377328902482
loss= 0.1123732940107584
loss= 0.11332700550556182
loss= 0.11883345998823643
loss= 0.11888397622853518
backup model
accuracy 93.94615342881944
epoch= 121 / 200
loss= 0.11786230497062206
loss= 0.11432648602873087
backup model
accuracy 93.44694808261846
epoch= 122 / 200
loss= 0.11737694449722767
loss= 0.11710621636360884
loss= 0.11561348039656877
loss= 0.11640250615775585
loss= 0.11631517872214317
loss= 0.11540684647858143
loss= 0.11275834254920483
loss= 0.11306705519556999
backup model
accuracy 93.28960663041258
epoch= 123 / 200
loss= 0.11308426342904568
loss= 0.11636205211281776
loss= 0.11778236709535123
backup model
accuracy 94.4043638939951
epoch= 124 / 200
loss= 0.11821365799754859
loss= 0.11783520504832268
loss= 0.11797105092555285
loss= 0.11638486232608557
loss= 0.11601554367691279
loss= 0.11565209798514843
loss= 0.11494514670222998
loss= 0.11566313486546279
loss= 0.11532719306647778
loss= 0.11694924887269735
backup model
accuracy 93.59503133935866
epoch= 125 / 200
loss= 0.11613189663738012
loss= 0.12242971144616605
loss= 0.12232903946191072
loss= 0.12128452889621258
loss= 0.12092276711016893
loss= 0.12067918002605438
loss= 0.12007135443389416
loss= 0.11997440874576569
loss= 0.1210355482250452
backup model
accuracy 93.72152650122548
epoch= 126 / 200
loss= 0.117185562774539
loss= 0.11686621718108654
loss= 0.116970219835639
loss= 0.1177135881781578
loss= 0.11794842950999737
loss= 0.11765534251928329
loss= 0.11781070519238711
loss= 0.11773101132363081
backup model
accuracy 94.53033566942402
epoch= 127 / 200
loss= 0.11752234842628241
loss= 0.11713903743773699
loss= 0.11690044432878494
loss= 0.11697741769254208
loss= 0.11729726064950227
loss= 0.11753963358700276
loss= 0.11832898933440447
loss= 0.11853650409728289
loss= 0.11792445503175258
loss= 0.1182440171763301
loss= 0.11611989736557007
loss= 0.11671131443232298
backup model
accuracy 93.70310744740604
epoch= 128 / 200
loss= 0.11797281302511692
loss= 0.11725787494331598
loss= 0.11731497179716825
loss= 0.11692086070775985
loss= 0.12038597796112299
loss= 0.12184514649212361
loss= 0.12157664116472006
loss= 0.12167152903974056
loss= 0.12187787991017103
loss= 0.11929654970765113
backup model
accuracy 93.40440059487337
epoch= 129 / 200
loss= 0.1189800662919879
loss= 0.11753684941679239
loss= 0.11340200666338206
loss= 0.11340336754918098
loss= 0.11307994984090328
loss= 0.11505915682762861
backup model
accuracy 93.53291590073529
epoch= 130 / 200
loss= 0.11956966955214739
loss= 0.12040133219212294
loss= 0.1207145930826664
loss= 0.1211528668552637
loss= 0.11686369378119707
loss= 0.11700188346207142
backup model
accuracy 93.85787026399102
epoch= 131 / 200
loss= 0.11677200809121131
loss= 0.11782313901931048
loss= 0.11586815293878316
loss= 0.11533496730029583
backup model
accuracy 93.59255323223039
epoch= 132 / 200
loss= 0.1126584206521511
loss= 0.11253060888499021
loss= 0.11195697247982025
loss= 0.11364007212221622
loss= 0.1137694988399744
loss= 0.11501143753528595
loss= 0.11576161332428456
loss= 0.11525747824460268
loss= 0.11485401879996061
loss= 0.11440141070634127
backup model
accuracy 93.75543332567402
epoch= 133 / 200
loss= 0.11464941911399365
loss= 0.11337602965533733
loss= 0.1125894508138299
loss= 0.11253675363957882
loss= 0.111894476339221
loss= 0.11233000446110963
backup model
accuracy 93.51999400020425
epoch= 134 / 200
loss= 0.11144257795065642
loss= 0.1112012366577983
loss= 0.11125128924846649
loss= 0.11136125169694423
loss= 0.11239569410681724
loss= 0.11256454456597567
loss= 0.11323086742311717
loss= 0.11375561863183975
loss= 0.11310251858085393
loss= 0.11302855018526316
backup model
accuracy 93.57518892973856
epoch= 135 / 200
loss= 0.1128416882455349
loss= 0.11274579141288996
loss= 0.11275903362780809
backup model
accuracy 94.0174520654616
epoch= 136 / 200
loss= 0.11328440085053444
loss= 0.11345747359097004
loss= 0.11313403848558665
loss= 0.11379131950438022
loss= 0.11287371836602687
loss= 0.11293060753494501
backup model
accuracy 93.75185578788808
epoch= 137 / 200
loss= 0.11340038239955902
loss= 0.11369150217622519
loss= 0.11463916391134261
loss= 0.11494023516774178
loss= 0.11369068305939437
loss= 0.11199796181172132
backup model
accuracy 94.22044781454248
epoch= 138 / 200
loss= 0.11283941011875868
loss= 0.11309535522013903
loss= 0.11404927443712949
loss= 0.1146123993396759
loss= 0.11489697888493539
loss= 0.11452350698411465
loss= 0.1141175888478756
loss= 0.11272916574031115
backup model
accuracy 94.21607881433823
epoch= 139 / 200
loss= 0.11153389900922775
loss= 0.11053298849612475
loss= 0.11003135614097119
loss= 0.11062580104917288
loss= 0.11070696748793125
loss= 0.11085449524223805
backup model
accuracy 94.4908566942402
epoch= 140 / 200
loss= 0.11070524640381336
loss= 0.11060899037867784
loss= 0.1112940876185894
loss= 0.11135764084756375
loss= 0.11089863631874324
loss= 0.11055778227746486
loss= 0.10961216062307358
loss= 0.11124571405351162
loss= 0.11323253389447928
loss= 0.11356892697513103
backup model
accuracy 93.54566546670752
epoch= 141 / 200
loss= 0.1139187666401267
loss= 0.11412978161126375
loss= 0.11456059589982033
loss= 0.11461799491196871
loss= 0.11491988252848387
loss= 0.11607295103371143
loss= 0.11627015877515078
loss= 0.11393066469579935
backup model
accuracy 94.35174121732027
epoch= 142 / 200
loss= 0.11363381080329418
loss= 0.11418606970459223
loss= 0.11390501577407122
loss= 0.11425154950469732
loss= 0.11427614107728004
loss= 0.11308382451534271
loss= 0.11306378066539764
loss= 0.11573260914534331
backup model
accuracy 93.26895201439952
epoch= 143 / 200
loss= 0.11577504180371762
loss= 0.1159724559634924
loss= 0.11586271047592163
loss= 0.11712755817919969
loss= 0.11641326282173395
loss= 0.11661510974168778
loss= 0.1144659499451518
loss= 0.11535561464726925
backup model
accuracy 94.0342546849469
epoch= 144 / 200
loss= 0.1143672538921237
loss= 0.11358531046658754
loss= 0.11287236247211695
loss= 0.1131183984875679
loss= 0.1129612784832716
loss= 0.11211454663425684
loss= 0.11134037118405103
loss= 0.11094694897532463
backup model
accuracy 93.95866364123775
epoch= 145 / 200
loss= 0.11015110742300749
loss= 0.11045238025486469
loss= 0.109993816614151
loss= 0.11026236377656459
loss= 0.11016994431614875
loss= 0.10983130868524313
loss= 0.10993591878563165
loss= 0.10998530559241772
backup model
accuracy 94.1680277905433
epoch= 146 / 200
loss= 0.10912269003689289
loss= 0.10780331971123815
loss= 0.10976033305749297
loss= 0.11102301256731152
loss= 0.11099730120971799
loss= 0.11131839970126749
loss= 0.11116018669679761
loss= 0.11166482055559754
loss= 0.1121791778691113
backup model
accuracy 94.26212724673202
epoch= 147 / 200
loss= 0.11250419264659285
loss= 0.11284965433180333
loss= 0.11272184181958438
loss= 0.11180893275886775
loss= 0.11174303539097309
loss= 0.10986893355846405
loss= 0.10996740005910396
loss= 0.10957152709364891
loss= 0.1094537527859211
loss= 0.1088137162104249
backup model
accuracy 94.05840386284723
epoch= 148 / 200
loss= 0.10850912865251303
loss= 0.10912001252174378
loss= 0.11004417095333338
loss= 0.1096558114886284
loss= 0.10964617908000945
loss= 0.10848284512758255
loss= 0.10861072264611721
backup model
accuracy 93.55824429381127
epoch= 149 / 200
loss= 0.10888926219195127
loss= 0.10981331292539835
loss= 0.1102080562710762
loss= 0.11127000238746404
backup model
accuracy 93.77229498570262
epoch= 150 / 200
loss= 0.11538888171315193
backup model
accuracy 94.43060980902777
epoch= 151 / 200
loss= 0.11289318007649854
loss= 0.11119202693225816
loss= 0.10803246670635418
loss= 0.10818468236597255
loss= 0.10719477971317247
loss= 0.10763581359060481
loss= 0.1075183779746294
backup model
accuracy 93.76301285488154
epoch= 152 / 200
loss= 0.10699093505740166
loss= 0.10688572011888027
loss= 0.1057445378229022
loss= 0.10612215388566255
loss= 0.10613202277570963
backup model
accuracy 94.10760059232027
epoch= 153 / 200
loss= 0.10701353128999472
loss= 0.10735864605754614
loss= 0.10828743983060121
loss= 0.10848281234502792
loss= 0.10769375301897526
loss= 0.10785337250679732
loss= 0.11082977194339037
loss= 0.11076690685003995
backup model
accuracy 94.28783541411356
epoch= 154 / 200
loss= 0.11106370616704225
loss= 0.11155985698103904
loss= 0.11232891988009214
loss= 0.11190410424023867
loss= 0.11203371230512857
loss= 0.11299532808363438
loss= 0.10912199221551418
loss= 0.10952378109097481
loss= 0.10902744248509406
loss= 0.10872051160782575
loss= 0.10869470279663801
backup model
accuracy 93.53101224213644
epoch= 155 / 200
loss= 0.10852828286588193
loss= 0.10702826879918576
loss= 0.10824083290994167
loss= 0.10833668325096368
loss= 0.10843666020780801
loss= 0.10825536429882049
loss= 0.10904920235276222
backup model
accuracy 94.4592795777165
epoch= 156 / 200
loss= 0.11047701101750135
loss= 0.11040865741670132
loss= 0.10884006228297949
backup model
accuracy 94.59213196997548
epoch= 157 / 200
loss= 0.10938494205474854
loss= 0.10920184589922428
loss= 0.10915745098143816
loss= 0.10971445288509131
loss= 0.11001446187496185
loss= 0.11096780452877283
loss= 0.11083302561193704
backup model
accuracy 94.96572776245915
epoch= 158 / 200
loss= 0.11118573352694511
loss= 0.11016247218474745
loss= 0.10992307355627418
loss= 0.10974061688408256
loss= 0.1091718534938991
loss= 0.10870575180277228
loss= 0.1094898590259254
loss= 0.10908352615311742
backup model
accuracy 94.47441948784723
epoch= 159 / 200
loss= 0.10842885050922632
loss= 0.10809651855379343
loss= 0.10815044343471528
loss= 0.10733203295618296
backup model
accuracy 94.21163960375817
epoch= 160 / 200
loss= 0.1167344431951642
loss= 0.11786162368953228
loss= 0.1181415781378746
loss= 0.11855029162019491
loss= 0.11592204842716455
loss= 0.1144595392793417
loss= 0.11374195653945207
loss= 0.1111557437852025
backup model
accuracy 93.18848773233252
epoch= 161 / 200
loss= 0.10882565163075925
loss= 0.10829871747642755
loss= 0.10825604140758514
loss= 0.10806905921548605
loss= 0.1080257934331894
loss= 0.10787998925894499
loss= 0.10744986362755299
loss= 0.10671928443014622
loss= 0.1069726849719882
loss= 0.10679312080144882
loss= 0.10695663537830115
loss= 0.1070151737704873
loss= 0.10695988565683365
loss= 0.10692881867289543
backup model
accuracy 94.17771522671569
epoch= 162 / 200
loss= 0.10586009196937084
loss= 0.10644109588116407
loss= 0.10645833894610406
loss= 0.10549264322966337
loss= 0.10492174714803695
loss= 0.10531673397868872
loss= 0.10541069380939007
loss= 0.10432299710810185
loss= 0.10447011921554804
loss= 0.10512109890580178
loss= 0.10469984825700522
backup model
accuracy 94.05277905433006
epoch= 163 / 200
loss= 0.1052200934290886
loss= 0.10515133801847697
loss= 0.10476133305579424
loss= 0.10465839423239232
loss= 0.10360077947378159
loss= 0.1036797121912241
loss= 0.10352204509079456
backup model
accuracy 94.02044558057598
epoch= 164 / 200
loss= 0.10626051139086484
loss= 0.10700950749218464
loss= 0.10728180557489395
loss= 0.10771434579044581
loss= 0.1062251165509224
loss= 0.10585681103169918
loss= 0.10643048670142889
backup model
accuracy 94.5052609911152
epoch= 165 / 200
loss= 0.10559317391365766
loss= 0.10616403851658106
loss= 0.10698489662259818
loss= 0.10662525307387113
loss= 0.1063522669672966
backup model
accuracy 94.2588640599469
epoch= 166 / 200
loss= 0.10684507317841054
loss= 0.10683709055185318
loss= 0.10757990695536136
loss= 0.10734942343086004
loss= 0.10906033404171467
loss= 0.10897102411836386
loss= 0.10899023201316595
loss= 0.1084804705902934
loss= 0.10815016735345125
backup model
accuracy 94.73445957158906
epoch= 167 / 200
loss= 0.10712112911045552
loss= 0.10785610042512417
loss= 0.10776049230247736
loss= 0.10654226329177618
backup model
accuracy 93.77075035743464
epoch= 168 / 200
loss= 0.10524796526879072
loss= 0.10526671126484871
loss= 0.10471974734216928
loss= 0.1041736325994134
loss= 0.10449681345373392
loss= 0.10535546161234378
loss= 0.10599123012274504
loss= 0.10557468235492706
loss= 0.1049618186801672
loss= 0.10577296886593103
loss= 0.1062328664213419
backup model
accuracy 93.14227973090277
epoch= 169 / 200
loss= 0.10785229712724685
loss= 0.10868181958794594
loss= 0.10869593478739262
loss= 0.10867250744253397
loss= 0.10908053983002901
loss= 0.10795180927962064
loss= 0.10807385997846723
loss= 0.10793308766558767
backup model
accuracy 94.01491013071896
epoch= 170 / 200
loss= 0.10367137167602777
loss= 0.10288370944559574
loss= 0.10362444914877415
loss= 0.1044045365601778
loss= 0.10405814671888948
loss= 0.10422220377251507
backup model
accuracy 94.50361902573529
epoch= 171 / 200
loss= 0.10726896421983838
loss= 0.10701521361246705
loss= 0.10612920900806784
loss= 0.10526633834466338
loss= 0.10569548165425659
loss= 0.10703756825998426
loss= 0.11018298467621207
loss= 0.11055766977369785
loss= 0.11052684538066387
backup model
accuracy 93.70949978298611
epoch= 172 / 200
loss= 0.11287640891969204
loss= 0.11289946097880602
loss= 0.11310382470488549
loss= 0.11317063216120005
loss= 0.1133946493268013
loss= 0.11343634940683842
loss= 0.11124151401221752
loss= 0.11019940000027419
loss= 0.10914245698601008
loss= 0.11000427592545747
loss= 0.10952542886137963
backup model
accuracy 94.56425047232435
epoch= 173 / 200
loss= 0.10803321197628975
loss= 0.10811610717326403
loss= 0.10838626202195883
loss= 0.10735117748379708
loss= 0.10759509108960628
loss= 0.106734785027802
backup model
accuracy 94.567280688317
epoch= 174 / 200
loss= 0.10402028448879719
loss= 0.10386866915971041
loss= 0.10298525903373956
loss= 0.10274178676307201
loss= 0.10285037823021412
loss= 0.1028581676632166
loss= 0.10246917054057121
loss= 0.10148667588829995
backup model
accuracy 94.47023877910539
epoch= 175 / 200
loss= 0.10242281883955001
loss= 0.10241666425019502
loss= 0.1023835500329733
loss= 0.10170949630439281
loss= 0.10232058320194483
loss= 0.10175201829522848
loss= 0.10145846225321292
loss= 0.10148035865277052
loss= 0.10148811403661967
loss= 0.10146428443491459
backup model
accuracy 94.65108953737744
epoch= 176 / 200
loss= 0.10349126543849707
loss= 0.10409916877746582
loss= 0.1045253999531269
loss= 0.1075142777711153
loss= 0.1085917516797781
loss= 0.10848610505461692
backup model
accuracy 93.9985862183415
epoch= 177 / 200
loss= 0.1049233827367425
loss= 0.10483805313706399
loss= 0.10420691430568695
loss= 0.10357072297483683
loss= 0.10341209705919027
loss= 0.1028628034889698
loss= 0.10395079027861356
loss= 0.10503576301038266
loss= 0.10557422652840615
loss= 0.1057553719356656
backup model
accuracy 94.59870621425654
epoch= 178 / 200
loss= 0.1049109247326851
loss= 0.10760953661054373
loss= 0.107626519985497
loss= 0.10875322300940753
backup model
accuracy 94.50721252042484
epoch= 179 / 200
loss= 0.10660102389752865
loss= 0.10449520386755466
loss= 0.1040609872713685
loss= 0.10357280772179366
loss= 0.10414071653038263
loss= 0.10268311947584152
backup model
accuracy 94.02612942963644
epoch= 180 / 200
loss= 0.10174410149455071
loss= 0.10260024067014456
loss= 0.10253272008150816
loss= 0.10365142293274403
loss= 0.1041571407020092
loss= 0.10455744806677103
loss= 0.10487685400992632
loss= 0.10509448491036892
loss= 0.10656535804271698
backup model
accuracy 93.64552696078431
epoch= 181 / 200
loss= 0.10644648481160403
loss= 0.10548931274563074
loss= 0.10463842961937189
loss= 0.10483370494097471
loss= 0.10435427259653807
backup model
accuracy 94.63311887254902
epoch= 182 / 200
loss= 0.10203189235180617
loss= 0.1025028746575117
loss= 0.10128452856093645
loss= 0.10331720482558011
backup model
accuracy 94.24236781301062
epoch= 183 / 200
loss= 0.10252648707479238
loss= 0.10226106360554695
loss= 0.10212829411029815
loss= 0.10033449348062277
loss= 0.10099590916186571
loss= 0.10085773736238479
loss= 0.1010557771101594
loss= 0.10147516492754222
loss= 0.10139710765331983
backup model
accuracy 94.35812876582925
epoch= 184 / 200
loss= 0.10160946648567915
loss= 0.10186741303652525
loss= 0.10118127942085266
loss= 0.10108262244611979
loss= 0.10265872351825238
backup model
accuracy 93.7327920751634
epoch= 185 / 200
loss= 0.10607992321252822
loss= 0.10625857975333929
loss= 0.10640649992972612
loss= 0.10651267945766449
loss= 0.10606767278164625
loss= 0.10570056039839983
loss= 0.10528677605092525
loss= 0.10294070534408092
loss= 0.10261121645569801
backup model
accuracy 94.30110517514298
epoch= 186 / 200
loss= 0.10302699949592352
loss= 0.10252317942678929
loss= 0.10257385976612568
loss= 0.10293739400804043
loss= 0.10300738662481308
loss= 0.1036149474605918
loss= 0.10470361296087503
loss= 0.10404639426618814
backup model
accuracy 94.30787090226715
epoch= 187 / 200
loss= 0.10381424302235245
loss= 0.10418642235919834
loss= 0.10443083522841334
loss= 0.10370885504409671
loss= 0.10411501919850707
loss= 0.10397992596030235
backup model
accuracy 94.39315736060048
epoch= 188 / 200
loss= 0.10962684135884046
loss= 0.11007102005183697
loss= 0.11189784083515406
loss= 0.11115851074457168
loss= 0.1064273637533188
backup model
accuracy 94.31313189338235
epoch= 189 / 200
loss= 0.10339408900588751
loss= 0.101595020852983
loss= 0.10207761459052563
loss= 0.10195636495947838
loss= 0.10072908882051707
loss= 0.10249509699642659
loss= 0.1027937199920416
loss= 0.10344273298978805
backup model
accuracy 94.3250261693219
epoch= 190 / 200
loss= 0.10186020012944937
loss= 0.1022628029435873
loss= 0.10255250375717878
loss= 0.10339934166520834
backup model
accuracy 94.35370551215277
epoch= 191 / 200
loss= 0.10477199111133814
loss= 0.10564650725573302
loss= 0.10471696868538856
loss= 0.10384988676756621
backup model
accuracy 95.03344566993464
epoch= 192 / 200
loss= 0.10218066073954106
loss= 0.1025337284989655
loss= 0.10249250618740917
loss= 0.10223795717582107
loss= 0.10174753030762076
loss= 0.10300436405465006
loss= 0.10297652820125222
backup model
accuracy 94.73378938163808
epoch= 193 / 200
loss= 0.10145452266559005
loss= 0.10161311287432909
loss= 0.10156125422567129
loss= 0.09965693112462759
loss= 0.09966231398284435
loss= 0.09964389108121395
loss= 0.0985057845711708
loss= 0.0988160515576601
loss= 0.09916712928563357
backup model
accuracy 94.82757927389706
epoch= 194 / 200
loss= 0.0995856899395585
loss= 0.10043584138154983
loss= 0.10055464323610068
loss= 0.10198993980884552
loss= 0.10090047113597393
backup model
accuracy 94.70549619587419
epoch= 195 / 200
loss= 0.10033262509852647
loss= 0.1004504744336009
loss= 0.09904470261186361
loss= 0.09942977454513312
loss= 0.1005992903932929
loss= 0.10088613513857127
loss= 0.10182926628738642
loss= 0.10228868465870619
backup model
accuracy 94.35366561989379
epoch= 196 / 200
loss= 0.10347452860325575
loss= 0.1034730862826109
backup model
accuracy 94.80594171262256
epoch= 197 / 200
loss= 0.1011142261698842
loss= 0.10160304609686137
loss= 0.10174371983855962
backup model
accuracy 94.10830269607843
epoch= 198 / 200
loss= 0.10128322150558233
loss= 0.10148740846663713
loss= 0.10144764963537455
loss= 0.1013072095438838
loss= 0.10110690042376519
loss= 0.10001003518700599
loss= 0.09991260550916195
loss= 0.10051248826086522
loss= 0.10130683414638042
loss= 0.10135729767382146
backup model
accuracy 94.67194042330473
epoch= 199 / 200
loss= 0.10113113701343536
loss= 0.10760646272450686
loss= 0.10750720139592886
loss= 0.1096000399067998
loss= 0.10977734394371509
backup model
accuracy 94.30001851000817
training stops after reaching time limit
/opt/conda/conda-bld/pytorch_1591914855613/work/torch/csrc/utils/tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.
load model
massif benchmark
indexing miniworld (mode test ): 23 towns found ( ['potsdam/test', 'christchurch/test', 'toulouse/test', 'paris/test', 'austin/test', 'chicago/test', 'kitsap/test', 'tyrol-w/test', 'vienna/test', 'vegas/test', 'shanghai/test', 'khartoum/test', 'bruges/test', 'rio/test', 'Arlington/test', 'Austin/test', 'DC/test', 'NewYork/test', 'SanFrancisco/test', 'Atlanta/test', 'NewHaven/test', 'Norfolk/test', 'Seekonk/test'] ) with a total of 6135 images
potsdam/test
2377954 85832 104021 1032193
94.72630555555556 88.53537375048252
christchurch/test
141582689 6330640 674224 14127947
95.6950235226515 81.06941795480513
toulouse/test
forward in progress 576 3392
forward in progress 1152 3392
forward in progress 1792 3392
forward in progress 2368 3392
forward in progress 3008 3392
forward in progress 576 3392
forward in progress 1152 3392
forward in progress 1792 3392
forward in progress 2368 3392
forward in progress 3008 3392
18560050 1104724 352994 4173848
93.97428431403674 83.4165538877965
paris/test
51976138 3075665 787940 3631357
93.50339072255264 70.76577200131437
austin/test
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
110301204 5631296 1172343 17895157
94.96026740740741 83.32184510286481
chicago/test
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
91149629 8288688 4128021 31433662
90.80243777777778 79.8473887851107
kitsap/test
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
124398701 2760694 1253421 6587184
97.02658148148149 79.50484247972722
tyrol-w/test
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
122972303 2436299 682219 8909179
97.68998666666667 85.79948098074836
vienna/test
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
91437254 8632597 2262870 32667279
91.9292837037037 82.17096315416629
vegas/test
151552770 12274872 2618824 32804534
92.52515871940417 79.91356010736934
shanghai/test
203693314 7362165 9066269 16850052
93.06734640999477 71.58506476766607
khartoum/test
42052585 2687512 2517807 5216596
90.08028852109119 69.519698368772
bruges/test
1654252 73852 27263 244633
94.94425 82.49718882255094
rio/test
385004486 9928815 8313743 17329722
95.66249030503982 72.09650589335983
Arlington/test
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
7643805 464061 51747 840387
94.2688 77.82252754287178
Austin/test
forward in progress 640 3456
forward in progress 1344 3456
forward in progress 2048 3456
forward in progress 2752 3456
8264913 450078 98578 1909994
94.88364081975365 85.72976789968793
DC/test
forward in progress 1280 1600
1459149 263867 39778 797206
88.1388671875 77.59601815816082
NewYork/test
1589140 154548 46553 459759
91.06217777777778 79.16831132340903
SanFrancisco/test
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
4669566 841486 219104 3269844
88.21566666666666 78.49976962662222
Atlanta/test
1660052 93066 31618 375264
94.22759259259259 84.03723751044694
NewHaven/test
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
7125147 493164 282252 1099437
91.38426666666666 74.41327226006163
Norfolk/test
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
7547569 375025 72845 1004561
95.02366666666667 81.78127158020581
Seekonk/test
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
8412576 173810 42070 371544
97.60133333333333 80.37388000295347
-------- results ----------
potsdam/test 88.53537375048252
christchurch/test 81.06941795480513
toulouse/test 83.4165538877965
paris/test 70.76577200131437
austin/test 83.32184510286481
chicago/test 79.8473887851107
kitsap/test 79.50484247972722
tyrol-w/test 85.79948098074836
vienna/test 82.17096315416629
vegas/test 79.91356010736934
shanghai/test 71.58506476766607
khartoum/test 69.519698368772
bruges/test 82.49718882255094
rio/test 72.09650589335983
Arlington/test 77.82252754287178
Austin/test 85.72976789968793
DC/test 77.59601815816082
NewYork/test 79.16831132340903
SanFrancisco/test 78.49976962662222
Atlanta/test 84.03723751044694
NewHaven/test 74.41327226006163
Norfolk/test 81.78127158020581
Seekonk/test 80.37388000295347
miniworld 79.34304602856415
