define model
load data
indexing miniworld (mode train ): 23 towns found ( ['potsdam/train', 'austin/train', 'chicago/train', 'kitsap/train', 'tyrol-w/train', 'vienna/train', 'christchurch/train', 'vegas/train', 'paris/train', 'shanghai/train', 'khartoum/train', 'toulouse/train', 'bruges/train', 'rio/train', 'Arlington/train', 'Austin/train', 'DC/train', 'NewYork/train', 'SanFrancisco/train', 'Atlanta/train', 'NewHaven/train', 'Norfolk/train', 'Seekonk/train'] ) with a total of 12434 images
train
epoch= 0 / 200
loss= 0.7313628315925598
loss= 0.5117002544370858
loss= 0.4767971408994574
loss= 0.445135434548701
loss= 0.3716408571600914
loss= 0.36956236869096754
loss= 0.3204211021959782
loss= 0.2859399627149105
loss= 0.2846160146594048
loss= 0.28191675543785094
loss= 0.2802192658931017
loss= 0.2775705519318581
loss= 0.2769908433407545
loss= 0.27628345020115375
loss= 0.2754830161482096
loss= 0.27407620452344417
loss= 0.2560028939694166
loss= 0.2563000337779522
loss= 0.256188845038414
loss= 0.25617797501385214
loss= 0.2578943368792534
loss= 0.25361687362194063
loss= 0.25048069961369035
loss= 0.2416234377026558
loss= 0.24102491684257984
loss= 0.24074972972273825
backup model
accuracy 87.11930573965256
epoch= 1 / 200
loss= 0.23889415174722672
loss= 0.23876089207828044
loss= 0.23757425822317602
loss= 0.23432142250239849
loss= 0.22765555046498775
loss= 0.22758634351193904
loss= 0.22655144080519676
loss= 0.22617801927030087
loss= 0.2175814601778984
loss= 0.21599751606583595
loss= 0.2148677459359169
loss= 0.21418628603219986
loss= 0.21516971819102765
loss= 0.22045563749969005
loss= 0.21973973892629148
loss= 0.2135139325633645
loss= 0.2006843364611268
loss= 0.1984159879758954
loss= 0.1968378723040223
loss= 0.19195843193680048
loss= 0.19565208282321692
loss= 0.20023388251662255
loss= 0.20383254647254945
loss= 0.20162202201783658
loss= 0.2023309761285782
loss= 0.19741689428687095
loss= 0.19582194678485393
backup model
accuracy 84.61456736270605
epoch= 2 / 200
loss= 0.1905750524997711
loss= 0.18779219303280115
loss= 0.1861349667236209
loss= 0.1804948928579688
loss= 0.18207617361098527
loss= 0.18034899476915597
loss= 0.18187840282917023
loss= 0.18466451682150364
loss= 0.18721441090106963
loss= 0.18890162818133832
loss= 0.1897096783667803
loss= 0.1816401456296444
loss= 0.18147673040628434
loss= 0.18155410408973693
loss= 0.18102800406515598
loss= 0.18324434973299503
loss= 0.1849317755550146
backup model
accuracy 90.17223589799974
epoch= 3 / 200
loss= 0.1867301142960787
loss= 0.18789136663079262
loss= 0.18771917007863523
loss= 0.18658402673900126
loss= 0.1865211107581854
loss= 0.18588420774787665
loss= 0.18102184612303973
loss= 0.18175971608608962
loss= 0.1811938701942563
loss= 0.1802435088530183
loss= 0.17447089366614818
loss= 0.17481930144131183
loss= 0.1744556313380599
loss= 0.17303865764290094
loss= 0.17454546939581633
loss= 0.1740365769341588
loss= 0.17754482209682465
loss= 0.17825015977025033
loss= 0.17905342809855937
loss= 0.18023451998829843
loss= 0.1813223832845688
loss= 0.1817153386026621
loss= 0.18125260047614575
loss= 0.1796346329897642
loss= 0.1822201757878065
loss= 0.1812700267881155
loss= 0.18047081425786018
backup model
accuracy 91.89721157937923
epoch= 4 / 200
loss= 0.17952243059873582
loss= 0.1808551059663296
loss= 0.1815638756752014
loss= 0.18234495483338833
loss= 0.1825100802630186
loss= 0.18005628757178782
loss= 0.17995763391256334
loss= 0.17784735128283502
loss= 0.1754011644423008
loss= 0.1756063774228096
loss= 0.17496576316654683
loss= 0.1748010740429163
loss= 0.17511324509978293
loss= 0.17662811934947967
loss= 0.1772479399293661
loss= 0.17732987992465496
loss= 0.174428919441998
loss= 0.1748348056897521
loss= 0.1765183898434043
loss= 0.17886006381362676
loss= 0.1785474294796586
loss= 0.17182890959084035
loss= 0.1683131219446659
loss= 0.16762477852404117
loss= 0.16871040064841508
loss= 0.15941654309630393
loss= 0.15946431435644626
backup model
accuracy 89.55018950962666
epoch= 5 / 200
loss= 0.15884222254157065
loss= 0.15880711160600186
loss= 0.16146891884505749
loss= 0.16192949168384074
loss= 0.16319078728556632
loss= 0.16829788777977228
loss= 0.16971258219331503
loss= 0.17240604057908057
loss= 0.16836779922246933
loss= 0.17009865231812
loss= 0.16912727653980256
loss= 0.16539558559656142
loss= 0.16605485506355763
loss= 0.17274767220020293
loss= 0.17571662068367006
loss= 0.17091741748154163
loss= 0.16950715735554694
loss= 0.1666073127090931
loss= 0.16561137206852436
loss= 0.16464050456881524
loss= 0.16477501779794693
loss= 0.1653319264575839
loss= 0.16548741109669207
backup model
accuracy 90.67827572199961
epoch= 6 / 200
loss= 0.1681933844834566
loss= 0.1690022561699152
loss= 0.170725424811244
loss= 0.17195662580430507
loss= 0.1716251078993082
loss= 0.17044681157916786
loss= 0.17153407003730536
loss= 0.17172705810517072
loss= 0.16999566540122032
loss= 0.166016925573349
loss= 0.16503684882074596
loss= 0.16487764168530702
loss= 0.16463635113090277
loss= 0.16474422488361598
loss= 0.16502623487263918
loss= 0.1649552382156253
loss= 0.1624935193359852
loss= 0.16279484778642656
loss= 0.16286396309733392
loss= 0.16349795892834662
loss= 0.1639913285151124
loss= 0.16433700796216727
loss= 0.164754917062819
loss= 0.16521970000118016
loss= 0.166840225122869
loss= 0.16678247455507517
loss= 0.16642147082835435
loss= 0.16083442311733961
loss= 0.15898293424397708
backup model
accuracy 92.34035035611318
epoch= 7 / 200
loss= 0.15272274479269982
loss= 0.15195127122104168
loss= 0.15229609996080398
loss= 0.15090971160680056
loss= 0.15035920586436988
loss= 0.15187462974339724
loss= 0.15258912440389394
loss= 0.15293882001191378
loss= 0.1519422083720565
loss= 0.1524855162575841
loss= 0.15190898042172193
loss= 0.15245289817452432
loss= 0.1508338339999318
loss= 0.1521650655195117
loss= 0.15208302035927773
loss= 0.1510592618957162
loss= 0.151967045776546
loss= 0.15276434913277626
loss= 0.15584451280534267
loss= 0.15442568518221378
loss= 0.15380097288638353
loss= 0.15506580617278815
loss= 0.15539271373301744
loss= 0.15915861614048482
loss= 0.15864167541265486
loss= 0.15921563483774662
backup model
accuracy 91.78449140105795
epoch= 8 / 200
loss= 0.15729168836027385
loss= 0.1631780446693301
loss= 0.20208642758429052
loss= 0.20391007885336876
loss= 0.22769487723708154
loss= 0.23613165613263845
loss= 0.23822127923369407
loss= 0.2426714775711298
loss= 0.2405408217012882
loss= 0.24138908907771112
loss= 0.21087850712239742
loss= 0.18558543123304844
loss= 0.1732699229568243
loss= 0.17293571922928094
loss= 0.1720148566737771
loss= 0.16773262035101652
loss= 0.16712231885641812
loss= 0.16585961651057005
loss= 0.16483284752815963
loss= 0.16498695876449346
loss= 0.1652249376103282
loss= 0.16573787201195955
loss= 0.16472042210400104
backup model
accuracy 91.88623893127362
epoch= 9 / 200
loss= 0.1708797638490796
loss= 0.17311141941696406
loss= 0.17286355532705783
loss= 0.16239154644310475
loss= 0.16492994617670775
loss= 0.16528831366449595
loss= 0.16538430754095315
loss= 0.16547194618731736
loss= 0.16569310057908296
loss= 0.16604739982634784
loss= 0.17345300707966088
loss= 0.17782454270869494
loss= 0.1780306101590395
loss= 0.15568758133798838
loss= 0.15497693579643965
loss= 0.15439641263335943
loss= 0.154336280785501
loss= 0.15335554182529448
loss= 0.15317996948957444
loss= 0.1552885990589857
loss= 0.1557303724437952
loss= 0.15887846246361734
backup model
accuracy 92.86532746275981
epoch= 10 / 200
loss= 0.1548829259350896
loss= 0.1529149390384555
loss= 0.15299686197191475
loss= 0.15143134139478207
loss= 0.15707623712718488
loss= 0.1580322191864252
loss= 0.15816951021552086
loss= 0.15857682030647993
loss= 0.157968688942492
loss= 0.15797144625335932
loss= 0.15522660352289677
loss= 0.1570127025619149
loss= 0.1526818472519517
backup model
accuracy 93.20113535252965
epoch= 11 / 200
loss= 0.15396349798887968
loss= 0.1529210891202092
loss= 0.1525459812954068
loss= 0.15057083148509265
loss= 0.1535367773473263
loss= 0.15144295059144497
loss= 0.15009369183331728
loss= 0.15040751066058874
loss= 0.15061111405491828
loss= 0.14830838643014432
loss= 0.1480689210444689
loss= 0.1518425478413701
loss= 0.15234821524471046
loss= 0.15290035244077443
loss= 0.1509908864274621
loss= 0.1513177277520299
loss= 0.14821345422416926
loss= 0.14802702371031046
loss= 0.1482916697114706
loss= 0.14875965267419816
loss= 0.15356065552681686
loss= 0.1531170591339469
loss= 0.1524542362615466
loss= 0.15225409422069788
loss= 0.151609645485878
loss= 0.15212246533483267
backup model
accuracy 91.49465792061669
epoch= 12 / 200
loss= 0.1514011224359274
loss= 0.15189134173095226
loss= 0.15220186188817025
loss= 0.15109814956784248
loss= 0.15131087377667427
loss= 0.14561518777161836
loss= 0.147355334199965
loss= 0.15010243967175485
loss= 0.15086390543729067
loss= 0.14641532905399798
loss= 0.14293396271765232
loss= 0.14675535973161458
loss= 0.14603228501975538
loss= 0.14750601410865782
loss= 0.1475122981891036
loss= 0.14803233865648507
loss= 0.14906317099928856
loss= 0.1481262083351612
loss= 0.14664809633046388
loss= 0.14631498783826827
loss= 0.1473514388501644
backup model
accuracy 92.48518040318771
epoch= 13 / 200
loss= 0.14577274948358535
loss= 0.1453765772283077
loss= 0.14497195810079574
loss= 0.14713572520762683
loss= 0.1484073343500495
loss= 0.14802702616900207
loss= 0.14771259479224683
loss= 0.14788093086332083
loss= 0.147812465056777
loss= 0.15430433247238398
loss= 0.16201909493654967
loss= 0.16074768465012312
loss= 0.1626726623624563
loss= 0.16284463211894035
loss= 0.15392453242093324
loss= 0.1510610580816865
loss= 0.15277643632143736
loss= 0.1518265737965703
loss= 0.14969769708812236
loss= 0.1497487073391676
loss= 0.15090812548995017
loss= 0.14988114837557076
backup model
accuracy 92.58764692977098
epoch= 14 / 200
loss= 0.15035180166363715
loss= 0.1489113463461399
loss= 0.1492877909168601
loss= 0.1488215534761548
loss= 0.14916937839239836
loss= 0.14735920801758767
loss= 0.14667351111769678
loss= 0.14373879816383123
loss= 0.1455040779337287
loss= 0.1461855908483267
loss= 0.14615999639034272
loss= 0.15161833841353656
loss= 0.15381779119372369
loss= 0.1509632297977805
loss= 0.1512368558719754
loss= 0.15198605112731456
loss= 0.1503168270736933
loss= 0.15055483318865298
loss= 0.14919098276644946
loss= 0.15117483608424664
backup model
accuracy 92.10229415833903
epoch= 15 / 200
loss= 0.15030548084527254
loss= 0.15010288413614034
loss= 0.16388041626662017
loss= 0.16337266560643912
loss= 0.16359599027782679
loss= 0.16686753194779158
loss= 0.16869273211807012
loss= 0.15660276893526315
loss= 0.15236059483140707
loss= 0.1431089271977544
loss= 0.14324123542755843
loss= 0.14148263067007064
loss= 0.1413307300955057
loss= 0.14141210809350013
loss= 0.14190368812531232
loss= 0.14299443032592535
loss= 0.14347227048128844
loss= 0.141528339125216
loss= 0.14162118524312972
loss= 0.14025808081030847
loss= 0.14184340983629226
loss= 0.1467535175383091
loss= 0.14987466353923082
loss= 0.1497404508292675
backup model
accuracy 92.40617988194715
epoch= 16 / 200
loss= 0.15431571912020445
loss= 0.15678895365446807
loss= 0.15707263089716433
loss= 0.15604892764240502
loss= 0.1507969268411398
loss= 0.1481893390417099
loss= 0.14815217308700085
loss= 0.1457203109562397
loss= 0.1453157478570938
loss= 0.14461505252867937
loss= 0.14305823374539614
loss= 0.14456513185054065
loss= 0.14365863543003798
loss= 0.1426183772087097
loss= 0.14434623401612043
loss= 0.14481332514435052
loss= 0.1421350345760584
loss= 0.14144198440015315
loss= 0.14303663562983274
loss= 0.14326306510716677
loss= 0.14474136639386415
loss= 0.14487412814050912
loss= 0.1445023750513792
loss= 0.1464487562701106
backup model
accuracy 91.31607481176293
epoch= 17 / 200
loss= 0.1484894709289074
loss= 0.1478280272334814
loss= 0.14833093859255314
loss= 0.14769796382635833
loss= 0.145510886721313
loss= 0.1450729041919112
loss= 0.1440151710808277
loss= 0.1512761839851737
loss= 0.15101641096174717
loss= 0.15039072196930647
loss= 0.1514827136695385
loss= 0.1544242075458169
loss= 0.15451857022941112
loss= 0.14877278231084345
loss= 0.14473166693001985
loss= 0.14569945722818375
loss= 0.14519766204059123
loss= 0.14501587383449077
loss= 0.14492133632302284
backup model
accuracy 93.10702636336983
epoch= 18 / 200
loss= 0.14479311976581813
loss= 0.1424891761690378
loss= 0.14216911617666483
loss= 0.14194845151156188
loss= 0.13970518495887518
loss= 0.1387104159593582
loss= 0.13774358458817004
loss= 0.13737081177532673
loss= 0.13777116011828183
loss= 0.1377226170897484
loss= 0.13808532141149044
loss= 0.13877278052270411
loss= 0.1390907882526517
loss= 0.1426162263378501
loss= 0.14466014061123134
loss= 0.1451588673889637
loss= 0.14514297880232335
loss= 0.14475927986204623
loss= 0.14408095821738243
loss= 0.14220191694796086
loss= 0.14102711237967014
loss= 0.1372535802051425
backup model
accuracy 92.25149863021647
epoch= 19 / 200
loss= 0.14257538910955192
loss= 0.1421729401126504
loss= 0.15452938497066498
loss= 0.152559923119843
loss= 0.15234987292438745
loss= 0.15229192066937686
loss= 0.14801696263253689
loss= 0.14854468990117312
loss= 0.14480710338801145
loss= 0.14101288422942163
loss= 0.14017737708985806
loss= 0.1432557177171111
loss= 0.1472127367556095
loss= 0.1452142222225666
loss= 0.14549573309719563
loss= 0.14396286211907863
loss= 0.14423574279993773
loss= 0.1463067327812314
loss= 0.1471487882733345
loss= 0.14728056214749813
loss= 0.14198287963867187
backup model
accuracy 92.10684992293378
epoch= 20 / 200
loss= 0.14178311713039876
loss= 0.14097897846251725
loss= 0.14011423774063586
loss= 0.1407896963879466
loss= 0.1394435827061534
loss= 0.14270249713212252
loss= 0.14580290723592043
loss= 0.14706116817891599
loss= 0.14408937510102987
loss= 0.14294908359646796
loss= 0.14458489146083595
loss= 0.14234394039958714
loss= 0.1405020298808813
loss= 0.1401579774543643
loss= 0.13579020261764527
loss= 0.13688293065875767
loss= 0.13702664777636528
loss= 0.13696895275264978
loss= 0.13576391477137803
loss= 0.1372024118900299
loss= 0.13778894178569318
loss= 0.13900711942464114
loss= 0.14048693902790546
loss= 0.14143764454871416
loss= 0.14150974471122027
loss= 0.14160839468240738
loss= 0.1412964540719986
backup model
accuracy 91.74441212566377
epoch= 21 / 200
loss= 0.13990084446966647
loss= 0.13929250031709672
loss= 0.13859130334109068
loss= 0.1381649097800255
loss= 0.13619944956153632
loss= 0.1350823950022459
loss= 0.14006540026515724
loss= 0.1386298107728362
loss= 0.1388136548921466
loss= 0.1396354040130973
loss= 0.14031514342874288
loss= 0.1410707813128829
loss= 0.14120243217796088
loss= 0.14059645030647516
loss= 0.14021032847464085
loss= 0.139889915920794
loss= 0.13941043570637704
loss= 0.1393119091913104
loss= 0.1347892313450575
loss= 0.1353598789870739
loss= 0.13587183229625224
loss= 0.13497341435402632
loss= 0.1358644500747323
loss= 0.1359218605235219
loss= 0.13181683022528887
loss= 0.1293431432545185
loss= 0.13248958341777325
loss= 0.1309467064216733
loss= 0.13083029888570308
backup model
accuracy 92.40382087395345
epoch= 22 / 200
loss= 0.12995809514075518
loss= 0.13146580886095763
loss= 0.13209144327789546
loss= 0.1312585202232003
loss= 0.13559626705944539
loss= 0.14207758322358133
loss= 0.1452546101808548
loss= 0.14830191507935525
loss= 0.14785996746271848
loss= 0.14872363302856684
loss= 0.14527958534657956
loss= 0.14453968316316604
loss= 0.13135296981781722
loss= 0.13122963335365057
loss= 0.132601056098938
loss= 0.13290093753486873
loss= 0.13414045117795467
loss= 0.13480012908577918
loss= 0.1346869182214141
loss= 0.1335603392869234
loss= 0.13514697439968587
loss= 0.13503624528646468
loss= 0.134388723410666
loss= 0.13824164051562549
loss= 0.13899424135684968
loss= 0.13812180258333684
backup model
accuracy 92.65236296565513
epoch= 23 / 200
loss= 0.13888047374784945
loss= 0.14027067724615336
loss= 0.13989055637270212
loss= 0.13979926582425833
loss= 0.14049610558897258
loss= 0.1408844628557563
loss= 0.1395383745804429
loss= 0.13934943709522485
loss= 0.1397762333601713
loss= 0.13513713620603085
loss= 0.1404908188059926
loss= 0.14135898124426605
loss= 0.14146195642650128
loss= 0.14197588805109262
loss= 0.14116561453789472
loss= 0.14087056562304498
loss= 0.14247113920748233
loss= 0.1412448440119624
loss= 0.14105135791003703
loss= 0.14245624568313361
loss= 0.142751794308424
loss= 0.14115927811712026
loss= 0.13924090079963208
loss= 0.13878735978156329
loss= 0.13849160339683295
loss= 0.13779043607413768
loss= 0.132302947640419
backup model
accuracy 92.169189453125
epoch= 24 / 200
loss= 0.1269833255186677
loss= 0.13177444536238908
loss= 0.1328851304575801
loss= 0.13304768592119218
loss= 0.13322941713035108
loss= 0.13404505852609871
loss= 0.13370354987680913
loss= 0.13424346044659616
loss= 0.1333106220513582
loss= 0.13611794471740724
loss= 0.1390073662996292
loss= 0.14000417083501815
loss= 0.13923582185059785
loss= 0.14189748037606478
loss= 0.14210424870252608
loss= 0.14385576259344815
loss= 0.1379112246260047
loss= 0.13686145603656769
loss= 0.13595399383455514
loss= 0.1337061946094036
loss= 0.13418159130960702
backup model
accuracy 92.37825355400541
epoch= 25 / 200
loss= 0.13468595519661902
loss= 0.13507086228579282
loss= 0.13497219558805226
loss= 0.13482346203178167
loss= 0.1350625930726528
loss= 0.13487711369991304
loss= 0.1340117834880948
loss= 0.13483308177441358
loss= 0.1336010652780533
loss= 0.13426798190921546
loss= 0.13419107347726822
loss= 0.13797090094536543
loss= 0.13994751129299401
loss= 0.14116902552545071
loss= 0.14106171175837517
loss= 0.14050256807357073
loss= 0.140737341940403
loss= 0.14334951046854258
loss= 0.1433858809992671
loss= 0.1385376411676407
loss= 0.13160483863204717
loss= 0.1287219775095582
loss= 0.12862681817263366
loss= 0.1276763901859522
backup model
accuracy 93.41041101650052
epoch= 26 / 200
loss= 0.13449916902929546
loss= 0.13527452692389488
loss= 0.13542171847075224
loss= 0.13310835465788842
loss= 0.1339100404828787
loss= 0.13430464651435614
loss= 0.13184155266731978
loss= 0.13064363311976193
loss= 0.12951373659074306
loss= 0.1288668869063258
loss= 0.12715869680047034
loss= 0.13070042077451943
loss= 0.1304300659149885
loss= 0.1327302288636565
loss= 0.13244589924812317
backup model
accuracy 92.92632921431131
epoch= 27 / 200
loss= 0.1314983131363988
loss= 0.1301841139793396
loss= 0.13013001404702662
loss= 0.13024684738367795
loss= 0.12820331569761037
loss= 0.12778040308505298
loss= 0.12737149868160486
loss= 0.12588647965341807
loss= 0.12496172469109297
loss= 0.12491719644516706
loss= 0.12372702226042748
loss= 0.1274301578477025
loss= 0.1348609847575426
loss= 0.1355580312758684
loss= 0.1382367080077529
loss= 0.13787628773599864
loss= 0.1367063472047448
loss= 0.13685291979461908
loss= 0.13516139857470988
loss= 0.13465930737555026
loss= 0.1342956408113241
loss= 0.13412272688001395
loss= 0.13528409015387297
loss= 0.13150608289986848
loss= 0.13223644610494376
loss= 0.13500387605279685
loss= 0.13541991405189038
loss= 0.13628481823951005
loss= 0.13678448870778084
loss= 0.13722552914172412
loss= 0.1372217670828104
loss= 0.13674671787768602
loss= 0.13600678548216819
backup model
accuracy 93.27244961171651
epoch= 28 / 200
loss= 0.1309125079587102
loss= 0.1323037553951144
loss= 0.13572024159133433
loss= 0.1359912868589163
loss= 0.13605662118643522
loss= 0.13456677474081516
loss= 0.1353248791396618
loss= 0.1336469679325819
loss= 0.13303480368107556
loss= 0.13610180273652075
loss= 0.13573430217802523
loss= 0.13711785811930896
loss= 0.13547226577997207
loss= 0.13587296959012746
loss= 0.135667261518538
loss= 0.1330810807272792
loss= 0.1299482209607959
loss= 0.12949243541806937
loss= 0.13257882539182902
backup model
accuracy 91.24346095073463
epoch= 29 / 200
loss= 0.13433292370289565
loss= 0.13364655163139105
loss= 0.13453145649284123
loss= 0.13502351105213165
loss= 0.1337757632881403
loss= 0.13312765333801507
loss= 0.13411126244813204
loss= 0.13227984234690665
loss= 0.13232583731412886
loss= 0.13253684844821692
loss= 0.13121100291609764
loss= 0.13137258172035218
loss= 0.13079964507371186
loss= 0.13033706616610288
loss= 0.13288523953408002
loss= 0.13310383148491384
loss= 0.13414334978908302
loss= 0.1329085685312748
loss= 0.1327901926636696
loss= 0.132705293931067
loss= 0.13263760633766652
loss= 0.13451917257159948
loss= 0.13520658623427154
loss= 0.1337838265299797
loss= 0.13297094836831092
loss= 0.13326662313193083
loss= 0.1359615856409073
loss= 0.13682115711271764
loss= 0.135947999432683
loss= 0.1394030500948429
backup model
accuracy 92.93482832402837
epoch= 30 / 200
loss= 0.1401233308017254
loss= 0.14019637916237115
loss= 0.13999755762517452
loss= 0.13658446602523328
loss= 0.13653473272919656
loss= 0.12973171707242728
loss= 0.1285047873482108
loss= 0.12897720415145159
loss= 0.12704004477709532
loss= 0.1268307038396597
loss= 0.12750032491981983
loss= 0.12765583243221046
loss= 0.12664057195186615
loss= 0.12643953755497933
loss= 0.12901238564401865
backup model
accuracy 92.16988777039353
epoch= 31 / 200
loss= 0.13071039333939552
loss= 0.13998184595257043
loss= 0.1419069381058216
loss= 0.14376293525099754
loss= 0.1467439978197217
loss= 0.1461150847002864
loss= 0.14625920683145524
loss= 0.1472261930257082
loss= 0.14088370334357023
loss= 0.14062257442623377
loss= 0.14044532664120196
loss= 0.1394096691906452
loss= 0.13944844678044319
loss= 0.1389602680876851
loss= 0.1382015847787261
loss= 0.13693191546946765
loss= 0.13736705657094717
loss= 0.13776003081351518
loss= 0.13842144697904588
loss= 0.13965592376887798
loss= 0.13076675187796355
loss= 0.132796175442636
loss= 0.13254639390856027
loss= 0.13200073298066856
loss= 0.13121892042458058
backup model
accuracy 92.09777179844279
epoch= 32 / 200
loss= 0.12981618732213973
loss= 0.13132174991071224
loss= 0.12949908223003148
loss= 0.12594743620604276
loss= 0.12636385194957256
loss= 0.12966438360512256
loss= 0.12929530296474695
loss= 0.12959037695080042
loss= 0.12873664740473031
loss= 0.13206423774361611
loss= 0.1327418403327465
loss= 0.13038620091974734
loss= 0.13056957133114339
loss= 0.12679063361138104
loss= 0.12692064229398967
loss= 0.12686599750071764
backup model
accuracy 93.01986077939715
epoch= 33 / 200
loss= 0.12694303166121246
loss= 0.12700758870691062
loss= 0.12680645383894443
loss= 0.12587457172572614
loss= 0.12555662337690593
loss= 0.1253817779570818
loss= 0.12625911481678487
loss= 0.12684387177228929
loss= 0.12787985172122718
loss= 0.1275212114676833
loss= 0.12758798699826002
loss= 0.13437387205660342
loss= 0.13466324333101512
loss= 0.13442267283797263
loss= 0.13607053596526383
loss= 0.136440060287714
loss= 0.13706650011241436
loss= 0.13761545900255442
loss= 0.13869237329810857
loss= 0.13672758832573892
loss= 0.13401266988366842
loss= 0.12783898606896402
loss= 0.1320484585314989
backup model
accuracy 90.65539827563038
epoch= 34 / 200
loss= 0.1327048660442233
loss= 0.1312098364531994
loss= 0.13075167343020438
loss= 0.12700599804520607
loss= 0.1258424262329936
loss= 0.12534694768488408
loss= 0.12939106959849597
loss= 0.12945965390652417
loss= 0.12925238173455
loss= 0.12808205328881742
loss= 0.12735575139522554
loss= 0.12771269701421262
loss= 0.12663609720766544
loss= 0.12415824212133884
loss= 0.1238914431631565
loss= 0.12298577684909105
loss= 0.12509766198694705
loss= 0.12873963996767998
loss= 0.12954719807952642
loss= 0.13079008780419826
loss= 0.1304275881499052
backup model
accuracy 92.39576556951639
epoch= 35 / 200
loss= 0.13670430198311806
loss= 0.1360710448399186
loss= 0.1334112088382244
loss= 0.13552683133631946
loss= 0.13527111392468213
loss= 0.13502601992338895
loss= 0.1347100654616952
loss= 0.13532645463943482
loss= 0.13460350304841995
loss= 0.13622340988367795
loss= 0.13636168479919433
loss= 0.131680028103292
loss= 0.1286737709492445
loss= 0.13003211375325918
loss= 0.130018977150321
loss= 0.135385439991951
backup model
accuracy 92.86461323849198
epoch= 36 / 200
loss= 0.13330012522637844
loss= 0.1279330038279295
loss= 0.12714393015950917
loss= 0.12463982090353966
loss= 0.12400042459368706
loss= 0.12415113903582096
loss= 0.12323572468012571
loss= 0.12562387950718404
loss= 0.12443083181977271
loss= 0.12559642758220435
loss= 0.125960772074759
loss= 0.12607631146907805
loss= 0.125621334053576
loss= 0.12503319799900056
loss= 0.12517844788730145
loss= 0.12791834995150567
loss= 0.1276092340052128
loss= 0.1291687249392271
loss= 0.1292078186571598
loss= 0.12993286248296498
loss= 0.13030507244169712
loss= 0.13127698887139558
loss= 0.13228753130882978
loss= 0.13471074014902115
loss= 0.13433308392763138
loss= 0.13394268810749055
loss= 0.13528029441833497
backup model
accuracy 90.84575097325384
epoch= 37 / 200
loss= 0.1339469988644123
loss= 0.1343227805942297
loss= 0.13476641543209553
loss= 0.13470185443758964
loss= 0.13352106373757125
loss= 0.1335928338393569
loss= 0.13266443457454444
loss= 0.1311605980247259
loss= 0.12802312936633825
loss= 0.12364277679473162
loss= 0.12339430913329125
loss= 0.12191432412713767
loss= 0.12094928622245789
loss= 0.1204639308154583
loss= 0.12098077733069658
loss= 0.11993300201371312
loss= 0.12023190943524241
loss= 0.12002731962129473
loss= 0.12070109093561769
loss= 0.12357206532731652
loss= 0.12429638946428895
loss= 0.12426649743691087
loss= 0.12516418039798738
loss= 0.12402600042521954
loss= 0.12377711292356253
loss= 0.12366379369050265
backup model
accuracy 91.9962358313176
epoch= 38 / 200
loss= 0.12585067577660083
loss= 0.12593290954828262
loss= 0.12553979102522134
loss= 0.1288084779307246
loss= 0.12947076123207807
loss= 0.1291334030777216
loss= 0.12946192651987076
loss= 0.12802515011280774
loss= 0.1282980802282691
loss= 0.12877894897013903
loss= 0.1275141866877675
loss= 0.12744571533054114
loss= 0.12993862304836512
loss= 0.12984790544956923
loss= 0.12683085098862648
loss= 0.12673912048339844
loss= 0.1262895781546831
loss= 0.12764620158821344
backup model
accuracy 94.21669067987278
epoch= 39 / 200
loss= 0.12728817339986562
loss= 0.12593772504478692
loss= 0.12326139781624079
loss= 0.12629968237131833
loss= 0.12622120678424836
loss= 0.12383511897176504
loss= 0.12688291501253843
loss= 0.12678538218140603
loss= 0.13025436729192733
loss= 0.12988179214298726
loss= 0.12551880806684493
loss= 0.12606663540005683
loss= 0.12720600605010987
loss= 0.12655894726514816
loss= 0.1264945401996374
loss= 0.1245445342361927
backup model
accuracy 92.94563713004138
epoch= 40 / 200
loss= 0.12863539632409812
loss= 0.1281196626275778
loss= 0.12738762017339467
loss= 0.1266784928739071
loss= 0.128543771058321
loss= 0.12845648072659968
loss= 0.1271441600099206
loss= 0.12613824017345907
loss= 0.12634262148290873
loss= 0.12909223783761262
loss= 0.12945606105029583
loss= 0.12982053201645613
loss= 0.12848435953259468
loss= 0.1267697373405099
loss= 0.12693188704550265
loss= 0.12562868379056455
loss= 0.1268498307093978
loss= 0.127076706700027
loss= 0.12646895460784435
loss= 0.12723632458597423
loss= 0.12766250614076852
loss= 0.1287900161370635
loss= 0.12803701143711804
loss= 0.12723426464945078
loss= 0.12583215650171042
loss= 0.12600181374698877
loss= 0.12595363967120649
loss= 0.12417976606637239
backup model
accuracy 92.60208253162057
epoch= 41 / 200
loss= 0.12408170163631439
loss= 0.12388372898101807
loss= 0.12214130479842425
loss= 0.12198987558484077
loss= 0.1217973742634058
loss= 0.12841847524046898
loss= 0.12809708643704654
loss= 0.1331913386285305
loss= 0.13300453342497348
loss= 0.13304838370531796
loss= 0.12190001949667931
loss= 0.12141376882791519
loss= 0.12136652912944555
loss= 0.12149732448160648
loss= 0.12242403287440538
backup model
accuracy 92.97483283652593
epoch= 42 / 200
loss= 0.12499599102884532
loss= 0.125033600628376
loss= 0.12601907409727572
loss= 0.12672688357532025
loss= 0.12897152855992317
loss= 0.12749077934771777
loss= 0.12822941046208144
loss= 0.12825865376740694
loss= 0.12562113232910632
loss= 0.1255962099507451
loss= 0.12516410868614913
loss= 0.12217859867960215
loss= 0.12384660441428423
loss= 0.12282794885337353
loss= 0.12307587362825871
loss= 0.123125506862998
loss= 0.12166700147092342
loss= 0.12302136514335871
loss= 0.12309067580848933
loss= 0.12306333266198635
backup model
accuracy 93.525989682593
epoch= 43 / 200
loss= 0.12190964702516795
loss= 0.12217024393379688
loss= 0.1220402043685317
loss= 0.12205370754003525
loss= 0.12122749827802182
loss= 0.12265940863639116
loss= 0.1239999794960022
loss= 0.12418857581913471
loss= 0.12353558745235205
loss= 0.12292100835591555
loss= 0.12244228933006525
loss= 0.1224305447563529
loss= 0.12170749761164189
loss= 0.12270544741302729
loss= 0.12287373658269644
loss= 0.11903612896800041
loss= 0.11981677558273077
loss= 0.12273220513015985
loss= 0.12305457197129727
loss= 0.12392517242580653
loss= 0.12588374584913253
loss= 0.12563908595591783
loss= 0.12592921499162912
loss= 0.13146128829568623
loss= 0.13430072855204345
loss= 0.13425471276044845
loss= 0.13441326931118966
loss= 0.1334103548899293
backup model
accuracy 91.08027422648716
epoch= 44 / 200
loss= 0.137867603674531
loss= 0.13394698031246663
loss= 0.1340250938385725
loss= 0.1308961346372962
loss= 0.13118250146508217
loss= 0.13077621299773454
loss= 0.12819369804114103
loss= 0.12836904853582382
loss= 0.12116504985839129
loss= 0.12110024314373731
loss= 0.12074346471577883
loss= 0.12054723117500543
loss= 0.12012287229299545
loss= 0.12122713096439838
loss= 0.11976996701210738
loss= 0.1188508116826415
loss= 0.12177067410200834
loss= 0.12172301303595305
loss= 0.12291054733097553
loss= 0.12436679761856795
loss= 0.12495198611170054
loss= 0.125479700230062
loss= 0.12532662723213434
loss= 0.12378382559865714
backup model
accuracy 93.7050961317232
epoch= 45 / 200
loss= 0.12408678829669953
loss= 0.12397471893578768
loss= 0.12476616781204938
loss= 0.12540471371263265
loss= 0.12666353479027748
loss= 0.12615652956068515
loss= 0.12614073272794485
loss= 0.12541638378053904
loss= 0.1286777398362756
loss= 0.12858158189803362
loss= 0.13082295071333647
loss= 0.12977077834308148
loss= 0.127860460691154
loss= 0.1260326864570379
loss= 0.1263314738124609
loss= 0.12753598973155023
loss= 0.1280740176141262
loss= 0.12639870338141918
loss= 0.1255236978828907
loss= 0.12284202475100756
backup model
accuracy 93.7722077616994
epoch= 46 / 200
loss= 0.12316457387059927
loss= 0.12410552382469177
loss= 0.12344195276498794
loss= 0.12051860295236111
loss= 0.12034932408481837
loss= 0.11867821414023638
loss= 0.11916146505624056
loss= 0.11851397905498744
loss= 0.12029733415693045
loss= 0.1211490985751152
loss= 0.12267865106463433
loss= 0.1227865407243371
loss= 0.12244642242789268
loss= 0.12297675393521786
loss= 0.12284814510494471
loss= 0.12223439667373896
loss= 0.12395775735378266
loss= 0.124034178070724
loss= 0.1226687129214406
loss= 0.1211418255418539
loss= 0.12053611323237419
loss= 0.12081672012805938
loss= 0.12095528550446033
loss= 0.12326192382723093
backup model
accuracy 93.53501690468627
epoch= 47 / 200
loss= 0.12302346903830767
loss= 0.12366225372999906
loss= 0.12588538493961096
loss= 0.12611069310456513
loss= 0.12521462969481945
loss= 0.1241974426805973
loss= 0.12397086996585131
loss= 0.12438240356743335
loss= 0.12472288433462381
loss= 0.1220517448335886
loss= 0.12085785306990146
loss= 0.12038448508828878
loss= 0.12050413332879543
loss= 0.12046705011278391
loss= 0.12464571800082921
loss= 0.12412788435816764
loss= 0.12464540608227254
loss= 0.12392318345606328
loss= 0.12399048648774624
loss= 0.12207408700138331
loss= 0.1200431814044714
loss= 0.12112390410155058
loss= 0.12085619442164898
loss= 0.1202829559519887
loss= 0.12012827280908824
loss= 0.12027454528957605
loss= 0.11971016962081193
backup model
accuracy 93.31096363838122
epoch= 48 / 200
loss= 0.12192345917224884
loss= 0.12318400621414184
loss= 0.12287202708423138
loss= 0.12386467535048723
loss= 0.12187881574034691
loss= 0.1251290488615632
loss= 0.12101075805723667
loss= 0.12082049496471882
loss= 0.11966168381273747
loss= 0.1171484475955367
loss= 0.11675476588308811
loss= 0.11667738094925881
loss= 0.11631287578493357
loss= 0.11492090176790953
loss= 0.1161297521367669
loss= 0.11634874146431684
loss= 0.11582490023225546
loss= 0.11633188113570213
loss= 0.11811602272093297
loss= 0.11787927638739347
loss= 0.11809996139258146
loss= 0.12010124105960131
backup model
accuracy 92.40191998753909
epoch= 49 / 200
loss= 0.1180685382336378
loss= 0.11807288341224194
loss= 0.11896430041640997
loss= 0.11852424923330546
loss= 0.11714953109622002
loss= 0.11891547545790672
loss= 0.11901822336018085
loss= 0.1168658808618784
loss= 0.11697763215750456
loss= 0.11812065105885267
loss= 0.11921060211956501
loss= 0.11894054986536502
loss= 0.12154820416122675
loss= 0.12270766746252776
loss= 0.12125116631388665
loss= 0.11911420278251171
loss= 0.1192290536314249
loss= 0.11925294317305088
loss= 0.11833491370081901
loss= 0.11730364382266999
loss= 0.1170936469733715
loss= 0.12175996996462345
loss= 0.12044486563652754
loss= 0.11817004926502704
backup model
accuracy 93.08027397197517
epoch= 50 / 200
loss= 0.11789901003241539
loss= 0.11704232160001993
loss= 0.11390477307140827
loss= 0.1128544707223773
loss= 0.11202997077256441
loss= 0.11202792581170798
loss= 0.11699807468801737
loss= 0.12049861669540406
loss= 0.12160622011870145
loss= 0.1226891165971756
loss= 0.12155391048640013
loss= 0.12168881297111511
loss= 0.12173876516520978
loss= 0.11921023696660996
loss= 0.1189061464369297
loss= 0.12141302727162838
loss= 0.12162185050547122
loss= 0.12300457429140806
loss= 0.12371554292738438
loss= 0.12355824936181307
loss= 0.1268177554011345
loss= 0.1284227353334427
loss= 0.12897601775825024
backup model
accuracy 93.30382298640295
epoch= 51 / 200
loss= 0.12804644137620927
loss= 0.12619217105209826
loss= 0.11935349181294441
loss= 0.119186498709023
loss= 0.11953406509011984
loss= 0.11910763960331679
loss= 0.1202623563632369
loss= 0.12008100006729365
loss= 0.1194140799716115
loss= 0.11798011757433415
loss= 0.11802205517888069
loss= 0.11949467048048973
loss= 0.11798279777169228
loss= 0.11820319056510925
loss= 0.11785321488976479
loss= 0.1179901684448123
loss= 0.1172030819952488
loss= 0.11655550479888915
loss= 0.11656338974833488
backup model
accuracy 94.09766814843546
epoch= 52 / 200
loss= 0.11749328933656215
loss= 0.11863757323473692
loss= 0.12070208255201578
loss= 0.12153244312852621
loss= 0.12093944322317839
loss= 0.12331674356013536
loss= 0.1235764729231596
loss= 0.12453612141311168
loss= 0.12366657376289368
loss= 0.12399224665015936
loss= 0.12396262668073177
loss= 0.12386491913348437
loss= 0.12042584341019393
loss= 0.12035021524876356
loss= 0.12053965099155903
loss= 0.11733982764184475
loss= 0.11517667971551418
loss= 0.11520423121750355
loss= 0.11436888013035058
loss= 0.11681106530129909
loss= 0.11693800523877144
loss= 0.11718294739723206
loss= 0.12125889830291271
loss= 0.1210606073960662
loss= 0.11996225606650114
loss= 0.11844256140291691
backup model
accuracy 92.88718686117491
epoch= 53 / 200
loss= 0.11877454806119203
loss= 0.11870167087763547
loss= 0.12005283776670694
loss= 0.1194377338513732
loss= 0.12076973099261522
loss= 0.12173633731901645
loss= 0.1175745977833867
loss= 0.11898264460265637
loss= 0.11886564821004868
loss= 0.11747954335063696
loss= 0.11751436572521926
loss= 0.11572994958609342
loss= 0.11533059295266866
loss= 0.11519198089838029
loss= 0.11689547143876552
loss= 0.11667639695107937
loss= 0.1167794493213296
loss= 0.11744893800467253
loss= 0.11656240724027157
loss= 0.11894630804657937
loss= 0.12109406415373086
loss= 0.12230453848838806
backup model
accuracy 93.44394297098971
epoch= 54 / 200
loss= 0.12173221565783024
loss= 0.12385303828865289
loss= 0.12291052330285311
loss= 0.12306837603449822
loss= 0.12133482694625855
loss= 0.12174653638154269
loss= 0.12201032780110836
loss= 0.12348840314894914
loss= 0.12221707466989756
loss= 0.12216460105031729
loss= 0.1221085849031806
loss= 0.1214494888484478
loss= 0.12122172139585018
loss= 0.1211210262030363
loss= 0.12066598642617464
loss= 0.1202786584571004
loss= 0.12223714683204889
loss= 0.12262972265481949
loss= 0.12119636591523886
loss= 0.12081792801618577
loss= 0.11948887970298529
loss= 0.11757697183638811
loss= 0.11737602826207877
backup model
accuracy 93.80308961010799
epoch= 55 / 200
loss= 0.11432175312191248
loss= 0.11642688099294901
loss= 0.11953369501978159
loss= 0.11897896710783243
loss= 0.11891696013510228
loss= 0.12086815889924765
loss= 0.1195358094200492
loss= 0.11980952829122543
loss= 0.1202138314396143
loss= 0.11980521641671657
loss= 0.12030023012310266
loss= 0.11963787451386451
loss= 0.11961312547326088
loss= 0.11974051304161548
loss= 0.1196525003388524
loss= 0.11865666653960943
loss= 0.11919405579566955
loss= 0.12099361438304186
loss= 0.12094507552683353
loss= 0.1214555636420846
loss= 0.12026169762015343
loss= 0.11992765575647354
loss= 0.12013067834079266
backup model
accuracy 93.25766405588269
epoch= 56 / 200
loss= 0.12208832945674658
loss= 0.11860354948788882
loss= 0.1176365814357996
loss= 0.11762580648064613
loss= 0.11528617326170205
loss= 0.11632599547505379
loss= 0.11638345830142498
loss= 0.11627959787845611
loss= 0.1166280322894454
loss= 0.11717109102755785
loss= 0.1181485865265131
loss= 0.12627392325550318
loss= 0.12601605486124753
loss= 0.12236494246870279
loss= 0.12243894673883915
loss= 0.11574943732470273
loss= 0.11572091519832611
loss= 0.11425135169178248
loss= 0.11487926680594683
loss= 0.11810617752373219
backup model
accuracy 93.38126621241366
epoch= 57 / 200
loss= 0.11991733856499195
loss= 0.11874592248350382
loss= 0.11863682691007853
loss= 0.11904878199100494
loss= 0.11775186620652675
loss= 0.11739048101007939
loss= 0.11728811979293824
loss= 0.11813791114836932
loss= 0.1156246504932642
loss= 0.11499462068080903
loss= 0.11492927402257919
loss= 0.1150323137268424
loss= 0.1152397945895791
loss= 0.11556867860257626
loss= 0.11600989300757647
loss= 0.11661622509360313
loss= 0.1169775627925992
loss= 0.11729528471827506
loss= 0.11755663000047206
loss= 0.11628687400370837
loss= 0.11609246544539928
loss= 0.11556220173835755
loss= 0.11471208740025758
loss= 0.11559786763042211
loss= 0.11437990847975016
backup model
accuracy 93.83158699932402
epoch= 58 / 200
loss= 0.11472509548068047
loss= 0.11409175299108028
loss= 0.11445838868618012
loss= 0.11396711822599173
loss= 0.11328223895281553
loss= 0.1129523104429245
loss= 0.11306841123849154
loss= 0.1131992956623435
loss= 0.11315119579434395
loss= 0.1136731729283929
loss= 0.11331099431961775
loss= 0.1135347793623805
loss= 0.11530954327434301
loss= 0.11454624332487583
loss= 0.11262330953031778
loss= 0.11531746290624141
loss= 0.11523591697216035
loss= 0.11627410672605037
loss= 0.11640692982822656
loss= 0.11565524995326996
loss= 0.1182468894124031
loss= 0.11903399888426065
loss= 0.11892444148659706
loss= 0.11785303819924593
loss= 0.11711414102464915
loss= 0.11838517006486654
loss= 0.1166984475031495
backup model
accuracy 92.93701712712975
epoch= 59 / 200
loss= 0.11707583609968424
loss= 0.11711304422467947
loss= 0.1184442000463605
loss= 0.11911530949175358
loss= 0.11920595575124025
loss= 0.11903329089283943
loss= 0.11937591839581728
loss= 0.11932828284800052
loss= 0.12014931056648492
loss= 0.11819199703633786
loss= 0.11818494416773319
loss= 0.11836809746921062
loss= 0.11939843442291022
loss= 0.12007169995456934
loss= 0.11999583851546049
loss= 0.11787549197673798
loss= 0.11771254859864712
loss= 0.11747515548020601
loss= 0.11740529593080282
loss= 0.11599922735244035
loss= 0.11589946947991848
loss= 0.11526510380208492
loss= 0.11665428809821606
loss= 0.11637394521385432
loss= 0.11331749692559243
loss= 0.11450329978018998
loss= 0.11439213801175356
loss= 0.11482554052025079
loss= 0.11642152290791273
backup model
accuracy 94.14678578082243
epoch= 60 / 200
loss= 0.11648835379630328
loss= 0.11511590972542762
loss= 0.11494792640209198
loss= 0.11249632868915796
loss= 0.11241388641297817
loss= 0.11195255059748888
loss= 0.11252137873321771
loss= 0.11277314059436322
loss= 0.11290764644742012
loss= 0.11499139819294214
loss= 0.1158897590637207
loss= 0.120298030115664
loss= 0.12483982659876347
loss= 0.12524636916816234
loss= 0.12548812828958034
loss= 0.1253932061418891
loss= 0.12619410742074252
loss= 0.12700084097683428
loss= 0.12637747518718243
loss= 0.12194380685687065
loss= 0.1196052449569106
backup model
accuracy 94.06024534192159
epoch= 61 / 200
loss= 0.11819234611466527
loss= 0.1160889851488173
loss= 0.11438579792156815
loss= 0.11350241133943201
loss= 0.11482825372368097
loss= 0.11486471850425005
loss= 0.11559106212109327
loss= 0.11356244605034589
loss= 0.1136320509761572
loss= 0.11532070077955722
loss= 0.11468081969767809
loss= 0.11163347896188497
loss= 0.11346108894795179
loss= 0.11630822986364364
loss= 0.11634063903242349
loss= 0.11646878324449063
loss= 0.11611514620482921
loss= 0.1156969677656889
loss= 0.11488609928637743
loss= 0.11567863889038563
loss= 0.11676553692668676
loss= 0.11598660800606013
loss= 0.11591125942766667
backup model
accuracy 93.88919260652854
epoch= 62 / 200
loss= 0.11521041452884674
loss= 0.11472247183322906
loss= 0.11401046723127366
loss= 0.11441140368580818
loss= 0.1144474845007062
loss= 0.11278177592903375
loss= 0.11316149108111859
loss= 0.11362700052559375
loss= 0.11315318487584591
loss= 0.11301613599061966
loss= 0.11326784390956163
loss= 0.11336042143404484
loss= 0.11288537006825208
loss= 0.11248374298214912
loss= 0.1122202829271555
loss= 0.11217991564422845
loss= 0.11328526761382818
loss= 0.11358554009348154
loss= 0.11347321659326554
loss= 0.11254092194139957
loss= 0.11167184043675661
loss= 0.11125469360500574
loss= 0.11229679986834526
loss= 0.11251740101724864
loss= 0.11571841798722744
loss= 0.1164064810797572
backup model
accuracy 94.05202937679177
epoch= 63 / 200
loss= 0.11020640715956688
loss= 0.10997411262243986
loss= 0.10890291351824999
loss= 0.1112312676757574
loss= 0.11265131745487451
loss= 0.11242700640112162
loss= 0.1139867078512907
loss= 0.11387003894895315
loss= 0.11347534250468015
loss= 0.1137963218986988
loss= 0.11436271876096725
loss= 0.1155131296813488
loss= 0.11395142193883658
loss= 0.1119861381687224
backup model
accuracy 93.51854202552857
epoch= 64 / 200
loss= 0.11201952109113336
loss= 0.1114109137840569
loss= 0.11206033961847424
loss= 0.11213434567674994
loss= 0.12420295553281903
loss= 0.12456335777416826
loss= 0.12577856438234447
loss= 0.12980236299335957
loss= 0.13064435217529535
loss= 0.13314325518906117
loss= 0.12145343229174614
loss= 0.11897040225565433
loss= 0.11924180831760169
loss= 0.11752082575112581
loss= 0.11864169470965863
loss= 0.11869669280946255
loss= 0.11489054463803768
loss= 0.11422936499118805
loss= 0.1141942622512579
backup model
accuracy 93.8455453911951
epoch= 65 / 200
loss= 0.11603987425565719
loss= 0.11822128906846047
loss= 0.11815589431673289
loss= 0.11872116032987833
loss= 0.11874543368816376
loss= 0.11927910137921571
loss= 0.11910444539040327
loss= 0.12163933299481869
loss= 0.12185251865535975
loss= 0.12170221470296383
loss= 0.12094371195882558
loss= 0.12112202219665051
loss= 0.11880867552012205
loss= 0.11706971794366837
loss= 0.11367756489664316
loss= 0.11503483261913061
loss= 0.11525265272706747
loss= 0.11520327966660261
loss= 0.11486590929329395
loss= 0.11257968410849571
backup model
accuracy 93.23743035279433
epoch= 66 / 200
loss= 0.11256646580994129
loss= 0.11259460862725973
loss= 0.11282311499118805
loss= 0.11218328412622214
loss= 0.11326382420957089
loss= 0.1129658817872405
loss= 0.11407920770347119
loss= 0.11092413295060397
loss= 0.11126706160604954
loss= 0.10988704156130552
loss= 0.10970144931226969
loss= 0.11053456496447325
loss= 0.11078361850231885
loss= 0.11060634803026914
loss= 0.1091188969090581
loss= 0.10837350949645043
loss= 0.1083390286937356
loss= 0.10929696705192328
loss= 0.10955614671111107
loss= 0.10854343935847283
loss= 0.10863093852996826
loss= 0.1096470734104514
loss= 0.11000416792929173
loss= 0.10892801746726036
loss= 0.10900509230792522
loss= 0.1127899656072259
loss= 0.1127642135694623
loss= 0.11780925430357456
loss= 0.11972901660948992
backup model
accuracy 93.85989509524856
epoch= 67 / 200
loss= 0.11743671726435423
loss= 0.11608018461614847
loss= 0.11282692700624466
loss= 0.11307197496294975
loss= 0.11310006979852914
loss= 0.10999588832259179
loss= 0.11065166629850864
loss= 0.11201680231839418
loss= 0.11258548997342586
loss= 0.11110118985176086
loss= 0.11079007863998414
loss= 0.1112324881181121
loss= 0.11420722655951977
loss= 0.11746800441294908
loss= 0.11694607317447663
loss= 0.1159185665845871
loss= 0.11622423563152552
loss= 0.11623869203031063
loss= 0.11617135904729366
loss= 0.11349598180502653
loss= 0.11174031380563974
backup model
accuracy 93.33361520536063
epoch= 68 / 200
loss= 0.11197379555553198
loss= 0.11164107650518418
loss= 0.11171285398304462
loss= 0.1143868549540639
loss= 0.11342555433511733
loss= 0.11183134399354458
loss= 0.11389851972460746
loss= 0.1135642410442233
loss= 0.11202452648431063
loss= 0.11183207519352437
loss= 0.11398154120892286
loss= 0.11567666906863451
loss= 0.11573798082768917
loss= 0.11398784894496203
loss= 0.11391626585274935
loss= 0.11285544350743294
loss= 0.11225152518600226
loss= 0.11365676518529653
backup model
accuracy 94.36519842518162
epoch= 69 / 200
loss= 0.11631493303924799
loss= 0.11524949911981822
loss= 0.11436762388795614
loss= 0.11416579440236091
loss= 0.11436567842960357
loss= 0.11509208917617798
loss= 0.1150726255774498
loss= 0.11422752071171999
loss= 0.11162610255181789
loss= 0.11071429327130318
loss= 0.10997323546558618
loss= 0.11046071488410235
loss= 0.11042592726647854
loss= 0.11631564628332854
loss= 0.11707507975399495
loss= 0.11921508405357599
loss= 0.11959783289581537
loss= 0.12024154897779227
loss= 0.11948048871010541
loss= 0.11972538355737924
loss= 0.12013242326676846
loss= 0.12069375347346067
backup model
accuracy 93.37399830444113
epoch= 70 / 200
loss= 0.12047472700476647
loss= 0.12067084699869156
loss= 0.12098729979246854
loss= 0.11857943080365657
loss= 0.11790142860263586
loss= 0.11659833598881959
loss= 0.11190697267651557
loss= 0.11094396073371172
loss= 0.11120173074305058
loss= 0.11299784395843744
loss= 0.1134321866557002
loss= 0.11446914684027433
loss= 0.11416934192180633
loss= 0.11238626584410667
loss= 0.10773130331188441
loss= 0.10697464808821679
loss= 0.1074027917161584
loss= 0.10784835066646338
loss= 0.10764912318438291
loss= 0.10850037343800067
loss= 0.10891934212297201
backup model
accuracy 93.32924714335743
epoch= 71 / 200
loss= 0.10939658910036087
loss= 0.11334789004176855
loss= 0.11434638738632202
loss= 0.11598770998418331
loss= 0.1165475195646286
loss= 0.11532466553151607
loss= 0.11547234870493411
loss= 0.11509027075022459
loss= 0.11323843069374562
loss= 0.1125366836413741
loss= 0.11146939162164926
loss= 0.11358424000442029
loss= 0.11390365488827228
loss= 0.11163155782967805
loss= 0.1124357682839036
loss= 0.11253114383667707
loss= 0.11222312673926353
loss= 0.11391663998365402
loss= 0.11450240831822157
loss= 0.11432948358356952
loss= 0.1145871263369918
loss= 0.11465879686176778
loss= 0.11476132195442915
loss= 0.11427281804382801
loss= 0.11268492490053177
loss= 0.11250570949167013
loss= 0.11189550966024399
loss= 0.11243089348077774
loss= 0.11205139294266701
loss= 0.11160937812179327
loss= 0.1115197628363967
loss= 0.11130689289420843
loss= 0.11291566036641598
loss= 0.1138026236370206
backup model
accuracy 93.71920245868762
epoch= 72 / 200
loss= 0.11393401309847832
loss= 0.11332348827272654
loss= 0.1128493158519268
loss= 0.11365954585373401
loss= 0.1137118174880743
loss= 0.11351426102221013
loss= 0.11520929999649525
loss= 0.11624271288514137
loss= 0.11539808515459299
loss= 0.1157151073217392
loss= 0.1165735211968422
loss= 0.11406057395040989
loss= 0.11502930670976638
loss= 0.11632202722132207
loss= 0.11543632362037898
loss= 0.1151563310995698
loss= 0.114583072476089
loss= 0.11440319705754519
loss= 0.11473328605294228
loss= 0.1155591744184494
loss= 0.11658477310091257
loss= 0.11528502929955721
loss= 0.11389570537954569
loss= 0.11259615935385227
loss= 0.1111079303175211
loss= 0.11121143694967031
loss= 0.11026235673576594
loss= 0.11104768335819244
loss= 0.11093905653804541
backup model
accuracy 93.69588916053802
epoch= 73 / 200
loss= 0.11200646802783013
loss= 0.112333301641047
loss= 0.11174481131136417
loss= 0.11246554672718048
loss= 0.11326121103018522
loss= 0.11292791001498699
loss= 0.11342728365212679
loss= 0.11292413149029017
loss= 0.11290094122290611
loss= 0.11171149138361215
loss= 0.10969495881348848
loss= 0.10878824897110462
loss= 0.10862613145262003
loss= 0.10822286270558834
loss= 0.11227171413600445
loss= 0.11474455017596483
loss= 0.11516716968268156
loss= 0.11459903005510569
loss= 0.11667991667985916
loss= 0.11508669059723615
loss= 0.11255078122019768
backup model
accuracy 94.16625912934502
epoch= 74 / 200
loss= 0.11128005769103766
loss= 0.11104566060006618
loss= 0.11128555089235306
loss= 0.1116352017596364
loss= 0.11051215946674348
loss= 0.11042756833136082
loss= 0.10946051899343728
loss= 0.10714920472353696
loss= 0.10738299433141947
loss= 0.10810494970530271
loss= 0.10822793439030648
loss= 0.10799416147172451
loss= 0.10873070877045393
loss= 0.10875166859477758
loss= 0.10854206062853336
loss= 0.10836432415992021
loss= 0.11029896091669798
loss= 0.11132555551826954
loss= 0.11126742750406265
loss= 0.10989135298877954
loss= 0.1091930129006505
backup model
accuracy 94.1684861092447
epoch= 75 / 200
loss= 0.1103891059011221
loss= 0.10729382626712322
loss= 0.10739515267312527
loss= 0.10539115566760301
loss= 0.10916568640619516
loss= 0.11160280272364616
loss= 0.11174855966120958
loss= 0.11538540974259376
loss= 0.1154531168937683
loss= 0.11532524291425944
loss= 0.11612842477858067
loss= 0.11563991252332925
loss= 0.11607177734375
loss= 0.11624421149492264
loss= 0.11654533453285694
loss= 0.11653940767049789
loss= 0.11645391527563334
loss= 0.11758845563977957
loss= 0.11883660458028317
loss= 0.1188387493789196
loss= 0.12018194120377303
loss= 0.11752333015203476
loss= 0.11578927256166935
loss= 0.1142956157028675
loss= 0.11339162915945053
loss= 0.11328947696834803
loss= 0.11359456986188889
loss= 0.11235509227961302
loss= 0.1117588259652257
loss= 0.11081002850085497
backup model
accuracy 93.62353935569782
epoch= 76 / 200
loss= 0.11116329830139876
loss= 0.10968564670532942
loss= 0.10912441749125719
loss= 0.10825004991143942
loss= 0.10757057085633277
loss= 0.10715518414974212
loss= 0.1068383464589715
loss= 0.11033589728176593
loss= 0.11051493305712938
loss= 0.11022102285176516
loss= 0.11201214732602238
loss= 0.11201566463336349
loss= 0.11260530231520534
loss= 0.11281959315761923
loss= 0.11293041298165918
loss= 0.11287697115913034
loss= 0.112843296546489
loss= 0.11466598028317093
loss= 0.11487215941771865
loss= 0.11598085729405284
loss= 0.11506650671362877
loss= 0.1151882017031312
backup model
accuracy 91.19532159880359
epoch= 77 / 200
loss= 0.11428500041365623
loss= 0.11444909639656543
loss= 0.11419303633272648
loss= 0.11411434166133404
loss= 0.11249916017055511
loss= 0.11151314098387957
loss= 0.11185897968709468
loss= 0.10782401703298092
loss= 0.10581987664103508
loss= 0.10623566705733538
loss= 0.1066354376450181
loss= 0.10878212675452233
loss= 0.11013724740594626
loss= 0.11164388775825501
loss= 0.11173335541039706
loss= 0.11107431843876839
loss= 0.11725293606519699
loss= 0.11712892662733793
loss= 0.11589292362332344
loss= 0.11554116822779179
loss= 0.1149210711568594
loss= 0.1128336501866579
backup model
accuracy 92.9684350414142
epoch= 78 / 200
loss= 0.11487051445990801
loss= 0.11561238314956426
loss= 0.11462172538042069
loss= 0.11261952299624682
loss= 0.11248498693108559
loss= 0.10981714114546776
loss= 0.10848071150481702
loss= 0.1080625282227993
loss= 0.11006199542433023
loss= 0.1124082399904728
loss= 0.11186857119202614
loss= 0.11299040403217077
loss= 0.1126534754037857
loss= 0.11333151549100876
loss= 0.10951428025960923
backup model
accuracy 94.05563390282936
epoch= 79 / 200
loss= 0.10976772602647543
loss= 0.10769383203238249
loss= 0.10868461642414332
loss= 0.10861920159310103
loss= 0.10897973138839007
loss= 0.10897382691502572
loss= 0.10868653159588576
loss= 0.10844226408749819
loss= 0.10883327428251505
loss= 0.10892020724713802
loss= 0.10829395581036806
loss= 0.10829456731677055
loss= 0.10825140632689
loss= 0.10815558563917875
loss= 0.10820115588605404
loss= 0.11275378450751304
loss= 0.11368945501744747
loss= 0.1141036743298173
loss= 0.11381388012319803
loss= 0.11362562775611877
loss= 0.11629436697810888
loss= 0.11631657607853413
loss= 0.11752035811543465
loss= 0.11897738460451364
loss= 0.11936593972146511
loss= 0.11647623769938946
loss= 0.11605599831789731
backup model
accuracy 93.68070592972211
epoch= 80 / 200
loss= 0.11746571611613035
loss= 0.11614164005964994
loss= 0.11562118884176016
loss= 0.11525444388389587
loss= 0.11460238356143236
loss= 0.11512778576463462
loss= 0.11435649648308754
loss= 0.11383011374622583
loss= 0.11352659232914447
loss= 0.11325569011271
loss= 0.11288008231669665
loss= 0.11291480593383313
loss= 0.11171701442450285
loss= 0.11440787754952908
loss= 0.11563727106899023
loss= 0.11393213484436274
loss= 0.11180061563849449
loss= 0.11210627976804971
loss= 0.11290127262473107
loss= 0.11741808995604515
loss= 0.11830766282975674
loss= 0.11698024351149798
loss= 0.11441559743136168
loss= 0.11178228139877319
backup model
accuracy 94.06056507260718
epoch= 81 / 200
loss= 0.1079095807299018
loss= 0.10703804094344377
loss= 0.10695249449461698
loss= 0.10699234623461962
loss= 0.10718515325337648
loss= 0.10763591073453427
loss= 0.10859878771007062
loss= 0.10858770690858364
loss= 0.11187273107469081
loss= 0.11221557002514601
loss= 0.11147975008934737
loss= 0.1124120020121336
loss= 0.11130614548921586
loss= 0.10680061418563128
loss= 0.10615944169461727
loss= 0.10977471571415663
loss= 0.11156685762107373
loss= 0.11259771309792996
loss= 0.1134661340713501
loss= 0.11560165893286467
loss= 0.11572961006313562
backup model
accuracy 93.56821322149058
epoch= 82 / 200
loss= 0.11686436485499144
loss= 0.11615819353610277
loss= 0.11525947980582714
loss= 0.11416381862014532
loss= 0.11431841507554054
loss= 0.1142470683529973
loss= 0.11317901268601417
loss= 0.11100436422973871
loss= 0.11235957838594914
loss= 0.11395001526921987
loss= 0.11511901065707207
loss= 0.1161121417582035
loss= 0.11650987617671489
loss= 0.11734411176294088
loss= 0.1176323014497757
loss= 0.11790129359811545
loss= 0.11757773377001285
loss= 0.11579913530498744
loss= 0.11514434047043323
loss= 0.11498694643378257
loss= 0.11422614134848118
loss= 0.1149410480633378
loss= 0.11322319064289331
loss= 0.11204329211264849
loss= 0.11119314577430486
loss= 0.11224063411355019
loss= 0.11090646713972091
loss= 0.11082743994891643
loss= 0.11082275196909905
loss= 0.10939618770033122
loss= 0.10866729412227868
loss= 0.10755044247955084
loss= 0.106822275146842
backup model
accuracy 92.99549284719508
epoch= 83 / 200
loss= 0.10938880193978548
loss= 0.10908006325364113
loss= 0.10819348350167274
loss= 0.1084479920193553
loss= 0.10847077544778586
loss= 0.10929465867578983
loss= 0.10919101059436798
loss= 0.10919838916510344
loss= 0.10953751973807811
loss= 0.11000015690922738
loss= 0.10962460774928331
loss= 0.10971464145928621
loss= 0.10981984570622444
loss= 0.11015269171446562
loss= 0.1109450263157487
loss= 0.11023796696215868
loss= 0.11120701521635055
loss= 0.1110042143240571
loss= 0.10974215745925903
loss= 0.10945089172571898
loss= 0.10948841076344251
loss= 0.10757730811834336
loss= 0.10829442642629146
loss= 0.10824053715914488
loss= 0.10852727483958007
loss= 0.10874263942241669
loss= 0.1101697413623333
loss= 0.11028205294162036
loss= 0.11142530914396048
backup model
accuracy 93.60710742543817
epoch= 84 / 200
loss= 0.11645108316093683
loss= 0.11462793126702309
loss= 0.11464241839945316
loss= 0.11544041316956281
loss= 0.11268560945987702
loss= 0.1119605566188693
loss= 0.11217259809374809
loss= 0.1119968843460083
loss= 0.10877022501081228
loss= 0.10886164609342813
loss= 0.11172350134700537
loss= 0.11060646641999483
loss= 0.11063526954501868
loss= 0.11079998277127742
loss= 0.11085497435182333
loss= 0.11123036656528712
loss= 0.11006163518875837
loss= 0.10967096038162709
loss= 0.10917270213365554
loss= 0.11226134281605482
loss= 0.11198479428887367
loss= 0.11128521632403135
backup model
accuracy 93.3947776176049
epoch= 85 / 200
loss= 0.11149372614920139
loss= 0.11249622605741023
loss= 0.11169150073081255
loss= 0.11098043538630009
loss= 0.10833294250071049
loss= 0.11143499173223972
loss= 0.1113555321842432
loss= 0.1120869917795062
loss= 0.1115447186678648
loss= 0.1108419854938984
loss= 0.1116776216775179
loss= 0.1117876809835434
loss= 0.11030580163002014
loss= 0.10909537971019745
loss= 0.1094892681017518
loss= 0.10933216374367476
loss= 0.10923754375427962
loss= 0.1097873766720295
loss= 0.10952704235911369
loss= 0.11253308199346065
loss= 0.11164679288864136
loss= 0.11020792912691832
loss= 0.10995505195111037
loss= 0.11174132753163576
backup model
accuracy 93.65985185366172
epoch= 86 / 200
loss= 0.11325349740684032
loss= 0.11253319997340441
loss= 0.11112817440181971
loss= 0.11115425139665604
loss= 0.1115567347034812
loss= 0.11265303038060664
loss= 0.10939667209982872
loss= 0.10959490898996592
loss= 0.11027462124824523
loss= 0.11082636404782534
loss= 0.1132001980021596
loss= 0.11065640561282634
loss= 0.10981813464313746
loss= 0.10993784826248884
loss= 0.11003511764109135
loss= 0.11070365209132432
loss= 0.10897246230393648
loss= 0.11176641523838043
backup model
accuracy 93.05310163579945
epoch= 87 / 200
loss= 0.11376705091446639
loss= 0.11271964929997921
loss= 0.11286861192435026
loss= 0.1140470365062356
loss= 0.11458340052515269
loss= 0.11414762146770954
loss= 0.11417422316968441
loss= 0.1120183914527297
loss= 0.11181811567395926
loss= 0.11195383686572313
loss= 0.1098902129009366
loss= 0.10951042260974646
loss= 0.10907376155257226
loss= 0.11024268448352814
loss= 0.10997584901750088
loss= 0.11496430691331624
loss= 0.11540852725505829
loss= 0.11162415944039822
loss= 0.11166905246675014
loss= 0.11198205150663852
loss= 0.11213816486299039
loss= 0.11158266961574555
loss= 0.11118284340947866
loss= 0.1111218698695302
loss= 0.11145323600620032
backup model
accuracy 93.60437142156144
epoch= 88 / 200
loss= 0.11085961781442165
loss= 0.10826233983039855
loss= 0.10932741712778807
loss= 0.10942678667604923
loss= 0.10953893698751926
loss= 0.11089832801371813
loss= 0.11163521774113178
loss= 0.11208471760153771
loss= 0.11473833665251731
loss= 0.11631472777575254
loss= 0.11664924934506417
loss= 0.11457068592309952
loss= 0.11396967321634292
loss= 0.11376808188855649
loss= 0.11332670006901026
loss= 0.11238179244101047
loss= 0.10673309024423361
loss= 0.1103277963027358
loss= 0.1104291121289134
backup model
accuracy 93.71996281325336
epoch= 89 / 200
loss= 0.11134435433894396
loss= 0.11043765101581812
loss= 0.11035677183419466
loss= 0.10913386952131987
loss= 0.10905825469642877
loss= 0.10962626855820418
loss= 0.11009788110852242
loss= 0.11073966931551694
loss= 0.10895659726113081
loss= 0.11382480882108212
loss= 0.11389395479112864
loss= 0.11106620728969574
loss= 0.11060697551816702
loss= 0.11061545126140118
loss= 0.11066335257142783
loss= 0.10977386713027953
loss= 0.10950841933488846
loss= 0.10959443029016257
loss= 0.10948660161346196
loss= 0.10963174104690551
loss= 0.10947286184877157
loss= 0.10878223966807127
loss= 0.10643259026110172
loss= 0.10557877197861672
loss= 0.10539360824972391
loss= 0.10672610104084015
loss= 0.10666745197027921
loss= 0.10594362966716289
backup model
accuracy 94.11076756234526
epoch= 90 / 200
loss= 0.10689214002341033
loss= 0.10415730234235525
loss= 0.10410062357783317
loss= 0.10553704027086497
loss= 0.10557465266436339
loss= 0.10608762733638287
loss= 0.10755817390978337
loss= 0.10773022569715977
loss= 0.10759221609681845
loss= 0.10934941694140435
loss= 0.10877908021211624
loss= 0.1091198318824172
loss= 0.10843126326799393
loss= 0.10970703773200512
loss= 0.11285090893507004
loss= 0.11327618476003408
loss= 0.11443535424768925
loss= 0.11390242587774992
loss= 0.11440583277493716
loss= 0.1137940176203847
loss= 0.11410119969397783
loss= 0.11582844816148281
loss= 0.1157531164214015
loss= 0.11337376970797777
backup model
accuracy 93.4559304856496
epoch= 91 / 200
loss= 0.1109152801334858
loss= 0.11078348327428103
loss= 0.11090281832963228
loss= 0.107892363704741
loss= 0.1071803069859743
loss= 0.10660766988992691
loss= 0.10721088573336601
loss= 0.10691958624869585
loss= 0.10547848209738732
loss= 0.10624308694154024
loss= 0.10624120898544788
loss= 0.10640945900231599
loss= 0.10568199146538973
loss= 0.10594895001500845
loss= 0.10620763480663299
loss= 0.10763870447874069
loss= 0.10711996931582689
loss= 0.10760475602000952
loss= 0.10608019731938839
loss= 0.10670898001641035
loss= 0.1061295011639595
loss= 0.1058993673324585
loss= 0.10551140110939741
loss= 0.10828117441385984
loss= 0.10852991174906493
loss= 0.10988470524549485
loss= 0.11307222988456488
backup model
accuracy 92.57393350568886
epoch= 92 / 200
loss= 0.11635597869753837
loss= 0.11625587180256844
loss= 0.11616447675973177
loss= 0.11628588031977415
loss= 0.11604884959757328
loss= 0.11595493160188199
loss= 0.11636488132178784
loss= 0.11902490168809891
loss= 0.11663079917430878
loss= 0.11479266732931137
loss= 0.11423630084842444
loss= 0.113552354760468
loss= 0.11073294442147016
loss= 0.11115851022303104
loss= 0.11109074976295233
loss= 0.11085831005126238
loss= 0.11162455320358276
loss= 0.11141716655343771
loss= 0.10915240287780761
loss= 0.10843678701668978
loss= 0.10752392906695604
loss= 0.10770081114023924
loss= 0.10767376519739628
loss= 0.10684247203171253
loss= 0.1073624350130558
backup model
accuracy 93.94599650096919
epoch= 93 / 200
loss= 0.10938657887279987
loss= 0.11003974113613367
loss= 0.10983448673039675
loss= 0.10993043642491102
loss= 0.10849055375903845
loss= 0.10881328653544188
loss= 0.10923918716609478
loss= 0.10777564201503992
loss= 0.10612576030194759
loss= 0.10787477500736714
loss= 0.10778996996581554
loss= 0.10766328871250153
loss= 0.10841124918311834
loss= 0.10788154315203428
loss= 0.10794654432684184
loss= 0.10735172029584646
loss= 0.10729615624994039
loss= 0.10744812343269587
loss= 0.10555781841278077
loss= 0.10489496167749167
loss= 0.10460396330803633
loss= 0.10333807319402695
loss= 0.10281274393200875
loss= 0.10296519845724106
loss= 0.10471987903118134
loss= 0.10451261341571808
loss= 0.1032298481464386
loss= 0.10372719898819924
loss= 0.10592773020267486
backup model
accuracy 93.71916587258926
epoch= 94 / 200
loss= 0.10809380374848843
loss= 0.10851035967469215
loss= 0.10651782512664795
loss= 0.10601338788866997
loss= 0.10650624055415392
loss= 0.10755852736532688
loss= 0.10859855573624372
loss= 0.10874226097017527
loss= 0.10912997491657733
loss= 0.10804138723760844
loss= 0.10754116345196962
loss= 0.10742593199014663
loss= 0.10727468550205231
loss= 0.10737147901207209
loss= 0.1083532078191638
loss= 0.10683836989104747
loss= 0.10659637674689293
loss= 0.10673496149480342
loss= 0.10666539788246154
loss= 0.10782829083502293
loss= 0.10704269040375948
backup model
accuracy 93.81353255513747
epoch= 95 / 200
loss= 0.1078721559792757
loss= 0.10722800645977258
loss= 0.10709942508488894
loss= 0.10702079918235541
loss= 0.10764385879039765
loss= 0.10823701530694961
loss= 0.10900534179061651
loss= 0.10915592957288027
loss= 0.11194372445344924
loss= 0.11178915947675705
loss= 0.11201311718672514
loss= 0.11089538507163525
loss= 0.1096506854519248
loss= 0.10882173161953687
loss= 0.10764387995004654
loss= 0.10671179167926312
loss= 0.10683658212423325
loss= 0.10643446240574121
loss= 0.10685694929212332
loss= 0.1194543868303299
loss= 0.12314271215349436
loss= 0.1253984959423542
loss= 0.12642579294741155
loss= 0.1264948556944728
backup model
accuracy 93.78308496780933
epoch= 96 / 200
loss= 0.12847539722919465
loss= 0.13010864187031984
loss= 0.11669958967715502
loss= 0.1181337932869792
loss= 0.11662626348435878
loss= 0.11651952475309373
loss= 0.11550938006490469
loss= 0.11685946576297283
loss= 0.11474850583821534
loss= 0.11323403052985669
loss= 0.10902093470096588
loss= 0.11167868070304393
loss= 0.112194171436131
backup model
accuracy 94.07014108617572
epoch= 97 / 200
loss= 0.10758732069283723
loss= 0.10441009279340506
loss= 0.10493241209536791
loss= 0.10484449818730354
loss= 0.10504022970795632
loss= 0.10524191550910472
loss= 0.1083603110536933
loss= 0.10910848222672939
loss= 0.11038619939237833
loss= 0.11056061621755361
loss= 0.11072769563645124
loss= 0.1104571633040905
loss= 0.11021915767341853
loss= 0.10850650567561387
loss= 0.10879953935742379
loss= 0.10832637164741754
loss= 0.10520890913903713
loss= 0.10463034190237522
loss= 0.10606184028089047
loss= 0.1059812930971384
loss= 0.10609139684587716
loss= 0.10600082334131003
loss= 0.11234473381191493
loss= 0.11379354424774647
loss= 0.11364184122532606
loss= 0.11225828021764755
loss= 0.11256521489471197
loss= 0.11276689652353525
loss= 0.1124436169117689
loss= 0.11184759087860584
loss= 0.11000924866646528
backup model
accuracy 94.14640242213969
epoch= 98 / 200
loss= 0.10684099834412336
loss= 0.10479408003389835
loss= 0.10267421260476112
loss= 0.10179050054401159
loss= 0.10039296086877585
loss= 0.10094243850558997
loss= 0.10184164609760046
loss= 0.10374720603227615
loss= 0.10410545289516449
loss= 0.1033410232886672
loss= 0.10333549804985523
loss= 0.104410151951015
loss= 0.10493438217788935
loss= 0.10505778182297945
loss= 0.10557144150137901
loss= 0.10570365618914365
loss= 0.10612234707921743
loss= 0.10712737463414669
loss= 0.10695633202791215
loss= 0.10809024844318628
loss= 0.10850967433303595
loss= 0.108809476159513
loss= 0.10850520480424165
loss= 0.10865956861525775
loss= 0.10835633251816035
loss= 0.10808701738715172
loss= 0.10831577941775322
loss= 0.10660293851047754
backup model
accuracy 94.06694377931979
epoch= 99 / 200
loss= 0.10536089889705182
loss= 0.10572981264442205
loss= 0.10407622881233693
loss= 0.10424690969288349
loss= 0.1035945925861597
loss= 0.10308403670787811
loss= 0.10450074393302203
loss= 0.10399110075086355
loss= 0.10641041569411755
loss= 0.10547636207193137
loss= 0.10574625629931689
loss= 0.10603213738650083
loss= 0.10747012931853533
loss= 0.1064951490983367
loss= 0.10579978194087744
loss= 0.10532043047249318
loss= 0.11183246713131666
loss= 0.1116759581118822
loss= 0.11043289508670569
loss= 0.11070270422846079
backup model
accuracy 93.86988150939862
epoch= 100 / 200
loss= 0.10880112882703542
loss= 0.10707289386540651
loss= 0.1071876609325409
loss= 0.10502943824976682
loss= 0.10468708716332913
loss= 0.10491271663457155
loss= 0.10451276261359453
loss= 0.1039017854258418
loss= 0.1038649544864893
loss= 0.1041015087068081
loss= 0.10412161622196436
loss= 0.10478073060512542
loss= 0.10204068548977376
loss= 0.10111024729907513
loss= 0.10197435904294253
loss= 0.10250913977622986
loss= 0.1038680361956358
loss= 0.10424698047339916
loss= 0.1057929402589798
loss= 0.10634315513074398
loss= 0.10691168427467346
loss= 0.10691169258207082
loss= 0.10570207674056292
loss= 0.10528405714780092
loss= 0.10523230291903019
loss= 0.10407082304358482
loss= 0.10397291626781226
loss= 0.10582034338265657
loss= 0.10710315197706223
loss= 0.10650235872715712
loss= 0.10625990923494101
backup model
accuracy 94.25805365010913
epoch= 101 / 200
loss= 0.11015866689383984
loss= 0.11010194823145866
loss= 0.10688541065901518
loss= 0.10190711185336113
loss= 0.10188135765492916
loss= 0.102163308262825
loss= 0.10506275329738855
loss= 0.10490194469690323
loss= 0.10684813857078553
loss= 0.10813204407691955
loss= 0.108746059499681
loss= 0.10908700380474329
loss= 0.10937546040862799
loss= 0.11009830992668868
loss= 0.10869674615561963
loss= 0.10755161110311746
loss= 0.10364161755889655
loss= 0.10461104065179824
loss= 0.10276546217501163
loss= 0.10274381849914789
loss= 0.10245883282274008
backup model
accuracy 94.24427182593008
epoch= 102 / 200
loss= 0.10058139752596616
loss= 0.10061411049216985
loss= 0.10124798268079757
loss= 0.10330188482999801
loss= 0.10390784405171871
loss= 0.10463299207389355
loss= 0.10418151039630175
loss= 0.10422926571220159
loss= 0.10403360806405544
loss= 0.10350469373166561
loss= 0.10336903844028711
loss= 0.10391715172678233
loss= 0.10422268338501453
loss= 0.10446625918149949
loss= 0.10509471759200097
loss= 0.10257764786481857
loss= 0.10127988636493683
loss= 0.10569426562637091
loss= 0.10409403290599585
loss= 0.108543044552207
backup model
accuracy 93.63088043586706
epoch= 103 / 200
loss= 0.10905905012041331
loss= 0.10997026730328799
loss= 0.10817375220358372
loss= 0.10509831048548221
loss= 0.10459735214710236
loss= 0.10373302523046732
loss= 0.10448974978178739
loss= 0.10401888225227594
loss= 0.10412221901118755
loss= 0.10446094274520874
loss= 0.10417201463133097
loss= 0.10409989025443793
loss= 0.10347293484956026
loss= 0.10700621861964464
loss= 0.10714860409498214
loss= 0.10759320173412562
loss= 0.1075429629534483
loss= 0.10639613069593906
loss= 0.1059659568592906
loss= 0.10721347767859697
loss= 0.10469758301973343
backup model
accuracy 94.38668878121335
epoch= 104 / 200
loss= 0.1038875849917531
loss= 0.1043300686404109
loss= 0.10485074359923602
loss= 0.10444412294775247
loss= 0.10230815954506398
loss= 0.10443005330860615
loss= 0.10457407016307116
loss= 0.10477506376802921
loss= 0.10412228342145681
loss= 0.10277922103181482
loss= 0.10299781100824475
loss= 0.1032776584289968
loss= 0.10282198818400502
loss= 0.1033285311050713
loss= 0.10343935361132026
loss= 0.10346142718568445
loss= 0.10373472558334469
loss= 0.10299329217523337
backup model
accuracy 93.73355216274108
epoch= 105 / 200
loss= 0.10384795475751162
loss= 0.10399031154811382
loss= 0.10301082365214825
loss= 0.10367874391376972
loss= 0.10324285767972469
loss= 0.10392197851091624
loss= 0.10605269446969032
loss= 0.10501288320869208
loss= 0.10478322967886924
loss= 0.10590848181396723
loss= 0.10609297942370176
loss= 0.10599628031253815
loss= 0.10579808741807938
loss= 0.10426157604902983
loss= 0.10387258429080248
loss= 0.10438778836280108
loss= 0.10574566408991813
loss= 0.10688232492655515
backup model
accuracy 94.391312945905
epoch= 106 / 200
loss= 0.1079835157468915
loss= 0.10597416706383228
loss= 0.10676259875297546
loss= 0.10501137509942055
loss= 0.10610251795500517
loss= 0.10566414285451174
loss= 0.10566896677017212
loss= 0.1045600575953722
loss= 0.10256624635308981
loss= 0.09938144259154796
loss= 0.1005116081610322
loss= 0.10176041435450316
loss= 0.10192555651068687
loss= 0.10078791495412588
loss= 0.10427462961524725
loss= 0.10415609169751405
loss= 0.1038004032149911
loss= 0.10339846141636372
loss= 0.10418421600013972
loss= 0.1037250715866685
backup model
accuracy 94.43842629638226
epoch= 107 / 200
loss= 0.10649155486375093
loss= 0.10644728560000657
loss= 0.11297970123589039
loss= 0.11307395305484533
loss= 0.11302447773516178
loss= 0.11301096305251121
loss= 0.11190573077648878
loss= 0.11179805360734463
loss= 0.11303415931761265
loss= 0.11178167931735515
loss= 0.10804162826389074
loss= 0.10844721525907516
loss= 0.10794902943074704
loss= 0.10785363495349884
loss= 0.10561863578855991
loss= 0.10950764670968055
loss= 0.11022784352302552
loss= 0.11242204815149308
loss= 0.11265689257532358
loss= 0.1123066833987832
loss= 0.11269677732139825
loss= 0.11388664137572051
loss= 0.11418028198182582
loss= 0.11462256494909524
loss= 0.11135356537997723
loss= 0.11123284548521042
loss= 0.1082745335996151
backup model
accuracy 94.14189278784288
epoch= 108 / 200
loss= 0.10622281424701213
loss= 0.10428568966686726
loss= 0.10292718939483166
loss= 0.10220138013362884
loss= 0.10240633696317673
loss= 0.10354065656661987
loss= 0.10399539560079575
loss= 0.10420161485671997
loss= 0.103572381362319
loss= 0.10298514191061259
loss= 0.10306413348764182
loss= 0.10332126006484031
loss= 0.10525954492390156
loss= 0.10479304019361735
loss= 0.10318074561655521
loss= 0.1033844018355012
loss= 0.10413977324962616
loss= 0.10587538283318282
loss= 0.10601418618112803
loss= 0.1059101378545165
loss= 0.10564982622861863
loss= 0.10520307302474975
loss= 0.10509676400572061
loss= 0.10553041588515043
backup model
accuracy 94.51176074447811
epoch= 109 / 200
loss= 0.10405681151896715
loss= 0.10302169132977725
loss= 0.10199330221861601
loss= 0.10294291209429503
loss= 0.10624477207660675
loss= 0.10815149862319232
loss= 0.10589372847229242
loss= 0.10805884558707475
loss= 0.1066371976211667
loss= 0.10646494206041097
loss= 0.10630056615918874
loss= 0.10487277049571275
loss= 0.10396389700472355
loss= 0.10412708275020123
loss= 0.10443681832402944
backup model
accuracy 92.75667947625504
epoch= 110 / 200
loss= 0.10727339714765549
loss= 0.10803368784487248
loss= 0.10828183863312006
loss= 0.10937878627330065
loss= 0.11172292377799749
loss= 0.13891661297529936
loss= 0.13932999461889267
loss= 0.1390441567823291
loss= 0.13832527354359628
loss= 0.11430417399853468
loss= 0.11359906505793332
loss= 0.10727523941546678
loss= 0.10658189848065376
loss= 0.10427060633897782
loss= 0.10425660494714975
loss= 0.10444605845957994
loss= 0.10435188364237546
loss= 0.10436659812927246
loss= 0.1066746947914362
loss= 0.10821684684604406
loss= 0.10724216658622027
backup model
accuracy 93.88686064043361
epoch= 111 / 200
loss= 0.10844150453805923
loss= 0.10963478103280068
loss= 0.11013404689729214
loss= 0.1079924901202321
loss= 0.1079688835889101
loss= 0.10834936544299126
loss= 0.10811844553798437
loss= 0.10638618778437375
loss= 0.10620252929627895
loss= 0.10547001238912344
loss= 0.10511952079832554
loss= 0.10412184532731772
loss= 0.10499933905899525
loss= 0.10494273982942104
loss= 0.10347347892820835
loss= 0.10364705361425877
loss= 0.10281838893890381
loss= 0.10294781915843487
loss= 0.10303967136889697
loss= 0.10502543538808823
loss= 0.10663323182612658
loss= 0.10586436845362186
loss= 0.10580555491149425
loss= 0.10443276807665824
loss= 0.10556606478989124
backup model
accuracy 94.04008799242979
epoch= 112 / 200
loss= 0.10907043665647506
loss= 0.10727008149027824
loss= 0.10564651116728782
loss= 0.10532754879444838
loss= 0.10542509511113167
loss= 0.10506670068949461
loss= 0.10509621053934097
loss= 0.10463622864335775
loss= 0.10470287561416626
loss= 0.10520638108253479
loss= 0.1054674980044365
loss= 0.10316029999405146
loss= 0.1031296456605196
loss= 0.10334967765957118
loss= 0.10275365050882102
loss= 0.10399238180369139
loss= 0.10460102446377277
loss= 0.10457131050527096
loss= 0.10421046793460846
loss= 0.10472175151109696
loss= 0.10457910120487213
loss= 0.10538073617964983
loss= 0.10523446664214134
loss= 0.1032973663881421
loss= 0.10232656359672547
loss= 0.10138041295111179
loss= 0.1020607889443636
loss= 0.10239523962140083
backup model
accuracy 94.38095748937158
epoch= 113 / 200
loss= 0.10207760646939278
loss= 0.10345091961324215
loss= 0.10311354592442512
loss= 0.10301623452454806
loss= 0.10344497531652451
loss= 0.10235331188887357
loss= 0.1047642144188285
loss= 0.10330501690506935
loss= 0.1036445215716958
loss= 0.10406839616596698
loss= 0.10468424197286368
loss= 0.10326462648808957
loss= 0.10324866529554129
loss= 0.1028275017812848
loss= 0.10256498973816633
loss= 0.1021086947619915
loss= 0.10234096065163613
loss= 0.10246719717979431
loss= 0.10068095482885837
loss= 0.10263916481286288
backup model
accuracy 94.40231899870912
epoch= 114 / 200
loss= 0.10352317705750465
loss= 0.10456917945295573
loss= 0.10316687073558568
loss= 0.10310308899730444
loss= 0.1030445283651352
loss= 0.10291824951767921
loss= 0.10509578473865985
loss= 0.10435432173311711
loss= 0.10285451151430607
loss= 0.10318194463849067
loss= 0.10363961406052112
loss= 0.10376861102879048
loss= 0.10290032364428044
loss= 0.10258038774132729
loss= 0.10087512165307999
loss= 0.10200533624738455
loss= 0.10301714926958085
loss= 0.10350589100271464
loss= 0.10232539720833302
loss= 0.10188033301383256
loss= 0.10215325888246297
loss= 0.10220066767185926
loss= 0.10179401896893978
loss= 0.10342257034033536
loss= 0.10405209138989449
loss= 0.10487735319882631
backup model
accuracy 93.97469113697632
epoch= 115 / 200
loss= 0.1063092752173543
loss= 0.10613619051873684
loss= 0.1060699376091361
loss= 0.10394901413470507
loss= 0.10429964784532786
loss= 0.10232558857649565
loss= 0.10305140271782876
loss= 0.1047764514014125
loss= 0.10604130253195762
loss= 0.10479511212557555
loss= 0.10435312703251838
loss= 0.10403856582939625
loss= 0.10263391200453043
loss= 0.10530693236738443
loss= 0.10441676206886769
loss= 0.10543036889284849
loss= 0.10488952212035656
backup model
accuracy 93.76505438412171
epoch= 116 / 200
loss= 0.10765331763774157
loss= 0.10790807515382767
loss= 0.10765891969203949
loss= 0.10843385014683009
loss= 0.10828485451638699
loss= 0.10820312883704901
loss= 0.10822377271950245
loss= 0.10972056452184915
loss= 0.10908037718385458
loss= 0.10973870377987623
loss= 0.10958797387778758
loss= 0.10699321016669273
loss= 0.10592613201588393
loss= 0.10540827348828316
loss= 0.10396107196807862
loss= 0.10307019621133805
loss= 0.1030549045279622
loss= 0.10244477819651365
loss= 0.10249095771461725
loss= 0.10341370820999146
loss= 0.10317532811313868
loss= 0.10315804447978735
loss= 0.10302335891872644
loss= 0.10334298357367516
loss= 0.10325957961380482
loss= 0.10355548832565546
loss= 0.1029434597864747
loss= 0.1024865797534585
loss= 0.10048609804362059
loss= 0.1001665960997343
loss= 0.10107683580368758
loss= 0.10103060826659202
loss= 0.09980933211743831
loss= 0.10056021019816398
loss= 0.10030587114393712
backup model
accuracy 94.67629479156486
epoch= 117 / 200
loss= 0.10140951380133628
loss= 0.1039498232677579
loss= 0.1042169725522399
loss= 0.10408857136964798
loss= 0.10511281736195087
loss= 0.10422323994338513
loss= 0.1052632747963071
loss= 0.1045668314397335
loss= 0.10188024327158927
loss= 0.10003625709563493
loss= 0.1000053395330906
loss= 0.1004101425781846
loss= 0.09960181206464767
loss= 0.09989609532058238
loss= 0.09949992910027504
loss= 0.100664137378335
loss= 0.10141579266637564
loss= 0.10138726528733968
loss= 0.1009951014444232
loss= 0.10061154089868068
loss= 0.1003831136226654
loss= 0.10248302936553955
backup model
accuracy 94.03805189652154
epoch= 118 / 200
loss= 0.10543294925242662
loss= 0.10616431411355734
loss= 0.10533452443778515
loss= 0.10470438148826361
loss= 0.10425334073603153
loss= 0.10453847281634808
loss= 0.10388192854821682
loss= 0.10354815103113651
loss= 0.10102984957396983
loss= 0.10081186957657337
loss= 0.10099127430468798
loss= 0.10134386461228133
loss= 0.10103410705924035
loss= 0.10419935289770364
loss= 0.10382676672190427
loss= 0.10748551223427057
loss= 0.10740319047123194
loss= 0.10756737254559993
loss= 0.10547311827540398
loss= 0.10523472495377063
backup model
accuracy 94.69088787270735
epoch= 119 / 200
loss= 0.10299361631274223
loss= 0.10285168167203665
loss= 0.10292356666177511
loss= 0.10315017610788345
loss= 0.10602642349898815
loss= 0.10703722093254328
loss= 0.10760537285357713
loss= 0.1076482754573226
loss= 0.10914453618228435
loss= 0.10587525259703398
loss= 0.10451792892068625
loss= 0.1046900012716651
loss= 0.10225766766816377
loss= 0.10219017580151558
loss= 0.10223158411681652
loss= 0.10051352303475142
loss= 0.1003789223358035
loss= 0.10036206565797329
loss= 0.10006314678117632
loss= 0.10040746064856648
loss= 0.0995679677836597
loss= 0.09851701902225614
loss= 0.09949502093717456
loss= 0.09970047837123275
loss= 0.0998777431435883
backup model
accuracy 94.25712149995114
epoch= 120 / 200
loss= 0.09967547276988625
loss= 0.09983133938163519
loss= 0.09927548296749591
loss= 0.09904484499245882
loss= 0.10000809971243144
loss= 0.10077600196003914
loss= 0.10106638044118882
loss= 0.10198749590665102
loss= 0.1022401724010706
loss= 0.10183092042803764
loss= 0.10750851586461067
loss= 0.10677644468843937
loss= 0.10807038985192775
loss= 0.10795565815642476
loss= 0.10606116062030196
loss= 0.10551798330619931
loss= 0.10114744512364268
loss= 0.10113639993593097
loss= 0.09952818756923079
loss= 0.09900572398677468
loss= 0.10009077541530133
loss= 0.10087381463497877
loss= 0.10058106400072575
loss= 0.10092508550733328
loss= 0.10088620085269212
loss= 0.1029117824882269
backup model
accuracy 92.70899188310366
epoch= 121 / 200
loss= 0.10636338111013174
loss= 0.10628431148827076
loss= 0.10664013687521219
loss= 0.10795371823012828
loss= 0.10849364466965199
loss= 0.10825814690440894
loss= 0.10699631657451392
loss= 0.10529743369668722
loss= 0.1052885214239359
loss= 0.10219066895544529
loss= 0.10420845847576857
loss= 0.10401022467762232
loss= 0.1031470312550664
loss= 0.10270778838545085
loss= 0.10256564620882273
loss= 0.10350655045360327
loss= 0.10387520756572485
loss= 0.1024054543301463
loss= 0.10391297832131385
loss= 0.1025347701832652
loss= 0.10197398874908686
loss= 0.10332213327288628
loss= 0.10290017306804657
loss= 0.10135824993252754
loss= 0.10149311073124409
loss= 0.10169482853263617
loss= 0.10121461618691682
loss= 0.10207963269203901
loss= 0.09924742665607482
backup model
accuracy 94.55214225285867
epoch= 122 / 200
loss= 0.10105394050944597
loss= 0.10207071885932237
loss= 0.10453332673758269
loss= 0.10786034151911736
loss= 0.10758132673799992
loss= 0.10726656522601843
loss= 0.10694455675780773
loss= 0.10717753048986196
loss= 0.10757233913987875
loss= 0.10651441194117069
loss= 0.10537105971947312
loss= 0.10518798446282744
loss= 0.10243152229115367
loss= 0.10299308167770505
loss= 0.10307371621951461
loss= 0.10145361017435789
backup model
accuracy 94.10045982680968
epoch= 123 / 200
loss= 0.10098978009074927
loss= 0.09993897397071123
loss= 0.09963075373321771
loss= 0.09976282540708781
loss= 0.09943100556731224
loss= 0.09992881760001182
loss= 0.09913950107991695
loss= 0.09904123164713383
loss= 0.10179960183799266
loss= 0.10455194640904665
loss= 0.10598190773278475
loss= 0.10474318701773883
loss= 0.10489137090742588
loss= 0.102118025906384
loss= 0.10243534084409475
loss= 0.10182454988360405
loss= 0.10138056699186564
loss= 0.09962355483323336
loss= 0.10457180909812451
loss= 0.10661596685647964
loss= 0.10624703217297793
loss= 0.1061606388911605
backup model
accuracy 94.4413595470501
epoch= 124 / 200
loss= 0.1087008273601532
loss= 0.10844305355101824
loss= 0.10602550808340311
loss= 0.10716108106076717
loss= 0.1059973281249404
loss= 0.10494314424693585
loss= 0.10487658705562353
loss= 0.10425253700464963
loss= 0.10378216933459043
loss= 0.1035789094492793
loss= 0.10345717210322619
loss= 0.10369886558502912
loss= 0.10306009292602539
loss= 0.10133297007530928
loss= 0.10143890805542469
loss= 0.1006452914327383
loss= 0.10173037182539701
loss= 0.10115634620189667
loss= 0.10198612216860056
loss= 0.1016951396688819
loss= 0.10274695917963982
loss= 0.1033496792986989
loss= 0.10403464250266552
loss= 0.10415294792503119
loss= 0.10407134752720594
loss= 0.10683225467801094
loss= 0.1041185724362731
loss= 0.10462219942361116
loss= 0.10431885469704866
backup model
accuracy 93.90737589740927
epoch= 125 / 200
loss= 0.10158062819391489
loss= 0.10240451138466597
loss= 0.10225757330656052
loss= 0.10229123812168836
loss= 0.10381839063018561
loss= 0.10390848360955715
loss= 0.10375806625932454
loss= 0.10363373048603534
loss= 0.10262123174965382
loss= 0.1006599585339427
loss= 0.09974259484559297
loss= 0.09997225016355514
loss= 0.09997913241386414
loss= 0.10159179028123617
loss= 0.10178421717137098
loss= 0.10105485014617444
loss= 0.10364028006792068
loss= 0.102852095477283
loss= 0.10134474013000727
loss= 0.10166583508253098
loss= 0.10139651706442238
loss= 0.09919714665040374
loss= 0.09899820810183883
loss= 0.10095376944169403
loss= 0.10199618821963669
backup model
accuracy 94.32680370101153
epoch= 126 / 200
loss= 0.10142044289037586
loss= 0.10243500484153628
loss= 0.10309290742501616
loss= 0.10442153917625546
loss= 0.10442663324996829
loss= 0.1045515443943441
loss= 0.10456220576539636
loss= 0.1045707505196333
loss= 0.10651980035007
loss= 0.10706479974091053
loss= 0.10323273357003927
loss= 0.10327899485826492
loss= 0.10512784834951162
loss= 0.10383410446345806
loss= 0.1026614287123084
loss= 0.10156224209815264
loss= 0.10342974472790957
loss= 0.10327539905905724
loss= 0.10204147413372994
loss= 0.10240260269492865
backup model
accuracy 93.97882218469019
epoch= 127 / 200
loss= 0.10340412139892578
loss= 0.10323464769870043
loss= 0.10359077095985413
loss= 0.10423933248966932
loss= 0.10404510322958231
loss= 0.10539589256048203
loss= 0.10578554686158896
loss= 0.10599209111183881
loss= 0.1057628408446908
loss= 0.10542429182678462
loss= 0.10324611362069845
loss= 0.10226704627275467
loss= 0.10584065645933151
loss= 0.10700996354222297
loss= 0.10756446171551942
loss= 0.10541230525821448
loss= 0.10311302691698074
loss= 0.10364534411579371
loss= 0.10382995899766684
backup model
accuracy 94.30039331010148
epoch= 128 / 200
loss= 0.1018093258049339
loss= 0.10098169687204063
loss= 0.1027500271704048
loss= 0.10270389861427248
loss= 0.101505012428388
loss= 0.10300727429799736
loss= 0.1020029182266444
loss= 0.10262556809000671
loss= 0.10252606968395411
loss= 0.10379464197903872
loss= 0.10479216374456883
loss= 0.10484221443533898
loss= 0.10435328744351864
loss= 0.1039489808678627
loss= 0.10354916900396346
loss= 0.10381541348993778
loss= 0.10198668792843818
loss= 0.1019933681935072
loss= 0.10142854791134596
loss= 0.10223763179033994
loss= 0.1023934218659997
loss= 0.10221425727009774
loss= 0.10067294232547283
loss= 0.1011440310254693
loss= 0.10125091429799796
loss= 0.10056360613554716
loss= 0.0998293138295412
loss= 0.09988495461642742
loss= 0.10055082600563764
loss= 0.10175906527787447
loss= 0.1011922500282526
loss= 0.10055648878216744
loss= 0.10167460087686778
backup model
accuracy 94.48832019033425
epoch= 129 / 200
loss= 0.10477906711399555
loss= 0.10444057501852512
loss= 0.11526628091931343
loss= 0.1155696676298976
loss= 0.11568268787115812
loss= 0.11647159889340401
loss= 0.11582993127405644
loss= 0.10591659784317016
loss= 0.10605815071612597
loss= 0.10601744163781404
loss= 0.10338959351181984
loss= 0.10326208267360926
loss= 0.1062453543022275
loss= 0.10593897838145494
loss= 0.10546300090849399
loss= 0.10546531818807126
loss= 0.10539070360362529
loss= 0.10789703473448753
loss= 0.11022791981697083
loss= 0.11153853863477707
loss= 0.11182233843952417
backup model
accuracy 94.28294969468742
epoch= 130 / 200
loss= 0.10915361758321523
loss= 0.10816349755972623
loss= 0.11029925785958766
loss= 0.10558141708374023
loss= 0.10730344034731389
loss= 0.10920385748147965
loss= 0.10888441272079945
loss= 0.10758828826248645
loss= 0.10435606423765421
loss= 0.10501173879951238
loss= 0.10479232504963874
loss= 0.10439030140638351
loss= 0.10294930916279554
loss= 0.10290658839046955
loss= 0.10331454534083605
loss= 0.10259811915457248
loss= 0.10061372015625239
loss= 0.09942904770374299
loss= 0.10005141921341419
loss= 0.1018387034907937
loss= 0.10223275221884251
loss= 0.10489111069589853
backup model
accuracy 94.38828584394139
epoch= 131 / 200
loss= 0.1062004555016756
loss= 0.10451629057526589
loss= 0.10357117608189582
loss= 0.10402807556092739
loss= 0.10062749270349741
loss= 0.10289648439735175
loss= 0.10122959997504949
loss= 0.10255399197340012
loss= 0.1026158595085144
loss= 0.10112075444310903
loss= 0.10083498444408179
loss= 0.09919993389397859
loss= 0.09805460065603257
loss= 0.09841234184801578
backup model
accuracy 94.48704763039159
epoch= 132 / 200
loss= 0.09927041344344616
loss= 0.10300565786659717
loss= 0.10417878221720457
loss= 0.10340810846537352
loss= 0.10294260956346989
loss= 0.10307209394872188
loss= 0.10261762827634811
loss= 0.10257474973797798
loss= 0.10073405280709266
loss= 0.09954958640038968
loss= 0.10300247393548488
loss= 0.10377324745059013
loss= 0.10340778194367886
loss= 0.1047703392803669
loss= 0.10569853391498327
loss= 0.10695729497820139
loss= 0.10715122368186712
loss= 0.10609442003071308
loss= 0.10403099454939366
loss= 0.10249160028994084
loss= 0.10298971507698297
loss= 0.10138972956687212
loss= 0.1036645283922553
loss= 0.10192998051643372
loss= 0.10297503214329481
loss= 0.10279673751443624
loss= 0.10308469280600548
loss= 0.10399065878242254
backup model
accuracy 94.31720859904385
epoch= 133 / 200
loss= 0.10401815172284841
loss= 0.10507624737918377
loss= 0.10457566305994988
loss= 0.10450578540563583
loss= 0.10409528024494648
loss= 0.10452964875847101
loss= 0.10362448710948229
loss= 0.10273320782929658
loss= 0.10258992534130812
loss= 0.1008323061466217
loss= 0.10129675179719926
loss= 0.10189031388610602
loss= 0.10199487090110779
loss= 0.10179615925997496
loss= 0.10014471288770438
loss= 0.10069435592740775
loss= 0.10052781082689762
loss= 0.10075870711356401
loss= 0.10077362537384033
loss= 0.10355307467281819
loss= 0.10292914222925902
loss= 0.1023919939622283
backup model
accuracy 94.1214777449627
epoch= 134 / 200
loss= 0.09818431278690695
loss= 0.09729903953149915
loss= 0.0978235019557178
loss= 0.09998212983831763
loss= 0.09960752291604877
loss= 0.09979657573625446
loss= 0.10000826044008136
loss= 0.10150408305227757
loss= 0.10073474582284689
loss= 0.1009260369092226
loss= 0.09742460183799267
loss= 0.09746718361973762
loss= 0.09796055540442467
loss= 0.09880182042717933
loss= 0.09934705018997192
loss= 0.10274664539843797
loss= 0.10100916840136051
loss= 0.10029498234391213
loss= 0.10105845492333174
backup model
accuracy 94.2331385171317
epoch= 135 / 200
loss= 0.10049740821123124
loss= 0.10173549078404903
loss= 0.10273955602198839
loss= 0.10297301352024078
loss= 0.10380523536354304
loss= 0.1016524295695126
loss= 0.10184811705723405
loss= 0.10107884688302875
loss= 0.09917344832792878
loss= 0.10129440544173121
loss= 0.10294371265918016
loss= 0.10548430483788251
loss= 0.10520619582384824
loss= 0.10654773335903883
loss= 0.10724374078214169
loss= 0.1077465484291315
loss= 0.10729241989552975
loss= 0.10482079330831766
loss= 0.10427904389798641
backup model
accuracy 94.92449011068217
epoch= 136 / 200
loss= 0.09821212708950043
loss= 0.09851226851344108
loss= 0.0954281784966588
loss= 0.09641613367944955
loss= 0.09638745699077844
loss= 0.1003888189047575
loss= 0.10144847378134728
loss= 0.1013350572809577
loss= 0.10245347134768963
loss= 0.10218934156000614
loss= 0.10268657427281142
loss= 0.10453614022582769
loss= 0.10134369608014822
loss= 0.10149210643023253
loss= 0.10335355777293444
loss= 0.10237852148711682
loss= 0.10251117322593928
backup model
accuracy 93.87909007128371
epoch= 137 / 200
loss= 0.10289671909064055
loss= 0.10247613687068224
loss= 0.10197579581290483
loss= 0.10143415786325932
loss= 0.09635402381420136
loss= 0.09870203167200088
loss= 0.09971028853207826
loss= 0.09980605199933051
loss= 0.10141240075230598
loss= 0.10221729416400194
loss= 0.1029876559600234
loss= 0.10299675315618514
loss= 0.10308958508074284
loss= 0.10192771565169095
loss= 0.10223645176738501
loss= 0.10152534566819668
loss= 0.10089714121073484
loss= 0.10116048660129309
loss= 0.09829844009131193
loss= 0.09876160740852356
loss= 0.09873343292623758
loss= 0.10261032920330763
loss= 0.10274748235940934
backup model
accuracy 93.19308004809258
epoch= 138 / 200
loss= 0.1081583397462964
loss= 0.10927250921726227
loss= 0.10872914016246796
loss= 0.1042349597811699
loss= 0.10435257460922003
loss= 0.10167924217879772
loss= 0.10026378974318505
loss= 0.09972616858780384
loss= 0.0990530901029706
loss= 0.09886361133307218
loss= 0.09943093501031398
loss= 0.10227403942495585
loss= 0.10236123587936163
loss= 0.1027707041427493
loss= 0.10261586342006922
loss= 0.10510129388421774
loss= 0.10524457778781653
loss= 0.10586914781481027
loss= 0.10270355056971311
loss= 0.10262699257582426
loss= 0.10300361711531877
loss= 0.10227606046944857
loss= 0.10127697076648473
backup model
accuracy 94.54041402228711
epoch= 139 / 200
loss= 0.10032529875636101
loss= 0.10066348489373922
loss= 0.10009266305714845
loss= 0.09858625859022141
loss= 0.09793091110885144
loss= 0.09822090242058039
loss= 0.0977638316527009
loss= 0.09696738127619028
loss= 0.09956828508526087
loss= 0.1003714408352971
loss= 0.10166520405560732
loss= 0.10176749501377344
loss= 0.1018928312882781
loss= 0.10100855752825737
loss= 0.10044330585747957
loss= 0.09960821025073528
loss= 0.1001746928691864
loss= 0.09990209646522999
loss= 0.09991703569889068
loss= 0.10049927331507207
loss= 0.10049360129982234
backup model
accuracy 94.19067796394481
epoch= 140 / 200
loss= 0.10110589753836394
loss= 0.10253333799540996
loss= 0.10292388834059238
loss= 0.10209590658545493
loss= 0.10269979551434517
loss= 0.10250590112060308
loss= 0.10193565778434277
loss= 0.10192626491189002
loss= 0.10173457890748977
loss= 0.10225948382169009
loss= 0.1022560653090477
loss= 0.10281412005424499
loss= 0.10243820685893297
loss= 0.10197592712938786
loss= 0.10174664288759232
loss= 0.10174179259687662
loss= 0.09978735528886318
loss= 0.10027012594044209
loss= 0.10011814638972283
loss= 0.1000647321343422
loss= 0.10086528219282627
loss= 0.10108539428561926
loss= 0.10115729365497828
loss= 0.1020526184886694
loss= 0.10175035443156957
backup model
accuracy 94.08458305082503
epoch= 141 / 200
loss= 0.10101394139230252
loss= 0.10248078413307667
loss= 0.10234024934470654
loss= 0.10484219878911973
loss= 0.10304455447942018
loss= 0.10187198653817177
loss= 0.10198323503136635
loss= 0.10348242849111557
loss= 0.10286608707159757
loss= 0.09914897598326206
loss= 0.09779146630316973
loss= 0.09724886868149042
loss= 0.09802625451236963
loss= 0.09505460396409035
loss= 0.0948116047307849
loss= 0.0932739869877696
loss= 0.09383952338248491
loss= 0.09782928612083197
loss= 0.09752780310809613
loss= 0.09761795248836279
loss= 0.09900988921523095
loss= 0.09976904027163983
loss= 0.10024675022810697
loss= 0.10092231955379248
backup model
accuracy 94.17249785446394
epoch= 142 / 200
loss= 0.10190330855548382
loss= 0.1017048180475831
loss= 0.10177177961915732
loss= 0.10240068722516299
loss= 0.1021234454959631
loss= 0.10201336082071066
loss= 0.10200929906219244
loss= 0.1023214266449213
loss= 0.10092877414077521
loss= 0.10123836591839791
loss= 0.10103368733078241
loss= 0.10274751957505941
loss= 0.10302302405238152
loss= 0.10325053043663501
loss= 0.10491189707070589
loss= 0.10427665941417218
loss= 0.10020997066050769
loss= 0.09981391735374928
loss= 0.09948228608816861
loss= 0.09959780365228653
loss= 0.100164241977036
loss= 0.10032749976962804
loss= 0.1000021293759346
loss= 0.1016843930259347
loss= 0.10101372687146068
loss= 0.10241370590403676
loss= 0.102580012883991
loss= 0.10252762684598565
loss= 0.10270993737503886
loss= 0.10276849346235395
loss= 0.10227800687775015
loss= 0.10145936092361808
backup model
accuracy 93.99000639588627
epoch= 143 / 200
loss= 0.1025430377572775
loss= 0.10370187729597091
loss= 0.10567325815558433
loss= 0.10579977165907621
loss= 0.10648555904626847
loss= 0.1063570050150156
loss= 0.10659149035811424
loss= 0.10516414843499661
loss= 0.10440542578697204
loss= 0.10348550252616405
loss= 0.10329471625387669
loss= 0.10317882157862186
loss= 0.10250243950635195
loss= 0.10117584433406591
loss= 0.09978079073131084
loss= 0.10064211655408144
loss= 0.10055221900343896
loss= 0.09958485625684262
loss= 0.09974719662219286
loss= 0.1001253580302
loss= 0.09979640770703554
loss= 0.10242838181555271
loss= 0.10407587874680757
backup model
accuracy 94.70745819386076
epoch= 144 / 200
loss= 0.1065109184756875
loss= 0.10615453027188777
loss= 0.10387938734143973
loss= 0.10402528326958418
loss= 0.1037884709239006
loss= 0.10291637036949396
loss= 0.10033855073153973
loss= 0.10090847630053759
loss= 0.10083355151116848
loss= 0.10418232783675194
loss= 0.1047614361718297
loss= 0.10490482348948717
loss= 0.10513522811233997
loss= 0.10925231531262397
loss= 0.11078803699463606
loss= 0.11342567518353462
loss= 0.11253673806786538
loss= 0.1133111684769392
loss= 0.11166315414011478
loss= 0.11164596665650606
loss= 0.1027740141004324
loss= 0.1023219633474946
loss= 0.10458434041589498
loss= 0.10455387540161609
backup model
accuracy 94.08479143251564
epoch= 145 / 200
loss= 0.10455596119165421
loss= 0.10579537261277437
loss= 0.10509611856192351
loss= 0.10437239281833172
loss= 0.10398253329098224
loss= 0.10254441168159247
loss= 0.10182015016674996
loss= 0.10151711035519838
loss= 0.10106008119881153
loss= 0.10114500962197781
loss= 0.10098195100203157
loss= 0.09841517582535744
loss= 0.09801734004169703
loss= 0.09796082783490419
loss= 0.09947681814432144
loss= 0.10024595484137536
loss= 0.10017482224851847
loss= 0.10221668437123299
loss= 0.10309908136725426
loss= 0.10314691703766585
loss= 0.10174809731543064
loss= 0.10491012215614319
loss= 0.10749004643410444
loss= 0.10732806570827962
loss= 0.10736258450895547
loss= 0.10750753965228796
loss= 0.10574887823313475
loss= 0.10623877160251141
backup model
accuracy 94.22995075447534
epoch= 146 / 200
loss= 0.10155034877359867
loss= 0.10150843497365714
loss= 0.10127456415444612
loss= 0.09970658972859382
loss= 0.09846441425383091
loss= 0.09879468314349651
loss= 0.1000753165408969
loss= 0.09933442961424589
loss= 0.10029622483998538
loss= 0.10148029495030642
loss= 0.10116511786356569
loss= 0.100659790802747
loss= 0.10150169407948852
loss= 0.10196549260988831
loss= 0.10271304858848453
loss= 0.10315896844491362
loss= 0.10303802898153663
loss= 0.10416013879701495
loss= 0.10376418555155396
loss= 0.10345027258619666
loss= 0.10095068778842688
loss= 0.09934721533209086
loss= 0.09652733918279409
loss= 0.09610032469034195
loss= 0.09625880636274814
loss= 0.0962455353885889
loss= 0.0957942807674408
loss= 0.09521117944270373
backup model
accuracy 94.6367388564471
epoch= 147 / 200
loss= 0.10146273620426655
loss= 0.1016921804472804
loss= 0.10214710749685764
loss= 0.10296374332159758
loss= 0.10355876915156842
loss= 0.10445333505049348
loss= 0.1033488274551928
loss= 0.1028436117619276
loss= 0.10056601975113154
loss= 0.09887149054557084
loss= 0.09870502065867186
loss= 0.10090735740959644
loss= 0.10142986416816711
loss= 0.10150570273399354
loss= 0.102598494887352
loss= 0.10283105598762632
loss= 0.1038489611633122
loss= 0.10343057004734874
loss= 0.10333261543884874
loss= 0.10197879154235125
loss= 0.10167692542076111
backup model
accuracy 94.6385586171651
epoch= 148 / 200
loss= 0.0998603793606162
loss= 0.10005358833819628
loss= 0.1000705013051629
loss= 0.09685267996042966
loss= 0.09648040767759085
loss= 0.09799225687980652
loss= 0.09904986951500178
loss= 0.10070439282804727
loss= 0.10076101325452327
loss= 0.10002965930849314
loss= 0.09872379567474127
loss= 0.09617729764431715
loss= 0.0972180687636137
loss= 0.0955439519509673
loss= 0.09546132858842611
loss= 0.09618492871522903
loss= 0.09811312023550273
loss= 0.10073180381208659
loss= 0.10047913249582052
backup model
accuracy 94.93964789029923
epoch= 149 / 200
loss= 0.0971403867378831
loss= 0.09754257928580046
loss= 0.09876962255686522
loss= 0.09893095627427101
loss= 0.1001189362630248
loss= 0.09985826496034861
loss= 0.09956076212227344
loss= 0.0987275101430714
loss= 0.09923576535657049
loss= 0.09908014206215739
loss= 0.0993133413232863
loss= 0.09884629214182496
loss= 0.09901085400953889
loss= 0.09852900112047791
loss= 0.09766461761668324
loss= 0.09854121258482337
loss= 0.0992078946903348
loss= 0.1002436688542366
loss= 0.10162372581660747
loss= 0.10144013125449419
loss= 0.10131936453282833
loss= 0.10159255102276803
loss= 0.10130750868469476
loss= 0.09917580556124449
loss= 0.0992991514876485
backup model
accuracy 93.62148735279027
epoch= 150 / 200
loss= 0.10038043355569243
loss= 0.10003252064809204
loss= 0.10035398716107011
loss= 0.09888938101008535
loss= 0.10046533558517695
loss= 0.10327274348586797
loss= 0.10466457352042198
loss= 0.10473824720829725
loss= 0.10826858144253493
loss= 0.10613408815115691
loss= 0.10540165718644857
loss= 0.10498188838362693
loss= 0.10363650903105735
loss= 0.10473472997546196
loss= 0.10410747598856687
loss= 0.10390688724815846
loss= 0.10114925686269999
loss= 0.10746235076338052
loss= 0.10863916330039501
backup model
accuracy 94.4516179708879
epoch= 151 / 200
loss= 0.10842627625912428
loss= 0.10724677588790656
loss= 0.1096317845955491
loss= 0.10411229342222214
loss= 0.10390387706458569
loss= 0.10246685687452554
loss= 0.09981761828064918
loss= 0.0978790370747447
loss= 0.0970002194866538
loss= 0.0980715236440301
loss= 0.09830844681710005
loss= 0.09771172676235437
loss= 0.09744353380054235
loss= 0.0976961261406541
loss= 0.09755811236798763
loss= 0.09867069821804762
loss= 0.09888278543949128
loss= 0.09824117414653301
loss= 0.09806437775492668
loss= 0.0988813453912735
loss= 0.0986200738325715
loss= 0.09895089413970709
backup model
accuracy 94.21218104557597
epoch= 152 / 200
loss= 0.09894051503390074
loss= 0.09863355357199907
loss= 0.10158803444355727
loss= 0.10172090422362089
loss= 0.10165443357080221
loss= 0.10084019411355256
loss= 0.10038786794990301
loss= 0.09852915681898594
loss= 0.0990683813765645
loss= 0.0994856645539403
loss= 0.09944904197007418
loss= 0.1010342975333333
loss= 0.10137158256024122
loss= 0.10078135211020708
loss= 0.10984866879880428
loss= 0.11236669365316629
loss= 0.11363335892558098
loss= 0.11290942966938018
loss= 0.11388991612941027
loss= 0.11432527929544449
loss= 0.11527871653437614
backup model
accuracy 93.42904765686083
epoch= 153 / 200
loss= 0.10915457639843225
loss= 0.10847558841109275
loss= 0.10654714606702327
loss= 0.10488188546150923
loss= 0.1046853818371892
loss= 0.10348854344338179
loss= 0.10220632169395685
loss= 0.10298148442059755
loss= 0.09830272372812032
loss= 0.0985906345769763
loss= 0.09806762713938952
loss= 0.09762736912816763
loss= 0.0966067861765623
loss= 0.09686212051659822
loss= 0.09687392141669988
loss= 0.09849748980253935
loss= 0.09906150370836259
loss= 0.09858151046559215
loss= 0.09716818923130631
loss= 0.09824268283322453
loss= 0.10002946572378278
loss= 0.09997068943455815
loss= 0.10203496804460883
backup model
accuracy 94.53578031339588
epoch= 154 / 200
loss= 0.10150692347437143
loss= 0.1005248299613595
loss= 0.10096834294497967
loss= 0.09784644596278667
loss= 0.09576976723968983
loss= 0.09956417873501777
loss= 0.10048065435141325
loss= 0.10091055069118739
loss= 0.10264336787164212
loss= 0.1008993823081255
loss= 0.09878153208643198
loss= 0.0974802079051733
loss= 0.097395681142807
loss= 0.09515636321157217
loss= 0.094433728531003
loss= 0.09548700239509345
loss= 0.09718932118266821
loss= 0.09776002414524555
loss= 0.09825805734843016
backup model
accuracy 94.39151814619576
epoch= 155 / 200
loss= 0.10026244752109051
loss= 0.10031314074993133
loss= 0.09993451584130525
loss= 0.09908891707658768
loss= 0.10035164088010788
loss= 0.10238209512084723
loss= 0.10259004406630994
loss= 0.1019455524533987
loss= 0.10271515715867281
loss= 0.10035001121461391
loss= 0.09920289278030396
loss= 0.10064186088740826
backup model
accuracy 94.22729587629496
epoch= 156 / 200
loss= 0.09787302233278751
loss= 0.09783650662750006
loss= 0.09777083080261946
loss= 0.09803321592509746
loss= 0.0974875259026885
loss= 0.0966323446854949
loss= 0.09644647240638733
loss= 0.09640154175460339
loss= 0.09587757106870413
loss= 0.09438386399298906
loss= 0.09592817328870297
loss= 0.09620309956371784
loss= 0.09603691313415766
loss= 0.09498581249266863
loss= 0.09568674348294735
loss= 0.09614551622420549
loss= 0.09733280722051858
loss= 0.09668441485613584
loss= 0.09662550441920757
loss= 0.0967813079059124
loss= 0.09930032428354024
loss= 0.09958374097943307
loss= 0.10067099567502737
loss= 0.10057678017765284
loss= 0.09969270680099726
loss= 0.09843163553625345
loss= 0.09623776961117983
loss= 0.09585921067744493
loss= 0.09530873250216246
loss= 0.09490365028381348
backup model
accuracy 94.30095800857603
epoch= 157 / 200
loss= 0.09555487062782049
loss= 0.09698002437129617
loss= 0.09983173364773393
loss= 0.09870356112718583
loss= 0.09768207255750895
loss= 0.10036352954804897
loss= 0.10155033208429813
loss= 0.10119656752794981
loss= 0.10118443038314581
loss= 0.10233416557312011
loss= 0.10200580850243568
loss= 0.10251529514789581
loss= 0.1035273601859808
loss= 0.10011510148644448
loss= 0.10040263153612614
loss= 0.09891863895580172
loss= 0.0982655287720263
loss= 0.09816185967996717
loss= 0.0987774675525725
loss= 0.0988189517147839
backup model
accuracy 94.72416213380815
epoch= 158 / 200
loss= 0.09996803637593984
loss= 0.09995498837903143
loss= 0.09885733934119344
loss= 0.09865180434659124
loss= 0.09841113584116101
loss= 0.09891021894291044
loss= 0.09810181310400366
loss= 0.09792544381693005
loss= 0.09760092983022332
loss= 0.09959368482232094
loss= 0.0994090086594224
loss= 0.09935330532491207
loss= 0.09955463837832212
loss= 0.09993015326559544
loss= 0.09941449522972107
loss= 0.09860240750014782
loss= 0.09840147584676742
loss= 0.09714802157133817
loss= 0.09618685103952884
loss= 0.09490656189620494
loss= 0.09499777309596538
backup model
accuracy 94.33362462230421
epoch= 159 / 200
loss= 0.0943408228084445
loss= 0.09519110333174467
loss= 0.10150128845125436
loss= 0.101295977383852
loss= 0.10163441818207503
loss= 0.10100905526429414
loss= 0.09964958813041448
loss= 0.09948956925421953
loss= 0.09890240918844938
loss= 0.10002904526889324
loss= 0.1010989924147725
loss= 0.10104112859815359
loss= 0.1019501193985343
loss= 0.10171333011239767
loss= 0.10167625598609448
loss= 0.1000320490822196
loss= 0.09923192232847214
backup model
accuracy 94.23540526452958
epoch= 160 / 200
loss= 0.09801049258559942
loss= 0.09837942309677601
loss= 0.09802680071443319
loss= 0.10023141641169786
loss= 0.10028676759451628
loss= 0.10033353857696056
loss= 0.10011612102389336
loss= 0.09939578287303448
loss= 0.09899826504290105
loss= 0.09892792243510484
loss= 0.0979243167117238
loss= 0.09788016639649869
loss= 0.09874194588512182
loss= 0.09846347473561763
loss= 0.09834666967391968
loss= 0.10079169537872076
loss= 0.0997498681396246
loss= 0.09977435778826475
loss= 0.09972361043095589
loss= 0.1013950003311038
loss= 0.10396312151104212
loss= 0.10439300853759051
loss= 0.10534244120121002
loss= 0.1077854011580348
backup model
accuracy 94.97907975082258
epoch= 161 / 200
loss= 0.10189829215407371
loss= 0.09859096992760896
loss= 0.09848288081586361
loss= 0.09829158935695886
loss= 0.09617065954953433
loss= 0.09619833722710609
loss= 0.09589875934645534
loss= 0.097009232994169
loss= 0.09694771623238921
loss= 0.09682667328044772
loss= 0.09872807500883937
loss= 0.09948870638385415
loss= 0.09847324093803764
loss= 0.10062277108430863
loss= 0.10046741589903832
loss= 0.10020933359861374
loss= 0.10042919058352709
loss= 0.09816944122314453
loss= 0.09707589656114578
loss= 0.09694041360169649
loss= 0.09570546466857195
loss= 0.09612699162214994
loss= 0.09563546627759933
loss= 0.0940465110167861
backup model
accuracy 94.60574088694374
epoch= 162 / 200
loss= 0.09321005145087838
loss= 0.09243524642661213
loss= 0.10080505395308137
loss= 0.1055282188206911
loss= 0.1062211075797677
loss= 0.10615651942789554
loss= 0.1057263021543622
loss= 0.0987869793921709
loss= 0.09844709187746048
loss= 0.09846350912004709
loss= 0.09885831892490388
loss= 0.0986130440980196
loss= 0.09793213620781899
loss= 0.10080248787999153
loss= 0.10533987641334534
loss= 0.1049846225604415
loss= 0.1041478182002902
loss= 0.10270538046956063
loss= 0.1043733374401927
loss= 0.10073462579399348
loss= 0.10049463227391243
backup model
accuracy 94.7964244501523
epoch= 163 / 200
loss= 0.10093757506459951
loss= 0.09964570604264736
loss= 0.10019007917493582
loss= 0.09674653861671687
loss= 0.09654995553195476
loss= 0.09696615703403949
loss= 0.09756931398063898
loss= 0.09718970976769924
loss= 0.09728342700749636
loss= 0.0988220115751028
loss= 0.0963916328176856
loss= 0.09476048309355974
loss= 0.09475389372557402
loss= 0.09523565210402012
loss= 0.09547682404518128
loss= 0.09610422484576703
loss= 0.09417707912623882
loss= 0.09607459004968405
loss= 0.09988812368363142
loss= 0.10031590208411217
loss= 0.10310645278543235
loss= 0.10275962699204683
backup model
accuracy 95.18507061944146
epoch= 164 / 200
loss= 0.09853406932204961
loss= 0.0988053023442626
loss= 0.09916224762797356
loss= 0.10362537242472172
loss= 0.10382176466286182
loss= 0.10529538847506047
loss= 0.10466850657016039
loss= 0.10270783711224794
loss= 0.10106453258544207
loss= 0.10092362184077501
loss= 0.10230093244463205
loss= 0.10361548069864511
loss= 0.10254993230104446
backup model
accuracy 93.75282826447257
epoch= 165 / 200
loss= 0.10334905603900552
loss= 0.10386824870482086
loss= 0.10419754089787603
loss= 0.10364930083975196
loss= 0.10015707777813077
loss= 0.1011044481024146
loss= 0.10116696242243052
loss= 0.09816746920347214
loss= 0.09711910136044026
loss= 0.09737365055829286
loss= 0.09746208988130092
loss= 0.09760987658053637
loss= 0.09724848706275224
loss= 0.09392214618623257
loss= 0.09448646776378154
loss= 0.09512513656169176
loss= 0.0938611089065671
loss= 0.0948069055750966
loss= 0.09475534111261368
loss= 0.09503757016733289
loss= 0.0965774840861559
loss= 0.09898380670696497
backup model
accuracy 94.25653612237751
epoch= 166 / 200
loss= 0.10002388540655374
loss= 0.10115388978272677
loss= 0.10129964780062437
loss= 0.09904796563088894
loss= 0.09869960281997919
loss= 0.09929165467619896
loss= 0.09912563309073448
loss= 0.09926816310733556
loss= 0.09930729772895575
loss= 0.09855855725705624
loss= 0.0956133446842432
loss= 0.09754929076880217
loss= 0.09909581039100886
loss= 0.09772260434925556
loss= 0.09766513362526894
loss= 0.09796560771763324
loss= 0.09829789858311415
loss= 0.09919372230768203
loss= 0.0991346786916256
loss= 0.10047632820904255
loss= 0.10031851813197136
loss= 0.10002225067466497
loss= 0.09875359874218702
loss= 0.09868100874125957
loss= 0.09846832230687141
backup model
accuracy 94.03782760783164
epoch= 167 / 200
loss= 0.09770037140697241
loss= 0.10071346931159496
loss= 0.10108711797744035
loss= 0.10059356015175581
loss= 0.1013452397286892
loss= 0.10211612038314342
loss= 0.1037568810582161
loss= 0.10243007890880108
loss= 0.10309869974851608
loss= 0.10325950793921948
loss= 0.1023483094573021
loss= 0.10181736387312412
loss= 0.10285599935799837
loss= 0.10298850040882826
loss= 0.1012130667641759
loss= 0.09849944066256285
loss= 0.09722718510776758
loss= 0.09620358441025019
loss= 0.09607130900025368
loss= 0.09660874206572771
loss= 0.09774465687572956
backup model
accuracy 94.55003616615357
epoch= 168 / 200
loss= 0.10228518266230821
loss= 0.10390825495123863
loss= 0.10367131400853395
loss= 0.1048337815515697
loss= 0.1045231412537396
loss= 0.10152336237952113
loss= 0.10133934149518609
loss= 0.10128701450303197
loss= 0.10075098540633917
loss= 0.09902031056582927
loss= 0.09941990461200476
loss= 0.09967297479510308
loss= 0.09999811474233866
loss= 0.09918941549956799
loss= 0.09907016202807427
loss= 0.09825476795434952
loss= 0.09867647599428891
loss= 0.09570118363946677
loss= 0.09535875331610441
backup model
accuracy 94.93611971785819
epoch= 169 / 200
loss= 0.0958402331545949
loss= 0.0958657918870449
loss= 0.09698454294353724
loss= 0.09770073104649782
loss= 0.09837064128369093
loss= 0.09851681660860777
loss= 0.09783851191401481
loss= 0.09727391596883535
loss= 0.09832695230841637
loss= 0.09891659494489431
loss= 0.09965455651283264
loss= 0.09951582990586758
loss= 0.09920422162860631
loss= 0.09924450889229774
loss= 0.09913461793214083
loss= 0.09947114538401365
loss= 0.09922222873196006
loss= 0.0989467809535563
loss= 0.0987173399142921
loss= 0.09755529562011361
loss= 0.09737877925857902
loss= 0.09691744392737746
loss= 0.09654587915167212
loss= 0.09632681572809815
loss= 0.09564928414300083
loss= 0.10106580577790737
loss= 0.10095431447029114
loss= 0.10134360052645207
backup model
accuracy 94.15417617268943
epoch= 170 / 200
loss= 0.09926677014678717
loss= 0.10524750022217631
loss= 0.10678762240335345
loss= 0.10824027111753821
loss= 0.10800994085147977
loss= 0.10867279028519988
loss= 0.12443658420816064
loss= 0.13288006741553546
loss= 0.13208879593759776
loss= 0.11920100264251232
loss= 0.11921519938856363
loss= 0.11851304568350315
loss= 0.11786933209747076
loss= 0.1172724373266101
loss= 0.11208920646458864
loss= 0.11189771447330714
loss= 0.11188304483890534
loss= 0.11144626278430224
loss= 0.11123852021992206
loss= 0.10947831306606531
loss= 0.1069787672534585
loss= 0.10769819620996714
loss= 0.1063890277966857
backup model
accuracy 93.79121662584295
epoch= 171 / 200
loss= 0.10478689048439264
loss= 0.10422394867986441
loss= 0.10400641772896052
loss= 0.10376929428428411
loss= 0.10364007614552975
loss= 0.1037162460014224
loss= 0.10261852495372295
loss= 0.10357554331421852
loss= 0.10303102251142264
loss= 0.10288321111351252
loss= 0.10356313455849886
loss= 0.10178179297596217
loss= 0.1019105364382267
loss= 0.10130822092294693
loss= 0.10305164054036141
loss= 0.10276291027665138
loss= 0.1016391209512949
loss= 0.10204997539520264
loss= 0.10198047135025262
loss= 0.10041192926466465
backup model
accuracy 94.24213392522641
epoch= 172 / 200
loss= 0.09764821384102106
loss= 0.0974892608076334
loss= 0.0995843005925417
loss= 0.09912861827760935
loss= 0.09962370444089175
loss= 0.09841335672885179
loss= 0.09954371374100447
loss= 0.10034075811505318
loss= 0.100469054505229
loss= 0.10070531900972128
loss= 0.10193802755326033
loss= 0.10264934077858925
loss= 0.10292627897113561
loss= 0.10195119004696608
loss= 0.10201856855303049
loss= 0.101998805180192
loss= 0.10180289261043071
loss= 0.10184341300278903
loss= 0.10241825576871634
loss= 0.1018812932446599
loss= 0.1014762169495225
loss= 0.10171858187764883
loss= 0.1015182588621974
loss= 0.10091728184372187
backup model
accuracy 94.03812665941817
epoch= 173 / 200
loss= 0.10122130949050188
loss= 0.10091387767344713
loss= 0.10094502080231905
loss= 0.10117212854325772
loss= 0.1010012898221612
loss= 0.09937413677573204
loss= 0.09942622158676385
loss= 0.09952609580010176
loss= 0.09842387020587921
loss= 0.0967328492552042
loss= 0.11691775348037481
loss= 0.12553752452135086
loss= 0.12635990750044584
loss= 0.13086742777377366
loss= 0.1333053222671151
loss= 0.13541113384068013
loss= 0.13665519051253797
loss= 0.1176418387517333
loss= 0.11099516704678536
loss= 0.11111194007098675
backup model
accuracy 93.61079784927189
epoch= 174 / 200
loss= 0.11250487808138132
loss= 0.11252939812839031
loss= 0.11178172692656517
loss= 0.11109366200864315
loss= 0.11081899706274272
loss= 0.10378970123827458
loss= 0.10946573287248612
loss= 0.10865129489451647
loss= 0.10699892923235893
loss= 0.10577174127101899
loss= 0.10630297217518091
loss= 0.1060197639092803
loss= 0.10547408066689969
loss= 0.10591102715581656
loss= 0.10706808011978865
loss= 0.10274765696376562
loss= 0.10256439186632633
loss= 0.10258906792849302
loss= 0.10262519791722298
loss= 0.10304207544773818
loss= 0.10295335467904806
loss= 0.10398524593561888
loss= 0.1020052233338356
loss= 0.1019794000685215
loss= 0.10125326953828334
backup model
accuracy 94.65985967990537
epoch= 175 / 200
loss= 0.09845305029302835
loss= 0.09948247324675322
loss= 0.09948719635605813
loss= 0.09951028876006603
loss= 0.09654235497117042
loss= 0.0968213227018714
loss= 0.0970102334395051
loss= 0.09743909299373626
loss= 0.09686492305248975
loss= 0.09694019507616758
loss= 0.09813720824196935
loss= 0.09753517365083099
loss= 0.09774446276947855
loss= 0.09837733371183276
loss= 0.0972681244276464
loss= 0.09709566818550229
loss= 0.09728051977232098
loss= 0.09851955141872168
loss= 0.09920777682214975
loss= 0.09981392461806536
loss= 0.10049235500395298
loss= 0.09883583378046751
backup model
accuracy 94.41746723412659
epoch= 176 / 200
loss= 0.09534821126610041
loss= 0.09350983537733555
loss= 0.09470920767635108
loss= 0.096090117841959
loss= 0.09736245721578599
loss= 0.10113663226366043
loss= 0.10142329093068839
loss= 0.10042876303195954
loss= 0.10010437529534101
loss= 0.099481729157269
loss= 0.09962972037494183
loss= 0.09968294061720372
loss= 0.10100789569318294
loss= 0.10145175836980343
loss= 0.10028060305863619
loss= 0.10071571249514819
loss= 0.10064624734222889
loss= 0.10111188668757677
loss= 0.10167227631434798
loss= 0.10387826899066567
loss= 0.10075571356341242
backup model
accuracy 94.47781202660771
epoch= 177 / 200
loss= 0.100113231446594
loss= 0.09987223094329238
loss= 0.09949259750545025
loss= 0.09914250038564205
loss= 0.09752984099090099
loss= 0.09661656897515059
loss= 0.09706142261624336
loss= 0.09742580007761717
loss= 0.09758359000086785
loss= 0.09992443051189184
loss= 0.10023245513439179
loss= 0.10040900181978941
loss= 0.1005232735350728
loss= 0.1006395584344864
loss= 0.10087732881307603
loss= 0.10121491853147745
loss= 0.10155213560909032
loss= 0.100640740506351
loss= 0.1015460678935051
loss= 0.10138927426189184
loss= 0.10165346935391426
loss= 0.10173494506627322
loss= 0.10377237685024739
loss= 0.10449878841638566
loss= 0.10257214970886708
loss= 0.10302016098052263
loss= 0.1034374313801527
loss= 0.10373811151832342
loss= 0.10243784070014954
loss= 0.09776083864271641
loss= 0.09712788451462984
loss= 0.09754565216600895
loss= 0.09773329950869084
backup model
accuracy 94.37266198924534
epoch= 178 / 200
loss= 0.09899458069354296
loss= 0.09815767437219619
loss= 0.09768738385289907
loss= 0.09591883789747953
loss= 0.09540140014141799
loss= 0.09449243927374482
loss= 0.09341351265087723
loss= 0.09354449486359954
loss= 0.09427611647173763
loss= 0.09546164887025953
loss= 0.09584535656496883
loss= 0.09605027636513114
loss= 0.09637866305187344
loss= 0.09780088864266873
loss= 0.09792181838303804
loss= 0.09608164932578803
loss= 0.09575615346431732
loss= 0.09764133922755719
loss= 0.09696406904608011
loss= 0.10021822594106197
loss= 0.0994150461256504
loss= 0.09891465879976749
backup model
accuracy 94.38938501759186
epoch= 179 / 200
loss= 0.09544028041884303
loss= 0.09459132408723235
loss= 0.09237481633201242
loss= 0.09176836026832462
loss= 0.0935331953689456
loss= 0.09387634120881558
loss= 0.09433026008307933
loss= 0.09543386310338973
loss= 0.09577942378818989
loss= 0.0961196019127965
loss= 0.09577236438170075
loss= 0.09587744502350688
loss= 0.0947012030147016
loss= 0.09410036472603679
loss= 0.09349430298432708
loss= 0.09360715618357063
loss= 0.09313155194744467
loss= 0.09316156206652522
loss= 0.09385820789262653
loss= 0.09380587825551628
loss= 0.09412696966901421
loss= 0.09490955244749784
loss= 0.09510256562381983
loss= 0.09503539972007274
loss= 0.09768403615802526
loss= 0.09824837751686573
loss= 0.09823853336274624
loss= 0.09826042655855417
loss= 0.09539168670773507
backup model
accuracy 94.84250861777593
epoch= 180 / 200
loss= 0.096306844484061
loss= 0.09743312682956456
loss= 0.09668741550296545
loss= 0.09432296622544527
loss= 0.0947796293720603
loss= 0.095377047508955
loss= 0.09471532829105854
loss= 0.0933567763492465
loss= 0.09380495052784682
loss= 0.09412904892116786
loss= 0.09451818849891425
loss= 0.09529366478323936
loss= 0.09605576619505882
loss= 0.09616644117981195
loss= 0.0964650509133935
loss= 0.09632480084896088
loss= 0.09599011275917292
loss= 0.09579629614949227
loss= 0.09698119182139635
backup model
accuracy 94.88680642938004
epoch= 181 / 200
loss= 0.0967660229280591
loss= 0.09863389369100332
loss= 0.09847757294774055
loss= 0.09841769363731145
loss= 0.09634518146514892
loss= 0.09633344236761332
loss= 0.09493796918541193
loss= 0.09471524197608233
loss= 0.09544204946607351
loss= 0.09562478587031364
loss= 0.09558044102042913
loss= 0.09419644221663476
loss= 0.09349045399576425
loss= 0.09354318220168352
loss= 0.09566759638488292
loss= 0.09595690835267305
loss= 0.09757094994187356
loss= 0.09990656584501266
loss= 0.1000406825914979
loss= 0.10006992870941758
loss= 0.10109545717015862
loss= 0.09895536849275231
loss= 0.09843793811276555
loss= 0.09895103299990296
loss= 0.09763548960909248
loss= 0.09440081818029285
loss= 0.09463554700836539
loss= 0.09608486611396075
loss= 0.09550758000463247
loss= 0.09519413668662309
backup model
accuracy 93.94241583543051
epoch= 182 / 200
loss= 0.09481806226074696
loss= 0.0956876626983285
loss= 0.0981021374091506
loss= 0.09914916362613439
loss= 0.09779722411185503
loss= 0.09850919172167778
loss= 0.09910336092114448
loss= 0.09859322119504213
loss= 0.0983535198122263
loss= 0.0994998325780034
loss= 0.09985182866454125
loss= 0.10006472453474999
loss= 0.09851513672620058
loss= 0.0988368921726942
loss= 0.09710993558168411
loss= 0.0973227969929576
loss= 0.10789096359163523
loss= 0.10871440473943948
loss= 0.1098118668422103
loss= 0.11076818592846394
loss= 0.11085686184465886
loss= 0.11177825018763542
loss= 0.105146509334445
loss= 0.10354942049831152
loss= 0.10145440947264434
loss= 0.09724808398634195
backup model
accuracy 94.36279169619006
epoch= 183 / 200
loss= 0.09932343266904355
loss= 0.09978429079055787
loss= 0.09952890768647193
loss= 0.09891443818807602
loss= 0.09712401300668716
loss= 0.09681634921580554
loss= 0.09668435290455818
loss= 0.09734548684209585
loss= 0.09846907209604978
loss= 0.09823999036103487
loss= 0.09856720846146345
loss= 0.09772897057235241
loss= 0.10633280906826258
loss= 0.1074754337966442
loss= 0.10342434991151095
loss= 0.1034927735105157
loss= 0.10210881322622299
loss= 0.10238521710038186
loss= 0.10240234654396772
loss= 0.10239131215959787
loss= 0.10121471725404263
backup model
accuracy 94.68671864819521
epoch= 184 / 200
loss= 0.10044547166675329
loss= 0.0998292537778616
loss= 0.09995400752872229
loss= 0.09474622908979655
loss= 0.09479120902717114
loss= 0.09570301346480846
loss= 0.0960981248319149
loss= 0.09585799634456635
loss= 0.09675626274198294
loss= 0.0980203114822507
loss= 0.09810988523066044
loss= 0.09854738458991051
loss= 0.09807779014110565
loss= 0.09854364361613989
loss= 0.09841711312532425
loss= 0.09876067046076059
loss= 0.09914280407130718
loss= 0.09953402232378722
loss= 0.09962927833199502
loss= 0.0988175992295146
loss= 0.10059540092945099
loss= 0.09978004807606339
loss= 0.09872667977586388
loss= 0.09964658694341778
loss= 0.09931370126083493
loss= 0.10018743960186839
loss= 0.09729149667546153
loss= 0.10120945807546378
backup model
accuracy 94.27458261306441
epoch= 185 / 200
loss= 0.10164411149919034
loss= 0.10062294326722622
loss= 0.09995806690305471
loss= 0.09829023022204637
loss= 0.09757953092455864
loss= 0.0971925324946642
loss= 0.09700277622789144
loss= 0.09226678535342217
loss= 0.09222298465669156
loss= 0.09381317801773548
loss= 0.09348364450037479
loss= 0.09283594202250242
loss= 0.09342754486948252
loss= 0.09661764372140169
loss= 0.09702508937567472
loss= 0.09614968024194241
loss= 0.09927799589931965
loss= 0.0996248546987772
loss= 0.1011945454031229
loss= 0.10055412653833627
loss= 0.10068967878818512
loss= 0.10074264466762543
loss= 0.10106567282229661
loss= 0.10176867213100195
backup model
accuracy 94.6519841245602
epoch= 186 / 200
loss= 0.1004278714582324
loss= 0.1008010671660304
loss= 0.10055076789110899
loss= 0.10720737494528293
loss= 0.11064950784668326
loss= 0.11054032390937209
loss= 0.1062041443027556
loss= 0.10318710058927535
loss= 0.10255186170339585
loss= 0.09955305598676205
loss= 0.0964862496778369
loss= 0.0961876267939806
loss= 0.09614490047097206
loss= 0.09598455209285021
loss= 0.09647904774174094
loss= 0.09580305557698011
loss= 0.09509053334593773
loss= 0.09507364165037871
loss= 0.09564742349088191
backup model
accuracy 94.91471685032252
epoch= 187 / 200
loss= 0.09485102865844965
loss= 0.09680587109178304
loss= 0.09618144169449806
loss= 0.09664040673524141
loss= 0.09642917308956385
loss= 0.09507318932563066
loss= 0.09488036643713713
loss= 0.09483492370694875
loss= 0.09526414163410664
loss= 0.09492453880608082
loss= 0.09346965439617634
loss= 0.09770753994584083
loss= 0.0974636623635888
loss= 0.09890905555337667
loss= 0.10132490430027247
loss= 0.10036636095494032
loss= 0.10100339900702238
backup model
accuracy 94.3825863660982
epoch= 188 / 200
loss= 0.09825072925537824
loss= 0.09778656348586083
loss= 0.09635056521743536
loss= 0.09761036667972803
loss= 0.10287635941058397
loss= 0.1052270071581006
loss= 0.10555428680032491
loss= 0.10636157177388668
loss= 0.10643857959657907
loss= 0.10656633082777262
loss= 0.10631460592150688
loss= 0.10207757513970137
loss= 0.10300383053719997
loss= 0.10276087105274201
loss= 0.100868871062994
loss= 0.09982800029218197
loss= 0.09976529106497764
loss= 0.09926987715065479
loss= 0.10031088020652533
backup model
accuracy 94.58515722987116
epoch= 189 / 200
loss= 0.1001832476258278
loss= 0.10142170865088701
loss= 0.0994684698060155
loss= 0.10053121626377105
loss= 0.0994302324578166
loss= 0.09978370126336814
loss= 0.09965911649167537
loss= 0.09924923092126846
loss= 0.099178078584373
loss= 0.09871910355985164
loss= 0.09949069693684578
loss= 0.09681910086423158
loss= 0.09793152097612619
loss= 0.09839082475751638
loss= 0.09594810470938682
loss= 0.09600051239132881
loss= 0.09693448532372713
loss= 0.09659340493381023
loss= 0.09600460544228553
loss= 0.0953413949161768
loss= 0.09613110817968845
backup model
accuracy 93.93619778941067
epoch= 190 / 200
loss= 0.09638586156070232
loss= 0.0964784924313426
loss= 0.0973478677496314
loss= 0.09736879028379918
loss= 0.10083340398967267
loss= 0.10375414002686739
loss= 0.10570778921246529
loss= 0.10634694427251816
loss= 0.10675502095371485
loss= 0.10669265449047088
loss= 0.10490648999810219
loss= 0.1019118132814765
loss= 0.10212715797126293
loss= 0.10149404186755419
loss= 0.0990602856874466
loss= 0.09918523769825698
loss= 0.09907236613333226
backup model
accuracy 94.62622432992083
epoch= 191 / 200
loss= 0.0993240775913
loss= 0.09843236025422812
loss= 0.09797014649957418
loss= 0.09871305897831917
loss= 0.09634805552661418
loss= 0.09555114243179559
loss= 0.09552717309445143
loss= 0.09439866494387389
loss= 0.09553591281175614
loss= 0.09586629200726747
loss= 0.09487765282392502
loss= 0.09468656126409769
loss= 0.09506322585046291
loss= 0.0958319291099906
loss= 0.09622080683708191
loss= 0.09597605016082525
loss= 0.09700165379792453
loss= 0.09797533769160509
loss= 0.09664239706471563
loss= 0.0964087794907391
loss= 0.09528930615633727
loss= 0.09423077329993249
loss= 0.09334421657025814
loss= 0.09480641223490238
loss= 0.0959170200303197
loss= 0.09622533865272999
backup model
accuracy 94.93237043812712
epoch= 192 / 200
loss= 0.09893918484449386
loss= 0.09914107099175454
loss= 0.09848260696977378
loss= 0.09719970241189003
loss= 0.09633150491863489
loss= 0.09746718674898147
loss= 0.09928816668689251
loss= 0.0993686693534255
loss= 0.10379414070397615
loss= 0.10267472866922617
loss= 0.10181254707276821
loss= 0.10203415088355541
loss= 0.10225272461771966
loss= 0.10392946638166904
loss= 0.10288291674107314
loss= 0.10214106496423483
loss= 0.10126613561064005
loss= 0.09968591686338187
loss= 0.10076519619673491
loss= 0.09850626714527606
loss= 0.09857303004711866
loss= 0.09689679149538279
backup model
accuracy 94.8750066173117
epoch= 193 / 200
loss= 0.10171044763177634
loss= 0.10171787131577731
loss= 0.10140041366219521
loss= 0.1015632490068674
loss= 0.10150940187275409
loss= 0.10152745831757784
loss= 0.10051870234310627
loss= 0.09896660923957824
loss= 0.09598084622994066
loss= 0.09336803728714585
loss= 0.09388950454071164
loss= 0.0976560589298606
loss= 0.09760710183531046
loss= 0.09764264147728681
loss= 0.09923653528094292
loss= 0.10030325327068568
loss= 0.09945102985948324
backup model
accuracy 94.6170475820343
epoch= 194 / 200
loss= 0.09808606464415788
loss= 0.09888401545584202
loss= 0.09532297972589732
loss= 0.09508903756737709
loss= 0.09506951704621315
loss= 0.09434796012938022
loss= 0.0946321877092123
loss= 0.09538870427757501
loss= 0.09625002801418304
loss= 0.09758392035961151
loss= 0.0981525406241417
loss= 0.10021945666521788
loss= 0.09704274144023657
loss= 0.09633133340626955
loss= 0.09561089772731066
loss= 0.09501154500991106
loss= 0.09520095612853766
loss= 0.09656989376991987
loss= 0.09990379516035318
backup model
accuracy 94.70177462301685
epoch= 195 / 200
loss= 0.10015285048633814
loss= 0.09951523527503013
loss= 0.09914563745260238
loss= 0.09723846780136228
loss= 0.09824625222012401
loss= 0.09916364064440131
loss= 0.10084789713844657
loss= 0.1008908523991704
loss= 0.09900534473359585
loss= 0.09883171942085028
loss= 0.09838070936501025
loss= 0.096258814483881
loss= 0.09634439829736947
loss= 0.09652589198201894
loss= 0.0967202927917242
loss= 0.09676089197397232
loss= 0.0966596769168973
loss= 0.09584283102303744
loss= 0.0952716961875558
loss= 0.09821329854428767
loss= 0.09869602326303721
loss= 0.09800441024824977
loss= 0.09704688800498844
loss= 0.09691351553425193
loss= 0.09662121130153536
backup model
accuracy 94.6806819419672
epoch= 196 / 200
loss= 0.09493953945115209
loss= 0.09463938979431986
loss= 0.09418560268357395
loss= 0.09463310508057475
loss= 0.09361753791570664
loss= 0.09619395785033703
loss= 0.09666950013488532
loss= 0.09669416699558496
loss= 0.09736679129302502
loss= 0.09758934438228607
loss= 0.097349953353405
loss= 0.09775786746293307
loss= 0.09734207421541213
loss= 0.097390680834651
loss= 0.09768381882458925
loss= 0.09592966310679912
loss= 0.09604400787502528
loss= 0.09626145601272583
loss= 0.0951758961379528
loss= 0.09491934843361377
loss= 0.09877979137003422
loss= 0.09921336138620973
loss= 0.09885414673015475
backup model
accuracy 94.18572293366807
epoch= 197 / 200
loss= 0.09922052560374141
loss= 0.09372757891193033
loss= 0.093928381819278
loss= 0.09387962451204658
loss= 0.09375627748668194
loss= 0.09309387095272541
loss= 0.09300361363217234
loss= 0.09260013526305556
loss= 0.09331956593319773
loss= 0.09355458909645677
loss= 0.09326443945989013
loss= 0.09433861250057816
loss= 0.09456480281427503
loss= 0.09335690518841147
loss= 0.09455973304808139
loss= 0.0954959262907505
loss= 0.09508310198783874
loss= 0.09508243970572948
loss= 0.09462468147277832
loss= 0.09472068879753351
loss= 0.09608023397624493
loss= 0.09673524364829063
loss= 0.09674470238387585
loss= 0.09709302049130202
loss= 0.09702906746417284
loss= 0.09654113948345185
loss= 0.09620954312384128
loss= 0.09575773872435094
loss= 0.09583948474377393
backup model
accuracy 94.66950568427075
epoch= 198 / 200
loss= 0.09611040003597736
loss= 0.09582759696990252
loss= 0.0957303350046277
loss= 0.09564929243177175
loss= 0.09558539506047964
loss= 0.09520960807800292
loss= 0.0952176022529602
loss= 0.09603647448122501
loss= 0.09552566487342119
loss= 0.09588666528463363
loss= 0.09833811201155186
loss= 0.10013750273734331
loss= 0.09832526281476021
loss= 0.09837137367576361
loss= 0.09831548109650612
loss= 0.09771711591631174
loss= 0.09735368475317956
loss= 0.09720203552395106
loss= 0.09804441686719656
loss= 0.09549484487622976
loss= 0.09546877261251212
loss= 0.09530654642730951
loss= 0.09454139947891235
loss= 0.0942056025005877
loss= 0.09374966794624924
backup model
accuracy 94.69724908172074
epoch= 199 / 200
loss= 0.0941528988815844
loss= 0.09380789807066321
loss= 0.0937707425840199
loss= 0.09279058422893285
loss= 0.0969490028731525
loss= 0.0999747577123344
loss= 0.09942118342965842
loss= 0.10002726703882217
loss= 0.09540721135213971
loss= 0.09423606364056468
loss= 0.09544911770150065
backup model
accuracy 94.54724925987914
training stops after reaching time limit
/opt/conda/conda-bld/pytorch_1591914855613/work/torch/csrc/utils/tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.
load model
massif benchmark
indexing miniworld (mode test ): 23 towns found ( ['potsdam/test', 'christchurch/test', 'toulouse/test', 'paris/test', 'austin/test', 'chicago/test', 'kitsap/test', 'tyrol-w/test', 'vienna/test', 'vegas/test', 'shanghai/test', 'khartoum/test', 'bruges/test', 'rio/test', 'Arlington/test', 'Austin/test', 'DC/test', 'NewYork/test', 'SanFrancisco/test', 'Atlanta/test', 'NewHaven/test', 'Norfolk/test', 'Seekonk/test'] ) with a total of 6135 images
potsdam/test
2360333 103453 86622 1049592
94.72013888888888 88.60726212570097
christchurch/test
140628192 7285137 894812 13907359
94.9728520024214 78.73420518609068
toulouse/test
forward in progress 576 3392
forward in progress 1152 3392
forward in progress 1792 3392
forward in progress 2368 3392
forward in progress 3008 3392
forward in progress 576 3392
forward in progress 1152 3392
forward in progress 1792 3392
forward in progress 2368 3392
forward in progress 3008 3392
18336081 1328693 326532 4200310
93.15785683767467 81.72628847571934
paris/test
52134893 2916910 758250 3661047
93.82025891567501 71.65934541631586
austin/test
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
110271080 5661420 1239149 17828351
94.8884674074074 83.10293197304978
chicago/test
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
91424447 8013870 5247705 30313978
90.17661111111111 78.4492635923408
kitsap/test
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
123864783 3294612 1096901 6743704
96.7470274074074 78.5689657286618
tyrol-w/test
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
122748084 2660518 627903 8963495
97.56413259259259 85.27542146040838
vienna/test
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
91264869 8804982 2024547 32905602
91.97812666666667 82.31550340703014
vegas/test
152744518 11083124 6339449 29083909
91.25596709677743 76.14940712449052
shanghai/test
203743825 7311654 10802786 15113535
92.35586681622033 68.65974961773942
khartoum/test
41842087 2898010 2964380 4770023
88.82811651373524 66.28703053423331
bruges/test
1647536 80568 28879 243017
94.52765 81.3593883208768
rio/test
381112117 13821184 7697078 17946387
94.88363035251453 70.06508415035816
Arlington/test
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
7680195 427671 50598 841536
94.6859 78.94995174690341
Austin/test
forward in progress 640 3456
forward in progress 1344 3456
forward in progress 2048 3456
forward in progress 2752 3456
8258973 456018 121348 1887224
94.61591264022974 85.01977607329167
DC/test
forward in progress 1280 1600
1438997 284019 40819 796165
87.311015625 76.30299111549692
NewYork/test
1609646 134042 42533 463779
92.15222222222222 81.27000676280797
SanFrancisco/test
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
4651287 859765 221647 3267301
87.98431111111111 78.13433619824266
Atlanta/test
1644125 108993 27769 379113
93.66842592592593 82.90494130893327
NewHaven/test
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
7183350 434961 269958 1111731
92.16756666666667 76.13023406194682
Norfolk/test
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
7586365 336229 74266 1003140
95.43894444444445 82.91426909783377
Seekonk/test
forward in progress 704 2944
forward in progress 1408 2944
forward in progress 2112 2944
forward in progress 2816 2944
8413906 172480 34027 379587
97.70547777777777 81.18499573761737
-------- results ----------
potsdam/test 88.60726212570097
christchurch/test 78.73420518609068
toulouse/test 81.72628847571934
paris/test 71.65934541631586
austin/test 83.10293197304978
chicago/test 78.4492635923408
kitsap/test 78.5689657286618
tyrol-w/test 85.27542146040838
vienna/test 82.31550340703014
vegas/test 76.14940712449052
shanghai/test 68.65974961773942
khartoum/test 66.28703053423331
bruges/test 81.3593883208768
rio/test 70.06508415035816
Arlington/test 78.94995174690341
Austin/test 85.01977607329167
DC/test 76.30299111549692
NewYork/test 81.27000676280797
SanFrancisco/test 78.13433619824266
Atlanta/test 82.90494130893327
NewHaven/test 76.13023406194682
Norfolk/test 82.91426909783377
Seekonk/test 81.18499573761737
miniworld 77.60335957861159
